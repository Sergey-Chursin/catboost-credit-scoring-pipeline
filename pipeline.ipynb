{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16440a4c-3e36-4614-958c-e83a5e2e5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "695f7092-6790-43f7-9177-1e2d4ea6ddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём внутреннюю папку проекта\n",
    "os.makedirs('pipeline', exist_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a991711a-05f4-4b8a-a3bc-11faa01c8919",
   "metadata": {},
   "source": [
    "# Lists of features for the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda82a61-1a8a-4f84-b873-d53bed7ab196",
   "metadata": {},
   "source": [
    "## Basic lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd86d03c-70ae-4b3c-8a89-abb51550015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rn - уникальный признак\n",
    "\n",
    "# Бинаризированные\n",
    "pre_features = [\n",
    "    'pre_since_opened',\n",
    "    'pre_since_confirmed',\n",
    "    'pre_pterm',\n",
    "    'pre_fterm',\n",
    "    'pre_till_pclose',\n",
    "    'pre_till_fclose',\n",
    "    'pre_loans_credit_limit',\n",
    "    'pre_loans_next_pay_summ',\n",
    "    'pre_loans_outstanding',\n",
    "    'pre_loans_max_overdue_sum',\n",
    "    'pre_loans_credit_cost_rate',\n",
    "    'pre_loans5',\n",
    "    'pre_loans530',\n",
    "    'pre_loans3060',\n",
    "    'pre_loans6090',\n",
    "    'pre_loans90',\n",
    "    'pre_util',\n",
    "    'pre_over2limit',\n",
    "    'pre_maxover2limit'\n",
    "]\n",
    "\n",
    "# Закодированные\n",
    "enc_features = [\n",
    "    'enc_loans_account_holder_type',\n",
    "    'enc_loans_credit_status',\n",
    "    'enc_loans_credit_type',\n",
    "    'enc_loans_account_cur'\n",
    "]\n",
    "\n",
    "# Статусы ежемесячных платежей\n",
    "enc_paym_features = [\n",
    "    'enc_paym_0',\n",
    "    'enc_paym_1',\n",
    "    'enc_paym_2',\n",
    "    'enc_paym_3',\n",
    "    'enc_paym_4',\n",
    "    'enc_paym_5',\n",
    "    'enc_paym_6',\n",
    "    'enc_paym_7',\n",
    "    'enc_paym_8',\n",
    "    'enc_paym_9',\n",
    "    'enc_paym_10',\n",
    "    'enc_paym_11',\n",
    "    'enc_paym_12',\n",
    "    'enc_paym_13',\n",
    "    'enc_paym_14',\n",
    "    'enc_paym_15',\n",
    "    'enc_paym_16',\n",
    "    'enc_paym_17',\n",
    "    'enc_paym_18',\n",
    "    'enc_paym_19',\n",
    "    'enc_paym_20',\n",
    "    'enc_paym_21',\n",
    "    'enc_paym_22',\n",
    "    'enc_paym_23',\n",
    "    'enc_paym_24'\n",
    "]\n",
    "\n",
    "#  Флаги\n",
    "flag_features = [\n",
    "    'is_zero_loans5',\n",
    "    'is_zero_loans530',\n",
    "    'is_zero_loans3060',\n",
    "    'is_zero_loans6090',\n",
    "    'is_zero_loans90',\n",
    "    'is_zero_util',\n",
    "    'is_zero_over2limit',\n",
    "    'is_zero_maxover2limit',\n",
    "    'pclose_flag',\n",
    "    'fclose_flag'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1809be45-ffa0-479d-ab99-ed02a40fd67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20931476, 61)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source = pd.read_csv('prepared_data/source_data_train_1.csv')\n",
    "df_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcd5991d-f0bb-4517-a2cd-36620a1315c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400000, 61)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.read_csv('prepared_data/cut_corr_imp_train.csv')\n",
    "df_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf0aa41-c0dd-4ed2-8534-66510b827c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'rn',\n",
       " 'pre_since_opened',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'pre_fterm',\n",
       " 'pre_till_pclose',\n",
       " 'pre_till_fclose',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_loans_next_pay_summ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source_columns = df_source.columns.tolist()\n",
    "df_source_columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cd7d089-961c-4f50-8027-fa8d06f64510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'flag',\n",
       " 'is_zero_sum_prop_1',\n",
       " 'enc_paym_avg_0_1_this_year_diff',\n",
       " 'pre_util_prop_3',\n",
       " 'enc_loans_credit_type_prop_0',\n",
       " 'pre_till_pclose_prop_10',\n",
       " 'pre_util_prop_6',\n",
       " 'pre_loans_outstanding_prop_1',\n",
       " 'pre_util_mean_freq']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_columns = df_result.columns.tolist()\n",
    "df_result_columns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28d7a8-c441-4630-9174-d5e2086a0c19",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## List of features to download from the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbf36f36-3bbf-4834-9a5d-f23dd1d5f796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pre_loans_total_overdue',\n",
       " 'pre_loans3060',\n",
       " 'pre_loans6090',\n",
       " 'pre_loans90',\n",
       " 'is_zero_loans3060',\n",
       " 'is_zero_loans6090',\n",
       " 'is_zero_loans90',\n",
       " 'pre_maxover2limit',\n",
       " 'is_zero_util',\n",
       " 'is_zero_maxover2limit',\n",
       " 'enc_paym_3',\n",
       " 'enc_paym_4',\n",
       " 'enc_paym_5',\n",
       " 'enc_paym_6',\n",
       " 'enc_paym_7',\n",
       " 'enc_paym_11',\n",
       " 'enc_paym_12',\n",
       " 'enc_paym_13',\n",
       " 'enc_paym_14',\n",
       " 'enc_paym_15',\n",
       " 'enc_paym_16',\n",
       " 'enc_paym_17',\n",
       " 'enc_paym_18',\n",
       " 'enc_paym_19',\n",
       " 'enc_paym_20',\n",
       " 'enc_paym_21',\n",
       " 'enc_paym_22',\n",
       " 'enc_paym_23',\n",
       " 'pclose_flag',\n",
       " 'fclose_flag']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Формируем список колонок из df_source_columns,\n",
    "которые НЕ встречаются ни в одном названии из df_result_columns как подстрока.\n",
    "\"\"\"\n",
    "drop_list = []\n",
    "for col_source in df_source_columns:\n",
    "    found = False\n",
    "    for col_result in df_result_columns:\n",
    "        if col_source in col_result:\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        drop_list.append(col_source)\n",
    "\n",
    "print(len(drop_list))\n",
    "drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2bd47bf9-694c-4bfd-acec-fa2ae3ab047f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'rn',\n",
       " 'pre_since_opened',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'pre_fterm',\n",
       " 'pre_till_pclose',\n",
       " 'pre_till_fclose',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_loans_next_pay_summ']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_columns = [x for x in df_source_columns if x not in drop_list]\n",
    "\n",
    "print(len(needed_columns))\n",
    "needed_columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84483ca2-71ed-41d2-b503-624f146a9458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'rn',\n",
       " 'pre_since_opened',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'pre_fterm',\n",
       " 'pre_till_pclose',\n",
       " 'pre_till_fclose',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_loans_next_pay_summ']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Добавим недостающие признаки из групп flag_features и enc_paym _features, \n",
    "для правильной работы функций обрабатывающих эти группы. \n",
    "\"\"\"\n",
    "features_list= [\n",
    "    'is_zero_loans3060',\n",
    "    'is_zero_loans6090',\n",
    "    'is_zero_loans90',\n",
    "    'enc_paym_3',\n",
    "    'enc_paym_4',\n",
    "    'enc_paym_5',\n",
    "    'enc_paym_6',\n",
    "    'enc_paym_7',\n",
    "    'enc_paym_11',\n",
    "    'enc_paym_12',\n",
    "    'enc_paym_13',\n",
    "    'enc_paym_14',\n",
    "    'enc_paym_15',\n",
    "    'enc_paym_16',\n",
    "    'enc_paym_17',\n",
    "    'enc_paym_18',\n",
    "    'enc_paym_19',\n",
    "    'enc_paym_20',\n",
    "    'enc_paym_21',\n",
    "    'enc_paym_22',\n",
    "    'enc_paym_23'\n",
    "]\n",
    "\n",
    "# Список признаков для скачивания из исходного датасета\n",
    "needed_columns = needed_columns + features_list\n",
    "\n",
    "print(len(needed_columns))\n",
    "needed_columns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d67d7-625f-4cde-9d97-0a2905017239",
   "metadata": {},
   "source": [
    "## Create_definite_value_proportion_features_pipeline funtion list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8918094-ea0a-43db-99db-cd070b4b5bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['is_zero_sum_prop_1',\n",
       " 'pre_util_prop_3',\n",
       " 'enc_loans_credit_type_prop_0',\n",
       " 'pre_till_pclose_prop_10',\n",
       " 'pre_util_prop_6',\n",
       " 'pre_loans_outstanding_prop_1',\n",
       " 'pre_loans_credit_limit_prop_2',\n",
       " 'pre_loans_credit_cost_rate_prop_6',\n",
       " 'pre_loans_outstanding_prop_5',\n",
       " 'pre_loans_credit_cost_rate_prop_11',\n",
       " 'pre_loans_credit_cost_rate_prop_4',\n",
       " 'pre_loans_next_pay_summ_prop_5',\n",
       " 'pre_since_opened_prop_12',\n",
       " 'pre_loans_credit_limit_prop_15',\n",
       " 'enc_loans_credit_type_prop_2',\n",
       " 'pre_fterm_prop_7',\n",
       " 'enc_paym_0_prop_1',\n",
       " 'is_zero_over2limit_prop_1',\n",
       " 'pre_since_opened_prop_8',\n",
       " 'pre_loans_max_overdue_sum_prop_1',\n",
       " 'pre_loans_next_pay_summ_prop_0',\n",
       " 'pre_pterm_prop_6',\n",
       " 'pre_since_opened_prop_19',\n",
       " 'is_zero_loans5_prop_1',\n",
       " 'enc_loans_account_holder_type_prop_4',\n",
       " 'pre_loans_credit_limit_prop_18',\n",
       " 'pre_till_fclose_prop_4',\n",
       " 'pre_pterm_prop_3',\n",
       " 'is_zero_loans530_prop_1',\n",
       " 'enc_loans_credit_status_prop_5',\n",
       " 'pre_since_confirmed_prop_4',\n",
       " 'pre_fterm_prop_3',\n",
       " 'pre_till_fclose_prop_3',\n",
       " 'pre_till_fclose_prop_1',\n",
       " 'pre_till_pclose_prop_7',\n",
       " 'pre_since_confirmed_prop_7',\n",
       " 'enc_paym_24_prop_1',\n",
       " 'pre_over2limit_prop_17']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим список пропорциональных фичей в итоговом датасете\n",
    "prop_features_result_list = [col for col in df_result_columns if 'prop_' in col]\n",
    "\n",
    "print(len(prop_features_result_list))\n",
    "prop_features_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "864d11b8-b29a-4cf7-8e75-1c82fa30f7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['enc_loans_account_holder_type',\n",
       " 'pre_pterm',\n",
       " 'is_zero_loans530',\n",
       " 'enc_paym_0',\n",
       " 'pre_loans_credit_cost_rate',\n",
       " 'pre_loans_next_pay_summ',\n",
       " 'is_zero_over2limit',\n",
       " 'pre_loans_outstanding',\n",
       " 'pre_util',\n",
       " 'pre_till_pclose',\n",
       " 'is_zero_loans5',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_over2limit',\n",
       " 'pre_till_fclose',\n",
       " 'enc_loans_credit_status',\n",
       " 'pre_since_opened',\n",
       " 'enc_paym_24',\n",
       " 'is_zero_sum',\n",
       " 'pre_loans_max_overdue_sum',\n",
       " 'enc_loans_credit_type',\n",
       " 'pre_fterm']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим список признаков исходного датасета из которых были сделаны пропорциональные фичи\n",
    "prop_features_source_list = list(\n",
    "    set(\n",
    "        [\n",
    "            re.sub(r'_prop.*$', '', col)\n",
    "            for col in prop_features_result_list\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(len(prop_features_source_list))\n",
    "prop_features_source_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c5e70c9-1efe-4c0d-ab60-9e90553339f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_loans_account_holder_type': [4],\n",
       " 'pre_pterm': [6, 3],\n",
       " 'is_zero_loans530': [1],\n",
       " 'enc_paym_0': [1],\n",
       " 'pre_loans_credit_cost_rate': [6, 11, 4],\n",
       " 'pre_loans_next_pay_summ': [5, 0],\n",
       " 'is_zero_over2limit': [1],\n",
       " 'pre_loans_outstanding': [1, 5],\n",
       " 'pre_util': [3, 6],\n",
       " 'pre_till_pclose': [10, 7],\n",
       " 'is_zero_loans5': [1],\n",
       " 'pre_since_confirmed': [4, 7],\n",
       " 'pre_loans_credit_limit': [2, 15, 18],\n",
       " 'pre_over2limit': [17],\n",
       " 'pre_till_fclose': [4, 3, 1],\n",
       " 'enc_loans_credit_status': [5],\n",
       " 'pre_since_opened': [12, 8, 19],\n",
       " 'enc_paym_24': [1],\n",
       " 'is_zero_sum': [1],\n",
       " 'pre_loans_max_overdue_sum': [1],\n",
       " 'enc_loans_credit_type': [0, 2],\n",
       " 'pre_fterm': [7, 3]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Соберем часть словаря пропорциональных фичей для пайплайна\n",
    "prop_features_dict = {}\n",
    "\n",
    "for source_col in prop_features_source_list:\n",
    "    # Инициализируем пустой список для каждого исходного признака\n",
    "    prop_features_dict[source_col] = []\n",
    "    # Создадим паттерн: имя col в начале и после него подчёркивание или конец строки\n",
    "    pattern = re.compile(r'^' + source_col + r'(_|$)')\n",
    "    for result_col in prop_features_result_list:\n",
    "        # Проверяем, совпадает ли имя признака с паттерном\n",
    "        if pattern.match(result_col):\n",
    "            # Ищем число в конце строки\n",
    "            match = re.search(r'(\\d+)$', result_col)\n",
    "            # Добавляем найденное число в список для данного source_col\n",
    "            prop_features_dict[source_col].append(int(match.group(1)))\n",
    "prop_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6776ea8b-4970-440c-b8ac-c93930ca9652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc_loans_account_holder_type': [4],\n",
       " 'pre_pterm': [6, 3],\n",
       " 'is_zero_loans530': [1],\n",
       " 'enc_paym_0': [1],\n",
       " 'pre_loans_credit_cost_rate': [6, 11, 4],\n",
       " 'pre_loans_next_pay_summ': [5, 0],\n",
       " 'is_zero_over2limit': [1],\n",
       " 'pre_loans_outstanding': [1, 5],\n",
       " 'pre_util': [3, 6],\n",
       " 'pre_till_pclose': [10, 7],\n",
       " 'is_zero_loans5': [1],\n",
       " 'pre_since_confirmed': [4, 7],\n",
       " 'pre_loans_credit_limit': [2, 15, 18],\n",
       " 'pre_over2limit': [17],\n",
       " 'pre_till_fclose': [4, 3, 1],\n",
       " 'enc_loans_credit_status': [5],\n",
       " 'pre_since_opened': [12, 8, 19],\n",
       " 'enc_paym_24': [1],\n",
       " 'pre_loans_max_overdue_sum': [1],\n",
       " 'enc_loans_credit_type': [0, 2],\n",
       " 'pre_fterm': [7, 3],\n",
       " 'is_zero_loans3060': [1],\n",
       " 'is_zero_loans6090': [1],\n",
       " 'is_zero_loans90': [1]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Добавим в словарь недостающие is_zero_loans* для функции суммирования.\n",
    "Удалим is_zero_sum, фича is_zero_sum_prop_1 будет собираться другой функцией.\n",
    "\"\"\"\n",
    "is_zero_loans_list = [\n",
    "        'is_zero_loans5',\n",
    "        'is_zero_loans530',\n",
    "        'is_zero_loans3060',\n",
    "        'is_zero_loans6090',\n",
    "        'is_zero_loans90'\n",
    "    ]\n",
    "for col in is_zero_loans_list:\n",
    "    if col not in prop_features_dict.keys():\n",
    "        prop_features_dict[col] = [1]\n",
    "        \n",
    "del prop_features_dict['is_zero_sum']\n",
    "\n",
    "prop_features_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0a3e3f-a04f-4cb9-a28e-309b435f2cb2",
   "metadata": {},
   "source": [
    "## List for create_mean_value_frequency_feature_pipeline features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3344e24-9ffb-45ca-ab41-0f8e2ee01700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pre_util_mean_freq',\n",
       " 'pre_loans_credit_limit_mean_freq',\n",
       " 'pre_since_opened_mean_freq',\n",
       " 'pre_loans_credit_cost_rate_mean_freq',\n",
       " 'enc_loans_credit_type_mean_freq',\n",
       " 'pre_loans_next_pay_summ_mean_freq',\n",
       " 'pre_since_confirmed_mean_freq',\n",
       " 'pre_pterm_mean_freq',\n",
       " 'enc_paym_0_mean_freq',\n",
       " 'enc_loans_account_holder_type_mean_freq',\n",
       " 'pre_loans530_mean_freq',\n",
       " 'enc_paym_8_mean_freq',\n",
       " 'pre_loans5_mean_freq',\n",
       " 'enc_paym_10_mean_freq',\n",
       " 'enc_loans_account_cur_mean_freq',\n",
       " 'enc_paym_9_mean_freq']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Соберем список всех фичей средней частотности в итоговом датасете\n",
    "mean_freq_result_list = [col for col in df_result_columns if 'mean_freq' in col]\n",
    "\n",
    "print(len(mean_freq_result_list))\n",
    "mean_freq_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ec18ab2-0503-4a84-8dd3-78be3f1457f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pre_util',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_since_opened',\n",
       " 'pre_loans_credit_cost_rate',\n",
       " 'enc_loans_credit_type',\n",
       " 'pre_loans_next_pay_summ',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'enc_paym_0',\n",
       " 'enc_loans_account_holder_type',\n",
       " 'pre_loans530',\n",
       " 'enc_paym_8',\n",
       " 'pre_loans5',\n",
       " 'enc_paym_10',\n",
       " 'enc_loans_account_cur',\n",
       " 'enc_paym_9']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Соберем список признаков исходного датасета \n",
    "из которых были сделаны фичи средней частотности.\n",
    "\"\"\"\n",
    "mean_freq_source_list = [x[:-len('_mean_freq')] for x in mean_freq_result_list]\n",
    "print(len(mean_freq_source_list))\n",
    "mean_freq_source_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3774b5-4a4d-417c-972e-6f998596816f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Downloading dataset and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf6d693b-65ab-4f66-b7fd-93020e230eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# СКАЧИВАЕМ ИСХОДНЫЙ ДАТАСЕТ\n",
    "# Путь до данных в проекте\n",
    "path = 'train_data/'\n",
    "\n",
    "def read_parquet_dataset_from_local(\n",
    "    path_to_dataset: str,\n",
    "    start_from: int = 0,\n",
    "    num_parts_to_read: int = 2,\n",
    "    columns: Optional[List[str]] = None,\n",
    "    verbose: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Читает num_parts_to_read партиций, преобразовывает их к pd.DataFrame и возвращает.\n",
    "\n",
    "    Args:\n",
    "        path_to_dataset : путь до директории с партициями\n",
    "        start_from : номер партиции, с которой нужно начать чтение\n",
    "        num_parts_to_read : количество партиций, которые требуется прочитать\n",
    "        columns : список колонок, которые нужно прочитать из партиции\n",
    "        verbose : выводить ли дополнительную информацию\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    dataset_paths = sorted(\n",
    "        os.path.join(path_to_dataset, filename)\n",
    "        for filename in os.listdir(path_to_dataset)\n",
    "        if filename.startswith('train')\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print('Dataset paths:')\n",
    "        for path in dataset_paths:\n",
    "            print(path)\n",
    "\n",
    "    start_from = max(0, start_from)\n",
    "    chunks = dataset_paths[start_from: start_from + num_parts_to_read]\n",
    "\n",
    "    if verbose:\n",
    "        print('Reading chunks:')\n",
    "        for chunk in chunks:\n",
    "            print(chunk)\n",
    "\n",
    "    for chunk_path in tqdm(chunks, desc=\"Reading dataset with pandas\"):\n",
    "        if verbose:\n",
    "            print('Reading chunk:', chunk_path)\n",
    "        chunk = pd.read_parquet(chunk_path, columns=columns)\n",
    "        res.append(chunk)\n",
    "\n",
    "    return pd.concat(res).reset_index(drop=True)\n",
    "\n",
    "def prepare_transactions_dataset(\n",
    "    path_to_dataset: str,\n",
    "    num_parts_to_preprocess_at_once: int = 1,\n",
    "    num_parts_total: int = 50,\n",
    "    save_to_path: str = None,\n",
    "    verbose: bool = False,\n",
    "    columns: Optional[List[str]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Возвращает исходный pd.DataFrame с признаками из которых нужно собрать\n",
    "    учебный датасет.\n",
    "\n",
    "    Args:\n",
    "        path_to_dataset : путь до датасета с партициями\n",
    "        num_parts_to_preprocess_at_once : количество партиций, \n",
    "            которые будут одновременно держаться и обрабатываться в памяти\n",
    "        num_parts_total : общее количество партиций, которые нужно обработать\n",
    "        save_to_path : путь до папки для сохранения обработанных блоков в .parquet-формате; \n",
    "            если None, сохранение не происходит\n",
    "        verbose : логировать каждую обрабатываемую часть данных\n",
    "        columns : список колонок, которые нужно оставить\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame : датафрейм с объединёнными данными\n",
    "    \"\"\"\n",
    "    preprocessed_frames = []\n",
    "\n",
    "    for step in tqdm(range(0, num_parts_total, num_parts_to_preprocess_at_once),\n",
    "                     desc=\"Transforming transactions data\"):\n",
    "        transactions_frame = read_parquet_dataset_from_local(\n",
    "            path_to_dataset,\n",
    "            start_from=step,\n",
    "            num_parts_to_read=num_parts_to_preprocess_at_once,\n",
    "            verbose=verbose,\n",
    "            columns=columns\n",
    "        )\n",
    "\n",
    "       # Записываем подготовленные данные в файл\n",
    "        if save_to_path:\n",
    "            block_as_str = str(step)\n",
    "            if len(block_as_str) == 1:\n",
    "                block_as_str = '00' + block_as_str\n",
    "            else:\n",
    "                block_as_str = '0' + block_as_str\n",
    "            transactions_frame.to_parquet(os.path.join(save_to_path, f'processed_chunk_{block_as_str}.parquet'))\n",
    "\n",
    "        preprocessed_frames.append(transactions_frame)\n",
    "    \n",
    "    return pd.concat(preprocessed_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "938b8752-54e0-415c-9c1a-5345f1fe9210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71bfd42b3e846a0a7aa34052414948c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transforming transactions data:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9842e8800d492285cf272b5bc425bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64820417b7824517b5473fba3eecd8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b810d1e3de194734b19d8f660263e3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242df1c0ad9d419f9b727b4f3d5cd7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1166a686bbad4f9a837874a07935d06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba7fc680f764be9834778198769a898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cccd205b2b4c298dbeee35683a3b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd4d3a4fb2a48fcb80064e697dcb210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20fcfc233dd4678a322d6378e6de1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c84a4a182c443291111e7eb0fa245e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbd476ca3eb49f3a4a7444cf6ed0ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f7e4d5b83c4183b0a45a9fe3bfa92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((20931476, 52), (5231241, 52), (2400000,), (600000,))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Собираем исходный датасет из parquet файлов,  \n",
    "скачиваем только необходимые колонки\n",
    "\"\"\"\n",
    "data = prepare_transactions_dataset(\n",
    "    path,\n",
    "    num_parts_to_preprocess_at_once=1,\n",
    "    num_parts_total=12,\n",
    "    save_to_path='train_data/',\n",
    "    columns=needed_columns) \n",
    "\n",
    "# Загружаем датасет с целевой переменной\n",
    "target = pd.read_csv('train_target.csv')\n",
    "\n",
    "# Делим датасет с целевой переменной на train/test части\n",
    "y_train, y_test  = train_test_split(target, train_size=0.8, random_state=0, stratify=target.flag)\n",
    "\n",
    "# Забираем наборы id из train/test\n",
    "train_id = y_train['id'].values\n",
    "test_id = y_test['id'].values\n",
    "\n",
    "# На основе наборов id делим исходный датасет на train/test части\n",
    "X_train = data.set_index('id').loc[train_id].reset_index()\n",
    "X_test = data.set_index('id').loc[test_id].reset_index()\n",
    "\n",
    "# Сбросим индексы для приведения к единому виду с X_train/X_test \n",
    "y_train = y_train.reset_index(drop=True)['flag']\n",
    "y_test = y_test.reset_index(drop=True)['flag']\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0392a984-602b-4c1a-a93f-17f0bba0c7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20931476, 52), (5231241, 52), (2400000,), (600000,))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохраним разделённые данные\n",
    "X_train.to_csv('pipeline/X_train.csv', index=False)\n",
    "X_test.to_csv('pipeline/X_test.csv', index=False)\n",
    "y_train.to_csv('pipeline/y_train.csv', index=False)\n",
    "y_test.to_csv('pipeline/y_test.csv', index=False)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd7962-3572-4930-99d7-c51655fe80de",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44231b7d-9226-4aad-a823-ffcbe7db8e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20931476, 52), (5231241, 52), (2400000, 1), (600000, 1))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем исходные разделённые данные \n",
    "X_train = pd.read_csv('pipeline/X_train.csv')\n",
    "X_test = pd.read_csv('pipeline/X_test.csv')\n",
    "y_train = pd.read_csv('pipeline/y_train.csv')\n",
    "y_test = pd.read_csv('pipeline/y_test.csv')\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a403e-6c17-4856-b5d2-a68f8c9655f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb7646-a345-45b7-8bba-252d9a5af26d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6015c69-9e80-43fd-899c-5f7359fb8223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce7a2c04-10f3-453d-b920-d4793f0fa03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_1.shape (1000, 93)\n",
      "y_train_1.shape (1000, 1)\n",
      "X_test_1.shape (1000, 52)\n",
      "y_test_1.shape (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Возьмём небольшую часть датасета для быстрой проверки пайплайна\n",
    "X_train_short = X_train[:1000].copy()\n",
    "y_train_short = y_train[:1000].copy()\n",
    "print('X_train_1.shape', X_train_1.shape)\n",
    "print('y_train_1.shape', y_train_1.shape)\n",
    "\n",
    "X_test_short = X_test[:1000].copy()\n",
    "y_test_short = y_test[:1000].copy()\n",
    "print('X_test_1.shape', X_test_1.shape)\n",
    "print('y_test_1.shape', y_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7427d652-1bef-4afa-8d04-b05fbbc15bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5231241, 52)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Для полной проверки будем использовать тестовые данные \n",
    "данные как меньшие по объёму.\n",
    "\"\"\"\n",
    "X_test_full = X_test.copy()\n",
    "X_test_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2585a60f-ea6e-46d4-a562-c3662858e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "def convert_all_to_numeric(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Преобразует типы всех колоноки в числовые с заменой ошибок на NaN.\n",
    "\n",
    "    Args:\n",
    "        df: Исходный DataFrame, содержащий колонки 'id' и 'rn'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Копия исходного DataFrame с добавленной колонкой 'rn_max'.\n",
    "    \"\"\"\n",
    "    return df.apply(lambda col: pd.to_numeric(col, errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3290d14-eac0-4546-a36a-1c5e59851111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGENERING FUNCTIONS\n",
    "\n",
    "def create_rn_max_feature_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Добавляет в DataFrame новую колонку 'rn_max' — максимальное \n",
    "    значение 'rn' для каждой группы 'id'.\n",
    "\n",
    "    Args:\n",
    "        df: Исходный DataFrame, содержащий колонки 'id' и 'rn'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Копия исходного DataFrame с добавленной колонкой 'rn_max'.\n",
    "    \"\"\"\n",
    "    print('FUNCTION create_rn_max_feature ')\n",
    "    df = df.copy()\n",
    "    # Вычисляем максимальное значение 'rn' для каждой группы 'id'\n",
    "    group_value = df.groupby('id')['rn'].max().rename('rn_max')\n",
    "\n",
    "    # Объедииняем исходный DataFrame с результатом группировки по 'id'\n",
    "    df = df.merge(group_value, on='id', how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def enc_paym_transcoding_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Прекодирует признаки enc_paym_features к единому виду с диапазоном значений {0, 1, 2, 3}.\n",
    "    Для каждого столбца enc_paym_0, enc_paym_1, ..., enc_paym_24, \n",
    "    если в значениях встречается 4, происходит замена:\n",
    "        1 -> 0\n",
    "        2 -> 1\n",
    "        3 -> 2\n",
    "        4 -> 3\n",
    "\n",
    "    Args:\n",
    "        df: Исходный DataFrame с колонками 'enc_paym_0' ... 'enc_paym_24'.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: Копия DataFrame с перекодированными признаками.\n",
    "    \"\"\"\n",
    "    print('FUNCTION enc_paym_transcoding ')\n",
    "    df = df.copy()\n",
    "    # Список колонок для перекодировки\n",
    "    columns = [f'enc_paym_{i}' for i in range(25)]\n",
    "    \n",
    "    for col in columns:\n",
    "        # Проверяем, есть ли значение 4 в колонке\n",
    "        if 4 in df[col].unique():\n",
    "            # Заменяем значения согласно маппингу\n",
    "            df.loc[:, col] = df[col].replace({1: 0, 2: 1, 3: 2, 4: 3})\n",
    "            \n",
    "    return df\n",
    "\n",
    "def create_definite_value_proportion_features_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Создаёт и добавляет в датафрейм новые частотные признаки \n",
    "    на основе заданных значений исходных признаков.\n",
    "    \n",
    "    Для каждого столбца и каждого указанного значения в словаре функция создаёт новые признаки, \n",
    "    отражающие долю записей с этим значением относительно общего количества \n",
    "    кредитов (rn_max) для каждого id.\n",
    "    \n",
    "    Args:\n",
    "        df: Исходный DataFrame, содержащий необходимые признаки и колонку 'rn_max'.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Копия исходного DataFrame с добавленными частотными признаками.\n",
    "    \"\"\"\n",
    "    print('FUNCTION create_definite_value_proportion_features ')\n",
    "    df = df.copy()\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'enc_loans_account_holder_type': [4],\n",
    "        'pre_pterm': [6, 3],\n",
    "        'is_zero_loans530': [1],\n",
    "        'enc_paym_0': [1],\n",
    "        'pre_loans_credit_cost_rate': [6, 11, 4],\n",
    "        'pre_loans_next_pay_summ': [5, 0],\n",
    "        'is_zero_over2limit': [1],\n",
    "        'pre_loans_outstanding': [1, 5],\n",
    "        'pre_util': [3, 6],\n",
    "        'pre_till_pclose': [10, 7],\n",
    "        'is_zero_loans5': [1],\n",
    "        'pre_since_confirmed': [4, 7],\n",
    "        'pre_loans_credit_limit': [2, 15, 18],\n",
    "        'pre_over2limit': [17],\n",
    "        'pre_till_fclose': [4, 3, 1],\n",
    "        'enc_loans_credit_status': [5],\n",
    "        'pre_since_opened': [12, 8, 19],\n",
    "        'enc_paym_24': [1],\n",
    "        'pre_loans_max_overdue_sum': [1],\n",
    "        'enc_loans_credit_type': [0, 2],\n",
    "        'pre_fterm': [7, 3],\n",
    "        'is_zero_loans3060': [1],\n",
    "        'is_zero_loans6090': [1],\n",
    "        'is_zero_loans90': [1]\n",
    "    }   \n",
    "\n",
    "    \n",
    "        \n",
    "    for col in  features_dictionary.keys():\n",
    "        print('Исходный признак', col)\n",
    "        print('Новые фичи')\n",
    "        \n",
    "        for value in features_dictionary[col]:\n",
    "            new_column = f'{col}_prop_{value}'\n",
    "            print(new_column)                     \n",
    "            \n",
    "            # Создаём группировку с количеством value для каждого id\n",
    "            group_value = df[df[col] == value].groupby('id').size().rename(new_column)\n",
    "\n",
    "            # Объедииняем группировку с  датасетом\n",
    "            df = df.merge(group_value, on='id', how='left')\n",
    "            \n",
    "            # Заполняем пропуски нулями\n",
    "            df[new_column] = df[new_column].fillna(0)\n",
    "            \n",
    "            # Считаем отношение к количеству кредитов\n",
    "            df[new_column] = df[new_column] / df['rn_max']         \n",
    "\n",
    "    return df\n",
    "\n",
    "def from_is_zero_prop_1_create_sum_prop_1_feature_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Вычисляет среднее значение признаков is_zero_*_prop_1 по строкам и добавляет \n",
    "    новый признак 'is_zero_sum_prop_1' в DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df:  Исходный DataFrame с признаками is_zero_*_prop_1.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Копия DataFrame с добавленным признаком 'is_zero_sum_prop_1'.\n",
    "    \"\"\"\n",
    "\n",
    "    print('FUNCTION of_is_zero_prop_1_create_sum_prop_1_feature ')\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    columns = [\n",
    "        'is_zero_loans5_prop_1',\n",
    "        'is_zero_loans530_prop_1',\n",
    "        'is_zero_loans3060_prop_1',\n",
    "        'is_zero_loans6090_prop_1',\n",
    "        'is_zero_loans90_prop_1'\n",
    "    ]\n",
    "\n",
    "    df['is_zero_sum_prop_1'] = df[columns].sum(axis=1) / 5\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_mean_value_frequency_feature_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cоздаёт новые агрегированные признаки,\n",
    "    отражающий среднюю частоту (относительную встречаемость) значений \n",
    "    заданных столбцов columns_list датафрейма для каждого уникального id.\n",
    "    Результат добавляется в  датафрейм \n",
    "    с нормировкой на количество записей (rn_max) для каждого id.\n",
    "    \n",
    "    Args:\n",
    "        df :  Исходный DataFrame с признаками из columns_list.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame :  Копия DataFrame с добавленным новым столбцом {column}_mean_freq,\n",
    "        содержащим нормированное агрегированное значение средней \n",
    "        частоты значений column для каждого id.\n",
    "    \"\"\"\n",
    "    print('FUNCTION create_mean_value_frequency_feature ')\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Список столбцов, для которых считаем среднюю частоту значений\n",
    "    columns_list = [\n",
    "        'pre_util',\n",
    "        'pre_loans_credit_limit',\n",
    "        'pre_since_opened',\n",
    "        'pre_loans_credit_cost_rate',\n",
    "        'enc_loans_credit_type',\n",
    "        'pre_loans_next_pay_summ',\n",
    "        'pre_since_confirmed',\n",
    "        'pre_pterm',\n",
    "        'enc_paym_0',\n",
    "        'enc_loans_account_holder_type',\n",
    "        'pre_loans530',\n",
    "        'enc_paym_8',\n",
    "        'pre_loans5',\n",
    "        'enc_paym_10',\n",
    "        'enc_loans_account_cur',\n",
    "        'enc_paym_9'\n",
    "    ]\n",
    "    \n",
    "    for col in columns_list:\n",
    "        new_column = f'{col}_mean_freq'\n",
    "        print('new_column', new_column)\n",
    "        \n",
    "        # Вычисляем относительную частоту каждого уникального значения в столбце\n",
    "        bin_freq = df[col].value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        # Создаём Series с частотами значений для каждой строки\n",
    "        freq_series = df[col].map(bin_freq)\n",
    "        \n",
    "        # Группируем по 'id' и суммируем частоты значений\n",
    "        agg_freq = freq_series.groupby(df['id']).sum().reset_index(name=new_column)\n",
    "        \n",
    "        # Добавляем новый признак в DataFrame, объединяя по 'id'\n",
    "        df = df.merge(agg_freq, on='id', how='left')\n",
    "    \n",
    "        # Нормируем агрегированные суммы частот на количество записей 'rn_max' для каждого id\n",
    "        df[new_column] = df[new_column] / df['rn_max']\n",
    "\n",
    "    return df\n",
    "\n",
    "def enc_paym_norm_group_sum_diff_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Генерирует признаки разницы между средними количествами различных статусов платежей \n",
    "    по кредитам за разные временные промежутки.\n",
    "\n",
    "    Основная цель функции — создать итоговые признаки:\n",
    "        - 'enc_paym_avg_0_1_this_year_diff'\n",
    "        - 'enc_paym_avg_1_2_all_diff'\n",
    "        - 'enc_paym_avg_0_years_diff'\n",
    "\n",
    "    Для их расчёта временно создаются промежуточные агрегированные признаки среднего \n",
    "    количества статусов платежей по id и периоду \n",
    "    (например, 'enc_paym_avg_0_this_year'), \n",
    "    которые впоследствии удаляются из итогового датасета.\n",
    "\n",
    "    Args:\n",
    "        df :  Исходный DataFrame с признаками из columns_list.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame :  Копия DataFrame с добавленными итоговыми признаками \n",
    "        разницы между средними количествами статусов платежей по различным периодам.\n",
    "    \"\"\"\n",
    "\n",
    "    print('FUNCTION enc_paym_norm_group_sum_diff_pipeline ')\n",
    "    df = df.copy()\n",
    "\n",
    "    # Создаём временный датафрейм со столбцом id из df\n",
    "    df_buff = pd.DataFrame(data = df['id'], columns = ['id'])\n",
    "    \n",
    "    # Временной промежуток 'all' — все периоды\n",
    "    time_span = 'all'\n",
    "    columns = [f'enc_paym_{i}' for i in range(25)]\n",
    "\n",
    "    # Для статусов платежей по кредитам 1 и 2\n",
    "    for i in range(1, 3):\n",
    "        new_col = f'enc_paym_avg_{i}_{time_span}'\n",
    "        print('new_column', new_col)\n",
    "        \n",
    "        # Считаем количество статуса i по всем столбцам за период \n",
    "        df_buff[new_col] = np.sum(\n",
    "            [df[col] == i for col in columns],\n",
    "            axis=0\n",
    "        )\n",
    "        \n",
    "        # Группируем по id и суммируем значения\n",
    "        agg_sum = (\n",
    "            df_buff\n",
    "            .groupby('id')\n",
    "            [new_col]  \n",
    "            .sum()\n",
    "            .reset_index(name=new_col)\n",
    "        )\n",
    "        \n",
    "        # Добавляем группировку в исходный DataFrame\n",
    "        df = df.merge(agg_sum, on='id', how='left')\n",
    "        \n",
    "        # Нормируем сумму на количество записей 'rn_max' \n",
    "        df[new_col] = df[new_col] / df['rn_max']\n",
    "        \n",
    "    # Временной промежуток 'this_year' — первые 12 месяцев\n",
    "    time_span = 'this_year'\n",
    "    columns = [f'enc_paym_{i}' for i in range(12)]\n",
    "\n",
    "    # Для статусов платежей по кредитам 0 и 1\n",
    "    for i in range(2):\n",
    "        new_col = f'enc_paym_avg_{i}_{time_span}'\n",
    "        print('new_column', new_col)\n",
    "        \n",
    "        # Считаем количество статуса i по всем столбцам за период \n",
    "        df_buff[new_col] = np.sum(\n",
    "            [df[col] == i for col in columns],\n",
    "            axis=0\n",
    "        )\n",
    "        \n",
    "        # Группируем по id и суммируем значения\n",
    "        agg_sum = (\n",
    "            df_buff\n",
    "            .groupby('id')\n",
    "            [new_col]  \n",
    "            .sum()\n",
    "            .reset_index(name=new_col)\n",
    "        )\n",
    "        \n",
    "        # Добавляем группировку в исходный DataFrame\n",
    "        df = df.merge(agg_sum, on='id', how='left')\n",
    "        \n",
    "        # Нормируем сумму на количество записей 'rn_max' \n",
    "        df[new_col] = df[new_col] / df['rn_max']\n",
    "        \n",
    "    # Временной промежуток 'last_year' — месяцы с 12 по 24\n",
    "    time_span = 'last_year'\n",
    "    columns = [f'enc_paym_{i}' for i in range(12, 25)]\n",
    "    \n",
    "    \"\"\"\n",
    "    Статус платежей  0.\n",
    "    (Оставим цикл для единообразия кода)\n",
    "    \"\"\"\n",
    "    for i in [0]:\n",
    "        new_col = f'enc_paym_avg_{i}_{time_span}'\n",
    "        print('new_column', new_col)\n",
    "        \n",
    "        # Считаем количество статуса i по всем столбцам за период \n",
    "        df_buff[new_col] = np.sum(\n",
    "            [df[old_col] == i for old_col in columns],\n",
    "            axis=0\n",
    "        )\n",
    "        \n",
    "        # Группируем по id и суммируем значения\n",
    "        agg_sum = (\n",
    "            df_buff\n",
    "            .groupby('id')\n",
    "            [new_col]  \n",
    "            .sum()\n",
    "            .reset_index(name=new_col)\n",
    "        )\n",
    "        \n",
    "        # Добавляем группировку в исходный DataFrame\n",
    "        df = df.merge(agg_sum, on='id', how='left')\n",
    "        \n",
    "        # Нормируем сумму на количество записей 'rn_max' \n",
    "        df[new_col] = df[new_col] / df['rn_max']\n",
    "\n",
    "    # Создаём фичи разницы \n",
    "    df['enc_paym_avg_0_1_this_year_diff'] = (\n",
    "            df['enc_paym_avg_0_this_year'] - \n",
    "            df['enc_paym_avg_1_this_year']\n",
    "    )\n",
    "\n",
    "    df['enc_paym_avg_1_2_all_diff'] = (\n",
    "            df['enc_paym_avg_1_all'] - \n",
    "            df['enc_paym_avg_2_all']\n",
    "    )\n",
    "\n",
    "    df['enc_paym_avg_0_years_diff'] = (\n",
    "            df['enc_paym_avg_0_this_year'] - \n",
    "            df['enc_paym_avg_0_last_year']\n",
    "    )\n",
    "    \n",
    "    print('new diff columns')\n",
    "    print('enc_paym_avg_0_1_this_year_diff')\n",
    "    print('enc_paym_avg_1_2_all_diff')\n",
    "    print('enc_paym_avg_0_years_diff')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3417c72d-5480-4485-bf36-277a44b44208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём SimpleImputer и настраиваем вывод в pandas DataFrame\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer.set_output(transform='pandas')\n",
    "\n",
    "# Создаём паплайн препроцессинга\n",
    "preprocessing_pipe = Pipeline([\n",
    "    ('to_numeric', FunctionTransformer(convert_all_to_numeric)),\n",
    "    ('imputer', imputer),\n",
    "    ('to_int', FunctionTransformer(lambda df: df.astype(int), validate=False)),\n",
    "    ('drop_duplicates', FunctionTransformer(lambda df: df.drop_duplicates(), validate=False))\n",
    "])\n",
    "\n",
    "# Создаём основной пайплайн\n",
    "main_pipe = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            'preprocessing',\n",
    "            preprocessing_pipe\n",
    "        ),\n",
    "        (\n",
    "            'create_rn_max_feature',\n",
    "            FunctionTransformer(create_rn_max_feature_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'enc_paym_transcoding', \n",
    "            FunctionTransformer(enc_paym_transcoding_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'create_definite_value_proportion_features',\n",
    "            FunctionTransformer(create_definite_value_proportion_features_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'create_sum_prop_1_feature',\n",
    "            FunctionTransformer(from_is_zero_prop_1_create_sum_prop_1_feature_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'create_mean_value_frequency_feature',\n",
    "            FunctionTransformer(create_mean_value_frequency_feature_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'from_enc_paym_create_normalized_group_sum_features_then_diff_features',\n",
    "            FunctionTransformer(enc_paym_norm_group_sum_diff_pipeline)\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "99d1afe4-f789-4558-a0f0-f00e32d4ac0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION create_rn_max_feature \n",
      "FUNCTION enc_paym_transcoding \n",
      "FUNCTION create_definite_value_proportion_features \n",
      "Исходный признак enc_loans_account_holder_type\n",
      "Новые фичи\n",
      "enc_loans_account_holder_type_prop_4\n",
      "Исходный признак pre_pterm\n",
      "Новые фичи\n",
      "pre_pterm_prop_6\n",
      "pre_pterm_prop_3\n",
      "Исходный признак is_zero_loans530\n",
      "Новые фичи\n",
      "is_zero_loans530_prop_1\n",
      "Исходный признак enc_paym_0\n",
      "Новые фичи\n",
      "enc_paym_0_prop_1\n",
      "Исходный признак pre_loans_credit_cost_rate\n",
      "Новые фичи\n",
      "pre_loans_credit_cost_rate_prop_6\n",
      "pre_loans_credit_cost_rate_prop_11\n",
      "pre_loans_credit_cost_rate_prop_4\n",
      "Исходный признак pre_loans_next_pay_summ\n",
      "Новые фичи\n",
      "pre_loans_next_pay_summ_prop_5\n",
      "pre_loans_next_pay_summ_prop_0\n",
      "Исходный признак is_zero_over2limit\n",
      "Новые фичи\n",
      "is_zero_over2limit_prop_1\n",
      "Исходный признак pre_loans_outstanding\n",
      "Новые фичи\n",
      "pre_loans_outstanding_prop_1\n",
      "pre_loans_outstanding_prop_5\n",
      "Исходный признак pre_util\n",
      "Новые фичи\n",
      "pre_util_prop_3\n",
      "pre_util_prop_6\n",
      "Исходный признак pre_till_pclose\n",
      "Новые фичи\n",
      "pre_till_pclose_prop_10\n",
      "pre_till_pclose_prop_7\n",
      "Исходный признак is_zero_loans5\n",
      "Новые фичи\n",
      "is_zero_loans5_prop_1\n",
      "Исходный признак pre_since_confirmed\n",
      "Новые фичи\n",
      "pre_since_confirmed_prop_4\n",
      "pre_since_confirmed_prop_7\n",
      "Исходный признак pre_loans_credit_limit\n",
      "Новые фичи\n",
      "pre_loans_credit_limit_prop_2\n",
      "pre_loans_credit_limit_prop_15\n",
      "pre_loans_credit_limit_prop_18\n",
      "Исходный признак pre_over2limit\n",
      "Новые фичи\n",
      "pre_over2limit_prop_17\n",
      "Исходный признак pre_till_fclose\n",
      "Новые фичи\n",
      "pre_till_fclose_prop_4\n",
      "pre_till_fclose_prop_3\n",
      "pre_till_fclose_prop_1\n",
      "Исходный признак enc_loans_credit_status\n",
      "Новые фичи\n",
      "enc_loans_credit_status_prop_5\n",
      "Исходный признак pre_since_opened\n",
      "Новые фичи\n",
      "pre_since_opened_prop_12\n",
      "pre_since_opened_prop_8\n",
      "pre_since_opened_prop_19\n",
      "Исходный признак enc_paym_24\n",
      "Новые фичи\n",
      "enc_paym_24_prop_1\n",
      "Исходный признак pre_loans_max_overdue_sum\n",
      "Новые фичи\n",
      "pre_loans_max_overdue_sum_prop_1\n",
      "Исходный признак enc_loans_credit_type\n",
      "Новые фичи\n",
      "enc_loans_credit_type_prop_0\n",
      "enc_loans_credit_type_prop_2\n",
      "Исходный признак pre_fterm\n",
      "Новые фичи\n",
      "pre_fterm_prop_7\n",
      "pre_fterm_prop_3\n",
      "Исходный признак is_zero_loans3060\n",
      "Новые фичи\n",
      "is_zero_loans3060_prop_1\n",
      "Исходный признак is_zero_loans6090\n",
      "Новые фичи\n",
      "is_zero_loans6090_prop_1\n",
      "Исходный признак is_zero_loans90\n",
      "Новые фичи\n",
      "is_zero_loans90_prop_1\n",
      "FUNCTION of_is_zero_prop_1_create_sum_prop_1_feature \n",
      "FUNCTION create_mean_value_frequency_feature \n",
      "new_column pre_util_mean_freq\n",
      "new_column pre_loans_credit_limit_mean_freq\n",
      "new_column pre_since_opened_mean_freq\n",
      "new_column pre_loans_credit_cost_rate_mean_freq\n",
      "new_column enc_loans_credit_type_mean_freq\n",
      "new_column pre_loans_next_pay_summ_mean_freq\n",
      "new_column pre_since_confirmed_mean_freq\n",
      "new_column pre_pterm_mean_freq\n",
      "new_column enc_paym_0_mean_freq\n",
      "new_column enc_loans_account_holder_type_mean_freq\n",
      "new_column pre_loans530_mean_freq\n",
      "new_column enc_paym_8_mean_freq\n",
      "new_column pre_loans5_mean_freq\n",
      "new_column enc_paym_10_mean_freq\n",
      "new_column enc_loans_account_cur_mean_freq\n",
      "new_column enc_paym_9_mean_freq\n",
      "FUNCTION enc_paym_norm_group_sum_diff_pipeline \n",
      "new_column enc_paym_avg_1_all\n",
      "new_column enc_paym_avg_2_all\n",
      "new_column enc_paym_avg_0_this_year\n",
      "new_column enc_paym_avg_1_this_year\n",
      "new_column enc_paym_avg_0_last_year\n",
      "new diff columns\n",
      "enc_paym_avg_0_1_this_year_diff\n",
      "enc_paym_avg_1_2_all_diff\n",
      "enc_paym_avg_0_years_diff\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_pterm</th>\n",
       "      <th>pre_fterm</th>\n",
       "      <th>pre_till_pclose</th>\n",
       "      <th>pre_till_fclose</th>\n",
       "      <th>pre_loans_credit_limit</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>...</th>\n",
       "      <th>enc_loans_account_cur_mean_freq</th>\n",
       "      <th>enc_paym_9_mean_freq</th>\n",
       "      <th>enc_paym_avg_1_all</th>\n",
       "      <th>enc_paym_avg_2_all</th>\n",
       "      <th>enc_paym_avg_0_this_year</th>\n",
       "      <th>enc_paym_avg_1_this_year</th>\n",
       "      <th>enc_paym_avg_0_last_year</th>\n",
       "      <th>enc_paym_avg_0_1_this_year_diff</th>\n",
       "      <th>enc_paym_avg_1_2_all_diff</th>\n",
       "      <th>enc_paym_avg_0_years_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1506130</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.5030</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1506130</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.5030</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1506130</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.5030</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1506130</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.5030</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1506130</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.5030</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>348416</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2451179</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.5030</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2451179</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.5030</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2451179</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.5030</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2451179</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.5030</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  rn  pre_since_opened  pre_since_confirmed  pre_pterm  pre_fterm  \\\n",
       "0    1506130   1                10                    6          1         16   \n",
       "1    1506130   2                10                    6          4         13   \n",
       "2    1506130   3                 5                    9         17          8   \n",
       "3    1506130   4                11                    1         15          9   \n",
       "4    1506130   5                 1                    9         15          8   \n",
       "..       ...  ..               ...                  ...        ...        ...   \n",
       "995   348416   4                 7                    0         16          8   \n",
       "996  2451179   1                16                    7          4          8   \n",
       "997  2451179   2                15                    4          4          8   \n",
       "998  2451179   3                15                   12         12         16   \n",
       "999  2451179   4                15                   11          0          7   \n",
       "\n",
       "     pre_till_pclose  pre_till_fclose  pre_loans_credit_limit  \\\n",
       "0                  3                5                       0   \n",
       "1                  1                7                      15   \n",
       "2                  1               11                      15   \n",
       "3                  2                6                       2   \n",
       "4                  1               11                       2   \n",
       "..               ...              ...                     ...   \n",
       "995               12               11                      16   \n",
       "996                1               11                       4   \n",
       "997                1               11                       4   \n",
       "998                9               13                       2   \n",
       "999               16                7                      15   \n",
       "\n",
       "     pre_loans_next_pay_summ  ...  enc_loans_account_cur_mean_freq  \\\n",
       "0                          5  ...                            0.995   \n",
       "1                          5  ...                            0.995   \n",
       "2                          2  ...                            0.995   \n",
       "3                          2  ...                            0.995   \n",
       "4                          5  ...                            0.995   \n",
       "..                       ...  ...                              ...   \n",
       "995                        2  ...                            0.995   \n",
       "996                        2  ...                            0.995   \n",
       "997                        2  ...                            0.995   \n",
       "998                        2  ...                            0.995   \n",
       "999                        2  ...                            0.995   \n",
       "\n",
       "     enc_paym_9_mean_freq  enc_paym_avg_1_all  enc_paym_avg_2_all  \\\n",
       "0                  0.5030                0.20                0.00   \n",
       "1                  0.5030                0.20                0.00   \n",
       "2                  0.5030                0.20                0.00   \n",
       "3                  0.5030                0.20                0.00   \n",
       "4                  0.5030                0.20                0.00   \n",
       "..                    ...                 ...                 ...   \n",
       "995                0.4805                3.00                0.25   \n",
       "996                0.5030                0.25                0.00   \n",
       "997                0.5030                0.25                0.00   \n",
       "998                0.5030                0.25                0.00   \n",
       "999                0.5030                0.25                0.00   \n",
       "\n",
       "     enc_paym_avg_0_this_year  enc_paym_avg_1_this_year  \\\n",
       "0                        11.8                       0.2   \n",
       "1                        11.8                       0.2   \n",
       "2                        11.8                       0.2   \n",
       "3                        11.8                       0.2   \n",
       "4                        11.8                       0.2   \n",
       "..                        ...                       ...   \n",
       "995                       6.0                       2.0   \n",
       "996                      12.0                       0.0   \n",
       "997                      12.0                       0.0   \n",
       "998                      12.0                       0.0   \n",
       "999                      12.0                       0.0   \n",
       "\n",
       "     enc_paym_avg_0_last_year  enc_paym_avg_0_1_this_year_diff  \\\n",
       "0                         7.6                             11.6   \n",
       "1                         7.6                             11.6   \n",
       "2                         7.6                             11.6   \n",
       "3                         7.6                             11.6   \n",
       "4                         7.6                             11.6   \n",
       "..                        ...                              ...   \n",
       "995                       5.5                              4.0   \n",
       "996                      12.0                             12.0   \n",
       "997                      12.0                             12.0   \n",
       "998                      12.0                             12.0   \n",
       "999                      12.0                             12.0   \n",
       "\n",
       "     enc_paym_avg_1_2_all_diff  enc_paym_avg_0_years_diff  \n",
       "0                         0.20                        4.2  \n",
       "1                         0.20                        4.2  \n",
       "2                         0.20                        4.2  \n",
       "3                         0.20                        4.2  \n",
       "4                         0.20                        4.2  \n",
       "..                         ...                        ...  \n",
       "995                       2.75                        0.5  \n",
       "996                       0.25                        0.0  \n",
       "997                       0.25                        0.0  \n",
       "998                       0.25                        0.0  \n",
       "999                       0.25                        0.0  \n",
       "\n",
       "[1000 rows x 118 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Трансформируем часть train датасета\n",
    "X_train_short = main_pipe.fit_transform(X_train_short)\n",
    "X_train_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5a8b700b-c1ba-4788-9d0b-47118dddb58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION create_rn_max_feature \n",
      "FUNCTION enc_paym_transcoding \n",
      "FUNCTION create_definite_value_proportion_features \n",
      "Исходный признак enc_loans_account_holder_type\n",
      "Новые фичи\n",
      "enc_loans_account_holder_type_prop_4\n",
      "Исходный признак pre_pterm\n",
      "Новые фичи\n",
      "pre_pterm_prop_6\n",
      "pre_pterm_prop_3\n",
      "Исходный признак is_zero_loans530\n",
      "Новые фичи\n",
      "is_zero_loans530_prop_1\n",
      "Исходный признак enc_paym_0\n",
      "Новые фичи\n",
      "enc_paym_0_prop_1\n",
      "Исходный признак pre_loans_credit_cost_rate\n",
      "Новые фичи\n",
      "pre_loans_credit_cost_rate_prop_6\n",
      "pre_loans_credit_cost_rate_prop_11\n",
      "pre_loans_credit_cost_rate_prop_4\n",
      "Исходный признак pre_loans_next_pay_summ\n",
      "Новые фичи\n",
      "pre_loans_next_pay_summ_prop_5\n",
      "pre_loans_next_pay_summ_prop_0\n",
      "Исходный признак is_zero_over2limit\n",
      "Новые фичи\n",
      "is_zero_over2limit_prop_1\n",
      "Исходный признак pre_loans_outstanding\n",
      "Новые фичи\n",
      "pre_loans_outstanding_prop_1\n",
      "pre_loans_outstanding_prop_5\n",
      "Исходный признак pre_util\n",
      "Новые фичи\n",
      "pre_util_prop_3\n",
      "pre_util_prop_6\n",
      "Исходный признак pre_till_pclose\n",
      "Новые фичи\n",
      "pre_till_pclose_prop_10\n",
      "pre_till_pclose_prop_7\n",
      "Исходный признак is_zero_loans5\n",
      "Новые фичи\n",
      "is_zero_loans5_prop_1\n",
      "Исходный признак pre_since_confirmed\n",
      "Новые фичи\n",
      "pre_since_confirmed_prop_4\n",
      "pre_since_confirmed_prop_7\n",
      "Исходный признак pre_loans_credit_limit\n",
      "Новые фичи\n",
      "pre_loans_credit_limit_prop_2\n",
      "pre_loans_credit_limit_prop_15\n",
      "pre_loans_credit_limit_prop_18\n",
      "Исходный признак pre_over2limit\n",
      "Новые фичи\n",
      "pre_over2limit_prop_17\n",
      "Исходный признак pre_till_fclose\n",
      "Новые фичи\n",
      "pre_till_fclose_prop_4\n",
      "pre_till_fclose_prop_3\n",
      "pre_till_fclose_prop_1\n",
      "Исходный признак enc_loans_credit_status\n",
      "Новые фичи\n",
      "enc_loans_credit_status_prop_5\n",
      "Исходный признак pre_since_opened\n",
      "Новые фичи\n",
      "pre_since_opened_prop_12\n",
      "pre_since_opened_prop_8\n",
      "pre_since_opened_prop_19\n",
      "Исходный признак enc_paym_24\n",
      "Новые фичи\n",
      "enc_paym_24_prop_1\n",
      "Исходный признак pre_loans_max_overdue_sum\n",
      "Новые фичи\n",
      "pre_loans_max_overdue_sum_prop_1\n",
      "Исходный признак enc_loans_credit_type\n",
      "Новые фичи\n",
      "enc_loans_credit_type_prop_0\n",
      "enc_loans_credit_type_prop_2\n",
      "Исходный признак pre_fterm\n",
      "Новые фичи\n",
      "pre_fterm_prop_7\n",
      "pre_fterm_prop_3\n",
      "Исходный признак is_zero_loans3060\n",
      "Новые фичи\n",
      "is_zero_loans3060_prop_1\n",
      "Исходный признак is_zero_loans6090\n",
      "Новые фичи\n",
      "is_zero_loans6090_prop_1\n",
      "Исходный признак is_zero_loans90\n",
      "Новые фичи\n",
      "is_zero_loans90_prop_1\n",
      "FUNCTION of_is_zero_prop_1_create_sum_prop_1_feature \n",
      "FUNCTION create_mean_value_frequency_feature \n",
      "new_column pre_util_mean_freq\n",
      "new_column pre_loans_credit_limit_mean_freq\n",
      "new_column pre_since_opened_mean_freq\n",
      "new_column pre_loans_credit_cost_rate_mean_freq\n",
      "new_column enc_loans_credit_type_mean_freq\n",
      "new_column pre_loans_next_pay_summ_mean_freq\n",
      "new_column pre_since_confirmed_mean_freq\n",
      "new_column pre_pterm_mean_freq\n",
      "new_column enc_paym_0_mean_freq\n",
      "new_column enc_loans_account_holder_type_mean_freq\n",
      "new_column pre_loans530_mean_freq\n",
      "new_column enc_paym_8_mean_freq\n",
      "new_column pre_loans5_mean_freq\n",
      "new_column enc_paym_10_mean_freq\n",
      "new_column enc_loans_account_cur_mean_freq\n",
      "new_column enc_paym_9_mean_freq\n",
      "FUNCTION enc_paym_norm_group_sum_diff_pipeline \n",
      "new_column enc_paym_avg_1_all\n",
      "new_column enc_paym_avg_2_all\n",
      "new_column enc_paym_avg_0_this_year\n",
      "new_column enc_paym_avg_1_this_year\n",
      "new_column enc_paym_avg_0_last_year\n",
      "new diff columns\n",
      "enc_paym_avg_0_1_this_year_diff\n",
      "enc_paym_avg_1_2_all_diff\n",
      "enc_paym_avg_0_years_diff\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_pterm</th>\n",
       "      <th>pre_fterm</th>\n",
       "      <th>pre_till_pclose</th>\n",
       "      <th>pre_till_fclose</th>\n",
       "      <th>pre_loans_credit_limit</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>...</th>\n",
       "      <th>enc_loans_account_cur_mean_freq</th>\n",
       "      <th>enc_paym_9_mean_freq</th>\n",
       "      <th>enc_paym_avg_1_all</th>\n",
       "      <th>enc_paym_avg_2_all</th>\n",
       "      <th>enc_paym_avg_0_this_year</th>\n",
       "      <th>enc_paym_avg_1_this_year</th>\n",
       "      <th>enc_paym_avg_0_last_year</th>\n",
       "      <th>enc_paym_avg_0_1_this_year_diff</th>\n",
       "      <th>enc_paym_avg_1_2_all_diff</th>\n",
       "      <th>enc_paym_avg_0_years_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1675248</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>0.492167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1675248</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>0.492167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675248</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>0.492167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1675248</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>0.492167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1675248</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>0.492167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5231236</th>\n",
       "      <td>2860085</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>0.402305</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5231237</th>\n",
       "      <td>2860085</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>0.402305</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5231238</th>\n",
       "      <td>2860085</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>0.402305</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5231239</th>\n",
       "      <td>2860085</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>0.402305</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5231240</th>\n",
       "      <td>2860085</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>0.402305</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5231241 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  rn  pre_since_opened  pre_since_confirmed  pre_pterm  \\\n",
       "0        1675248   1                14                   14          6   \n",
       "1        1675248   2                13                   12         14   \n",
       "2        1675248   3                 6                    8          2   \n",
       "3        1675248   4                 6                   16          6   \n",
       "4        1675248   5                 6                    3          0   \n",
       "...          ...  ..               ...                  ...        ...   \n",
       "5231236  2860085   2                 8                    7         13   \n",
       "5231237  2860085   3                14                    3         15   \n",
       "5231238  2860085   4                11                   10         11   \n",
       "5231239  2860085   5                 9                    5          3   \n",
       "5231240  2860085   6                19                    6         14   \n",
       "\n",
       "         pre_fterm  pre_till_pclose  pre_till_fclose  pre_loans_credit_limit  \\\n",
       "0                8                0               11                       2   \n",
       "1                7                2                6                      15   \n",
       "2               14                5                7                      11   \n",
       "3                8                0               11                       2   \n",
       "4               13               14               14                       4   \n",
       "...            ...              ...              ...                     ...   \n",
       "5231236          0                9                1                       3   \n",
       "5231237          8                6               11                       8   \n",
       "5231238         16                8                8                      16   \n",
       "5231239          5                2               15                       6   \n",
       "5231240          7               10                4                      11   \n",
       "\n",
       "         pre_loans_next_pay_summ  ...  enc_loans_account_cur_mean_freq  \\\n",
       "0                              2  ...                         0.997625   \n",
       "1                              2  ...                         0.997625   \n",
       "2                              2  ...                         0.997625   \n",
       "3                              5  ...                         0.997625   \n",
       "4                              2  ...                         0.997625   \n",
       "...                          ...  ...                              ...   \n",
       "5231236                        2  ...                         0.997625   \n",
       "5231237                        1  ...                         0.997625   \n",
       "5231238                        1  ...                         0.997625   \n",
       "5231239                        2  ...                         0.997625   \n",
       "5231240                        2  ...                         0.997625   \n",
       "\n",
       "         enc_paym_9_mean_freq  enc_paym_avg_1_all  enc_paym_avg_2_all  \\\n",
       "0                    0.492167            0.000000            0.000000   \n",
       "1                    0.492167            0.000000            0.000000   \n",
       "2                    0.492167            0.000000            0.000000   \n",
       "3                    0.492167            0.000000            0.000000   \n",
       "4                    0.492167            0.000000            0.000000   \n",
       "...                       ...                 ...                 ...   \n",
       "5231236              0.402305            1.666667            0.333333   \n",
       "5231237              0.402305            1.666667            0.333333   \n",
       "5231238              0.402305            1.666667            0.333333   \n",
       "5231239              0.402305            1.666667            0.333333   \n",
       "5231240              0.402305            1.666667            0.333333   \n",
       "\n",
       "         enc_paym_avg_0_this_year  enc_paym_avg_1_this_year  \\\n",
       "0                       11.000000                  0.000000   \n",
       "1                       11.000000                  0.000000   \n",
       "2                       11.000000                  0.000000   \n",
       "3                       11.000000                  0.000000   \n",
       "4                       11.000000                  0.000000   \n",
       "...                           ...                       ...   \n",
       "5231236                  4.333333                  1.333333   \n",
       "5231237                  4.333333                  1.333333   \n",
       "5231238                  4.333333                  1.333333   \n",
       "5231239                  4.333333                  1.333333   \n",
       "5231240                  4.333333                  1.333333   \n",
       "\n",
       "         enc_paym_avg_0_last_year  enc_paym_avg_0_1_this_year_diff  \\\n",
       "0                        8.000000                             11.0   \n",
       "1                        8.000000                             11.0   \n",
       "2                        8.000000                             11.0   \n",
       "3                        8.000000                             11.0   \n",
       "4                        8.000000                             11.0   \n",
       "...                           ...                              ...   \n",
       "5231236                  2.833333                              3.0   \n",
       "5231237                  2.833333                              3.0   \n",
       "5231238                  2.833333                              3.0   \n",
       "5231239                  2.833333                              3.0   \n",
       "5231240                  2.833333                              3.0   \n",
       "\n",
       "         enc_paym_avg_1_2_all_diff  enc_paym_avg_0_years_diff  \n",
       "0                         0.000000                        3.0  \n",
       "1                         0.000000                        3.0  \n",
       "2                         0.000000                        3.0  \n",
       "3                         0.000000                        3.0  \n",
       "4                         0.000000                        3.0  \n",
       "...                            ...                        ...  \n",
       "5231236                   1.333333                        1.5  \n",
       "5231237                   1.333333                        1.5  \n",
       "5231238                   1.333333                        1.5  \n",
       "5231239                   1.333333                        1.5  \n",
       "5231240                   1.333333                        1.5  \n",
       "\n",
       "[5231241 rows x 118 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Трансформируем весь test датасет\n",
    "X_test_full = main_pipe.fit_transform(X_test_full)\n",
    "X_test_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473af5b0-b834-4ac5-84af-88168a96c527",
   "metadata": {},
   "source": [
    "git commit -m 'Create enc_paym_norm_group_sum_diff_pipeline feature'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
