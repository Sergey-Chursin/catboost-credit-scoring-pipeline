{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc7f2eb-e995-4512-9e68-06681dc26b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695f7092-6790-43f7-9177-1e2d4ea6ddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём внутреннюю папку проекта\n",
    "os.makedirs('pipeline', exist_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a991711a-05f4-4b8a-a3bc-11faa01c8919",
   "metadata": {},
   "source": [
    "# Lists of features for the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda82a61-1a8a-4f84-b873-d53bed7ab196",
   "metadata": {},
   "source": [
    "## Basic lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd86d03c-70ae-4b3c-8a89-abb51550015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rn - уникальный признак\n",
    "\n",
    "# Бинаризированные\n",
    "pre_features = [\n",
    "    'pre_since_opened',\n",
    "    'pre_since_confirmed',\n",
    "    'pre_pterm',\n",
    "    'pre_fterm',\n",
    "    'pre_till_pclose',\n",
    "    'pre_till_fclose',\n",
    "    'pre_loans_credit_limit',\n",
    "    'pre_loans_next_pay_summ',\n",
    "    'pre_loans_outstanding',\n",
    "    'pre_loans_max_overdue_sum',\n",
    "    'pre_loans_credit_cost_rate',\n",
    "    'pre_loans5',\n",
    "    'pre_loans530',\n",
    "    'pre_loans3060',\n",
    "    'pre_loans6090',\n",
    "    'pre_loans90',\n",
    "    'pre_util',\n",
    "    'pre_over2limit',\n",
    "    'pre_maxover2limit'\n",
    "]\n",
    "\n",
    "# Закодированные\n",
    "enc_features = [\n",
    "    'enc_loans_account_holder_type',\n",
    "    'enc_loans_credit_status',\n",
    "    'enc_loans_credit_type',\n",
    "    'enc_loans_account_cur'\n",
    "]\n",
    "\n",
    "# Статусы ежемесячных платежей\n",
    "enc_paym_features = [\n",
    "    'enc_paym_0',\n",
    "    'enc_paym_1',\n",
    "    'enc_paym_2',\n",
    "    'enc_paym_3',\n",
    "    'enc_paym_4',\n",
    "    'enc_paym_5',\n",
    "    'enc_paym_6',\n",
    "    'enc_paym_7',\n",
    "    'enc_paym_8',\n",
    "    'enc_paym_9',\n",
    "    'enc_paym_10',\n",
    "    'enc_paym_11',\n",
    "    'enc_paym_12',\n",
    "    'enc_paym_13',\n",
    "    'enc_paym_14',\n",
    "    'enc_paym_15',\n",
    "    'enc_paym_16',\n",
    "    'enc_paym_17',\n",
    "    'enc_paym_18',\n",
    "    'enc_paym_19',\n",
    "    'enc_paym_20',\n",
    "    'enc_paym_21',\n",
    "    'enc_paym_22',\n",
    "    'enc_paym_23',\n",
    "    'enc_paym_24'\n",
    "]\n",
    "\n",
    "#  Флаги\n",
    "flag_features = [\n",
    "    'is_zero_loans5',\n",
    "    'is_zero_loans530',\n",
    "    'is_zero_loans3060',\n",
    "    'is_zero_loans6090',\n",
    "    'is_zero_loans90',\n",
    "    'is_zero_util',\n",
    "    'is_zero_over2limit',\n",
    "    'is_zero_maxover2limit',\n",
    "    'pclose_flag',\n",
    "    'fclose_flag'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1809be45-ffa0-479d-ab99-ed02a40fd67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20931476, 61)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source = pd.read_csv('prepared_data/source_data_train_1.csv')\n",
    "df_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd5991d-f0bb-4517-a2cd-36620a1315c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400000, 61)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.read_csv('prepared_data/cut_corr_imp_train.csv')\n",
    "df_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bf0aa41-c0dd-4ed2-8534-66510b827c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'rn',\n",
       " 'pre_since_opened',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'pre_fterm',\n",
       " 'pre_till_pclose',\n",
       " 'pre_till_fclose',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_loans_next_pay_summ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source_columns = df_source.columns.tolist()\n",
    "df_source_columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cd7d089-961c-4f50-8027-fa8d06f64510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'flag',\n",
       " 'is_zero_sum_prop_1',\n",
       " 'enc_paym_avg_0_1_this_year_diff',\n",
       " 'pre_util_prop_3',\n",
       " 'enc_loans_credit_type_prop_0',\n",
       " 'pre_till_pclose_prop_10',\n",
       " 'pre_util_prop_6',\n",
       " 'pre_loans_outstanding_prop_1',\n",
       " 'pre_util_mean_freq']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_columns = df_result.columns.tolist()\n",
    "df_result_columns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28d7a8-c441-4630-9174-d5e2086a0c19",
   "metadata": {},
   "source": [
    "## List of features to download from the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbf36f36-3bbf-4834-9a5d-f23dd1d5f796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pre_loans_total_overdue',\n",
       " 'pre_loans3060',\n",
       " 'pre_loans6090',\n",
       " 'pre_loans90',\n",
       " 'is_zero_loans3060',\n",
       " 'is_zero_loans6090',\n",
       " 'is_zero_loans90',\n",
       " 'pre_maxover2limit',\n",
       " 'is_zero_util',\n",
       " 'is_zero_maxover2limit',\n",
       " 'enc_paym_3',\n",
       " 'enc_paym_4',\n",
       " 'enc_paym_5',\n",
       " 'enc_paym_6',\n",
       " 'enc_paym_7',\n",
       " 'enc_paym_11',\n",
       " 'enc_paym_12',\n",
       " 'enc_paym_13',\n",
       " 'enc_paym_14',\n",
       " 'enc_paym_15',\n",
       " 'enc_paym_16',\n",
       " 'enc_paym_17',\n",
       " 'enc_paym_18',\n",
       " 'enc_paym_19',\n",
       " 'enc_paym_20',\n",
       " 'enc_paym_21',\n",
       " 'enc_paym_22',\n",
       " 'enc_paym_23',\n",
       " 'pclose_flag',\n",
       " 'fclose_flag']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Формируем список колонок из df_source_columns,\n",
    "которые НЕ встречаются ни в одном названии из df_result_columns как подстрока.\n",
    "\"\"\"\n",
    "drop_list = []\n",
    "for col_source in df_source_columns:\n",
    "    found = False\n",
    "    for col_result in df_result_columns:\n",
    "        if col_source in col_result:\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        drop_list.append(col_source)\n",
    "\n",
    "print(len(drop_list))\n",
    "drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd47bf9-694c-4bfd-acec-fa2ae3ab047f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'rn',\n",
       " 'pre_since_opened',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'pre_fterm',\n",
       " 'pre_till_pclose',\n",
       " 'pre_till_fclose',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_loans_next_pay_summ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_columns = [x for x in df_source_columns if x not in drop_list]\n",
    "\n",
    "print(len(needed_columns))\n",
    "needed_columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84483ca2-71ed-41d2-b503-624f146a9458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'rn',\n",
       " 'pre_since_opened',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'pre_fterm',\n",
       " 'pre_till_pclose',\n",
       " 'pre_till_fclose',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_loans_next_pay_summ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Добавим недостающие признаки из групп flag_features и enc_paym _features, \n",
    "для правильной работы функций обрабатывающих эти группы. \n",
    "\"\"\"\n",
    "features_list= [\n",
    "    'is_zero_loans3060',\n",
    "    'is_zero_loans6090',\n",
    "    'is_zero_loans90',\n",
    "    'enc_paym_3',\n",
    "    'enc_paym_4',\n",
    "    'enc_paym_5',\n",
    "    'enc_paym_6',\n",
    "    'enc_paym_7',\n",
    "    'enc_paym_11',\n",
    "    'enc_paym_12',\n",
    "    'enc_paym_13',\n",
    "    'enc_paym_14',\n",
    "    'enc_paym_15',\n",
    "    'enc_paym_16',\n",
    "    'enc_paym_17',\n",
    "    'enc_paym_18',\n",
    "    'enc_paym_19',\n",
    "    'enc_paym_20',\n",
    "    'enc_paym_21',\n",
    "    'enc_paym_22',\n",
    "    'enc_paym_23'\n",
    "]\n",
    "\n",
    "# Список признаков для скачивания из исходного датасета\n",
    "needed_columns = needed_columns + features_list\n",
    "\n",
    "print(len(needed_columns))\n",
    "needed_columns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d67d7-625f-4cde-9d97-0a2905017239",
   "metadata": {},
   "source": [
    "## Create_definite_value_proportion_features_pipeline funtion list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8918094-ea0a-43db-99db-cd070b4b5bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['is_zero_sum_prop_1',\n",
       " 'pre_util_prop_3',\n",
       " 'enc_loans_credit_type_prop_0',\n",
       " 'pre_till_pclose_prop_10',\n",
       " 'pre_util_prop_6',\n",
       " 'pre_loans_outstanding_prop_1',\n",
       " 'pre_loans_credit_limit_prop_2',\n",
       " 'pre_loans_credit_cost_rate_prop_6',\n",
       " 'pre_loans_outstanding_prop_5',\n",
       " 'pre_loans_credit_cost_rate_prop_11',\n",
       " 'pre_loans_credit_cost_rate_prop_4',\n",
       " 'pre_loans_next_pay_summ_prop_5',\n",
       " 'pre_since_opened_prop_12',\n",
       " 'pre_loans_credit_limit_prop_15',\n",
       " 'enc_loans_credit_type_prop_2',\n",
       " 'pre_fterm_prop_7',\n",
       " 'enc_paym_0_prop_1',\n",
       " 'is_zero_over2limit_prop_1',\n",
       " 'pre_since_opened_prop_8',\n",
       " 'pre_loans_max_overdue_sum_prop_1',\n",
       " 'pre_loans_next_pay_summ_prop_0',\n",
       " 'pre_pterm_prop_6',\n",
       " 'pre_since_opened_prop_19',\n",
       " 'is_zero_loans5_prop_1',\n",
       " 'enc_loans_account_holder_type_prop_4',\n",
       " 'pre_loans_credit_limit_prop_18',\n",
       " 'pre_till_fclose_prop_4',\n",
       " 'pre_pterm_prop_3',\n",
       " 'is_zero_loans530_prop_1',\n",
       " 'enc_loans_credit_status_prop_5',\n",
       " 'pre_since_confirmed_prop_4',\n",
       " 'pre_fterm_prop_3',\n",
       " 'pre_till_fclose_prop_3',\n",
       " 'pre_till_fclose_prop_1',\n",
       " 'pre_till_pclose_prop_7',\n",
       " 'pre_since_confirmed_prop_7',\n",
       " 'enc_paym_24_prop_1',\n",
       " 'pre_over2limit_prop_17']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим список пропорциональных фичей в итоговом датасете\n",
    "prop_features_result_list = [col for col in df_result_columns if 'prop_' in col]\n",
    "\n",
    "print(len(prop_features_result_list))\n",
    "prop_features_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "864d11b8-b29a-4cf7-8e75-1c82fa30f7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['is_zero_over2limit',\n",
       " 'pre_till_fclose',\n",
       " 'is_zero_sum',\n",
       " 'pre_loans_credit_cost_rate',\n",
       " 'enc_paym_24',\n",
       " 'pre_loans_next_pay_summ',\n",
       " 'pre_till_pclose',\n",
       " 'pre_loans_outstanding',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_fterm',\n",
       " 'pre_util',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_since_opened',\n",
       " 'pre_loans_max_overdue_sum',\n",
       " 'enc_loans_credit_type',\n",
       " 'is_zero_loans5',\n",
       " 'enc_loans_account_holder_type',\n",
       " 'pre_over2limit',\n",
       " 'pre_pterm',\n",
       " 'enc_loans_credit_status',\n",
       " 'enc_paym_0',\n",
       " 'is_zero_loans530']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим список признаков исходного датасета из которых были сделаны пропорциональные фичи\n",
    "prop_features_source_list = list(\n",
    "    set(\n",
    "        [\n",
    "            re.sub(r'_prop.*$', '', col)\n",
    "            for col in prop_features_result_list\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(len(prop_features_source_list))\n",
    "prop_features_source_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c5e70c9-1efe-4c0d-ab60-9e90553339f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_zero_over2limit': [1],\n",
       " 'pre_till_fclose': [4, 3, 1],\n",
       " 'is_zero_sum': [1],\n",
       " 'pre_loans_credit_cost_rate': [6, 11, 4],\n",
       " 'enc_paym_24': [1],\n",
       " 'pre_loans_next_pay_summ': [5, 0],\n",
       " 'pre_till_pclose': [10, 7],\n",
       " 'pre_loans_outstanding': [1, 5],\n",
       " 'pre_since_confirmed': [4, 7],\n",
       " 'pre_fterm': [7, 3],\n",
       " 'pre_util': [3, 6],\n",
       " 'pre_loans_credit_limit': [2, 15, 18],\n",
       " 'pre_since_opened': [12, 8, 19],\n",
       " 'pre_loans_max_overdue_sum': [1],\n",
       " 'enc_loans_credit_type': [0, 2],\n",
       " 'is_zero_loans5': [1],\n",
       " 'enc_loans_account_holder_type': [4],\n",
       " 'pre_over2limit': [17],\n",
       " 'pre_pterm': [6, 3],\n",
       " 'enc_loans_credit_status': [5],\n",
       " 'enc_paym_0': [1],\n",
       " 'is_zero_loans530': [1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Соберем часть словаря пропорциональных фичей для пайплайна\n",
    "prop_features_dict = {}\n",
    "\n",
    "for source_col in prop_features_source_list:\n",
    "    # Инициализируем пустой список для каждого исходного признака\n",
    "    prop_features_dict[source_col] = []\n",
    "    # Создадим паттерн: имя col в начале и после него подчёркивание или конец строки\n",
    "    pattern = re.compile(r'^' + source_col + r'(_|$)')\n",
    "    for result_col in prop_features_result_list:\n",
    "        # Проверяем, совпадает ли имя признака с паттерном\n",
    "        if pattern.match(result_col):\n",
    "            # Ищем число в конце строки\n",
    "            match = re.search(r'(\\d+)$', result_col)\n",
    "            # Добавляем найденное число в список для данного source_col\n",
    "            prop_features_dict[source_col].append(int(match.group(1)))\n",
    "prop_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6776ea8b-4970-440c-b8ac-c93930ca9652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_zero_over2limit': [1],\n",
       " 'pre_till_fclose': [4, 3, 1],\n",
       " 'pre_loans_credit_cost_rate': [6, 11, 4],\n",
       " 'enc_paym_24': [1],\n",
       " 'pre_loans_next_pay_summ': [5, 0],\n",
       " 'pre_till_pclose': [10, 7],\n",
       " 'pre_loans_outstanding': [1, 5],\n",
       " 'pre_since_confirmed': [4, 7],\n",
       " 'pre_fterm': [7, 3],\n",
       " 'pre_util': [3, 6],\n",
       " 'pre_loans_credit_limit': [2, 15, 18],\n",
       " 'pre_since_opened': [12, 8, 19],\n",
       " 'pre_loans_max_overdue_sum': [1],\n",
       " 'enc_loans_credit_type': [0, 2],\n",
       " 'is_zero_loans5': [1],\n",
       " 'enc_loans_account_holder_type': [4],\n",
       " 'pre_over2limit': [17],\n",
       " 'pre_pterm': [6, 3],\n",
       " 'enc_loans_credit_status': [5],\n",
       " 'enc_paym_0': [1],\n",
       " 'is_zero_loans530': [1],\n",
       " 'is_zero_loans3060': [1],\n",
       " 'is_zero_loans6090': [1],\n",
       " 'is_zero_loans90': [1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Добавим в словарь недостающие is_zero_loans* для функции суммирования.\n",
    "Удалим is_zero_sum, фича is_zero_sum_prop_1 будет собираться другой функцией.\n",
    "\"\"\"\n",
    "is_zero_loans_list = [\n",
    "        'is_zero_loans5',\n",
    "        'is_zero_loans530',\n",
    "        'is_zero_loans3060',\n",
    "        'is_zero_loans6090',\n",
    "        'is_zero_loans90'\n",
    "    ]\n",
    "for col in is_zero_loans_list:\n",
    "    if col not in prop_features_dict.keys():\n",
    "        prop_features_dict[col] = [1]\n",
    "        \n",
    "del prop_features_dict['is_zero_sum']\n",
    "\n",
    "prop_features_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0a3e3f-a04f-4cb9-a28e-309b435f2cb2",
   "metadata": {},
   "source": [
    "## List for create_mean_value_frequency_feature_pipeline features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3344e24-9ffb-45ca-ab41-0f8e2ee01700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pre_util_mean_freq',\n",
       " 'pre_loans_credit_limit_mean_freq',\n",
       " 'pre_since_opened_mean_freq',\n",
       " 'pre_loans_credit_cost_rate_mean_freq',\n",
       " 'enc_loans_credit_type_mean_freq',\n",
       " 'pre_loans_next_pay_summ_mean_freq',\n",
       " 'pre_since_confirmed_mean_freq',\n",
       " 'pre_pterm_mean_freq',\n",
       " 'enc_paym_0_mean_freq',\n",
       " 'enc_loans_account_holder_type_mean_freq',\n",
       " 'pre_loans530_mean_freq',\n",
       " 'enc_paym_8_mean_freq',\n",
       " 'pre_loans5_mean_freq',\n",
       " 'enc_paym_10_mean_freq',\n",
       " 'enc_loans_account_cur_mean_freq',\n",
       " 'enc_paym_9_mean_freq']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Соберем список всех фичей средней частотности в итоговом датасете\n",
    "mean_freq_result_list = [col for col in df_result_columns if 'mean_freq' in col]\n",
    "\n",
    "print(len(mean_freq_result_list))\n",
    "mean_freq_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ec18ab2-0503-4a84-8dd3-78be3f1457f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pre_util',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_since_opened',\n",
       " 'pre_loans_credit_cost_rate',\n",
       " 'enc_loans_credit_type',\n",
       " 'pre_loans_next_pay_summ',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'enc_paym_0',\n",
       " 'enc_loans_account_holder_type',\n",
       " 'pre_loans530',\n",
       " 'enc_paym_8',\n",
       " 'pre_loans5',\n",
       " 'enc_paym_10',\n",
       " 'enc_loans_account_cur',\n",
       " 'enc_paym_9']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Соберем список признаков исходного датасета \n",
    "из которых были сделаны фичи средней частотности.\n",
    "\"\"\"\n",
    "mean_freq_source_list = [x[:-len('_mean_freq')] for x in mean_freq_result_list]\n",
    "print(len(mean_freq_source_list))\n",
    "mean_freq_source_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b72342-98ab-45a1-842d-96c6a2b3de50",
   "metadata": {},
   "source": [
    "## Drop list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52afd524-3819-4222-8fcb-e2f1bb21ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_features_list = [\n",
    "    'enc_paym_avg_1_all',\n",
    "    'enc_paym_avg_2_all',\n",
    "    'enc_paym_avg_0_this_year',\n",
    "    'enc_paym_avg_1_this_year',\n",
    "    'enc_paym_avg_0_last_year',\n",
    "    'is_zero_loans3060_prop_1',\n",
    "    'is_zero_loans6090_prop_1',\n",
    "    'is_zero_loans90_prop_1'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf48c49b-bd63-40eb-9a6f-32f1e9a96fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'rn',\n",
       " 'pre_since_opened',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'pre_fterm',\n",
       " 'pre_till_pclose',\n",
       " 'pre_till_fclose',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_loans_next_pay_summ',\n",
       " 'pre_loans_outstanding',\n",
       " 'pre_loans_max_overdue_sum',\n",
       " 'pre_loans_credit_cost_rate',\n",
       " 'pre_loans5',\n",
       " 'pre_loans530',\n",
       " 'is_zero_loans5',\n",
       " 'is_zero_loans530',\n",
       " 'pre_util',\n",
       " 'pre_over2limit',\n",
       " 'is_zero_over2limit',\n",
       " 'enc_paym_0',\n",
       " 'enc_paym_1',\n",
       " 'enc_paym_2',\n",
       " 'enc_paym_8',\n",
       " 'enc_paym_9',\n",
       " 'enc_paym_10',\n",
       " 'enc_paym_24',\n",
       " 'enc_loans_account_holder_type',\n",
       " 'enc_loans_credit_status',\n",
       " 'enc_loans_credit_type',\n",
       " 'enc_loans_account_cur',\n",
       " 'is_zero_loans3060',\n",
       " 'is_zero_loans6090',\n",
       " 'is_zero_loans90',\n",
       " 'enc_paym_3',\n",
       " 'enc_paym_4',\n",
       " 'enc_paym_5',\n",
       " 'enc_paym_6',\n",
       " 'enc_paym_7',\n",
       " 'enc_paym_11',\n",
       " 'enc_paym_12',\n",
       " 'enc_paym_13',\n",
       " 'enc_paym_14',\n",
       " 'enc_paym_15',\n",
       " 'enc_paym_16',\n",
       " 'enc_paym_17',\n",
       " 'enc_paym_18',\n",
       " 'enc_paym_19',\n",
       " 'enc_paym_20',\n",
       " 'enc_paym_21',\n",
       " 'enc_paym_22',\n",
       " 'enc_paym_23',\n",
       " 'enc_paym_avg_1_all',\n",
       " 'enc_paym_avg_2_all',\n",
       " 'enc_paym_avg_0_this_year',\n",
       " 'enc_paym_avg_1_this_year',\n",
       " 'enc_paym_avg_0_last_year',\n",
       " 'is_zero_loans3060_prop_1',\n",
       " 'is_zero_loans6090_prop_1',\n",
       " 'is_zero_loans90_prop_1']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_list = needed_columns + temporary_features_list\n",
    "print(len(drop_list))\n",
    "drop_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3774b5-4a4d-417c-972e-6f998596816f",
   "metadata": {},
   "source": [
    "# Downloading dataset and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf6d693b-65ab-4f66-b7fd-93020e230eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# СКАЧИВАЕМ ИСХОДНЫЙ ДАТАСЕТ\n",
    "\n",
    "def read_parquet_dataset_from_local(\n",
    "    path_to_dataset: str,\n",
    "    start_from: int = 0,\n",
    "    num_parts_to_read: int = 2,\n",
    "    columns: Optional[List[str]] = None,\n",
    "    verbose: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Читает num_parts_to_read партиций, преобразовывает их к pd.DataFrame и возвращает.\n",
    "\n",
    "    Args:\n",
    "        path_to_dataset : путь до директории с партициями\n",
    "        start_from : номер партиции, с которой нужно начать чтение\n",
    "        num_parts_to_read : количество партиций, которые требуется прочитать\n",
    "        columns : список колонок, которые нужно прочитать из партиции\n",
    "        verbose : выводить ли дополнительную информацию\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    dataset_paths = sorted(\n",
    "        os.path.join(path_to_dataset, filename)\n",
    "        for filename in os.listdir(path_to_dataset)\n",
    "        if filename.startswith('train')\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print('Dataset paths:')\n",
    "        for path in dataset_paths:\n",
    "            print(path)\n",
    "\n",
    "    start_from = max(0, start_from)\n",
    "    chunks = dataset_paths[start_from: start_from + num_parts_to_read]\n",
    "\n",
    "    if verbose:\n",
    "        print('Reading chunks:')\n",
    "        for chunk in chunks:\n",
    "            print(chunk)\n",
    "\n",
    "    for chunk_path in tqdm(chunks, desc=\"Reading dataset with pandas\"):\n",
    "        if verbose:\n",
    "            print('Reading chunk:', chunk_path)\n",
    "        chunk = pd.read_parquet(chunk_path, columns=columns)\n",
    "        res.append(chunk)\n",
    "\n",
    "    return pd.concat(res).reset_index(drop=True)\n",
    "\n",
    "def prepare_transactions_dataset(\n",
    "    path_to_dataset: str,\n",
    "    num_parts_to_preprocess_at_once: int = 1,\n",
    "    num_parts_total: int = 50,\n",
    "    save_to_path: str = None,\n",
    "    verbose: bool = False,\n",
    "    columns: Optional[List[str]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Возвращает исходный pd.DataFrame с признаками из которых нужно собрать\n",
    "    учебный датасет.\n",
    "\n",
    "    Args:\n",
    "        path_to_dataset : путь до датасета с партициями\n",
    "        num_parts_to_preprocess_at_once : количество партиций, \n",
    "            которые будут одновременно держаться и обрабатываться в памяти\n",
    "        num_parts_total : общее количество партиций, которые нужно обработать\n",
    "        save_to_path : путь до папки для сохранения обработанных блоков в .parquet-формате; \n",
    "            если None, сохранение не происходит\n",
    "        verbose : логировать каждую обрабатываемую часть данных\n",
    "        columns : список колонок, которые нужно оставить\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame : датафрейм с объединёнными данными\n",
    "    \"\"\"\n",
    "    preprocessed_frames = []\n",
    "\n",
    "    for step in tqdm(range(0, num_parts_total, num_parts_to_preprocess_at_once),\n",
    "                     desc=\"Transforming transactions data\"):\n",
    "        transactions_frame = read_parquet_dataset_from_local(\n",
    "            path_to_dataset,\n",
    "            start_from=step,\n",
    "            num_parts_to_read=num_parts_to_preprocess_at_once,\n",
    "            verbose=verbose,\n",
    "            columns=columns\n",
    "        )\n",
    "\n",
    "       # Записываем подготовленные данные в файл\n",
    "        if save_to_path:\n",
    "            block_as_str = str(step)\n",
    "            if len(block_as_str) == 1:\n",
    "                block_as_str = '00' + block_as_str\n",
    "            else:\n",
    "                block_as_str = '0' + block_as_str\n",
    "            transactions_frame.to_parquet(os.path.join(save_to_path, f'processed_chunk_{block_as_str}.parquet'))\n",
    "\n",
    "        preprocessed_frames.append(transactions_frame)\n",
    "    \n",
    "    return pd.concat(preprocessed_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "938b8752-54e0-415c-9c1a-5345f1fe9210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae1d224f3214005af6ab72ae3793f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transforming transactions data:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8c61730e7b4e2195a6a6b65301b770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40802a7b5e5d466085a6eddd436d791f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311ddff93fa543ca87df4d95a02ad04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6eeee97dfc4062be7bee4b87ce4d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7a4bdb152a43a3be0480a54555d7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a599c3ee2542218cdd27a7d90552f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67db9713379446d19ca18d8db25d3dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb9f26285c441d1b505a6285f9713d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c249bcffe34735bb98dd5b9abb1847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423ad73c53684442b6cba70d0d9c262d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05b14fcf69e44b9bdbe8fc5a0172ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc2076e9c294d89a79aeb52c126c9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((20931476, 52), (5231241, 52), (2400000,), (600000,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Собираем исходный датасет из parquet файлов,  \n",
    "скачиваем только необходимые колонки\n",
    "\"\"\"\n",
    "# Путь до данных в проекте\n",
    "path = 'train_data/'\n",
    "\n",
    "data = prepare_transactions_dataset(\n",
    "    path,\n",
    "    num_parts_to_preprocess_at_once=1,\n",
    "    num_parts_total=12,\n",
    "    save_to_path='train_data/',\n",
    "    columns=needed_columns) \n",
    "\n",
    "# Загружаем датасет с целевой переменной\n",
    "target = pd.read_csv('train_target.csv')\n",
    "\n",
    "# Делим датасет с целевой переменной на train/test части\n",
    "y_train, y_test  = train_test_split(target, train_size=0.8, random_state=0, stratify=target.flag)\n",
    "\n",
    "# Забираем наборы id из train/test\n",
    "train_id = y_train['id'].values\n",
    "test_id = y_test['id'].values\n",
    "\n",
    "# На основе наборов id делим исходный датасет на train/test части\n",
    "X_train = data.set_index('id').loc[train_id].reset_index()\n",
    "X_test = data.set_index('id').loc[test_id].reset_index()\n",
    "\n",
    "# Сбросим индексы для приведения к единому виду с X_train/X_test \n",
    "y_train = y_train.reset_index(drop=True)['flag']\n",
    "y_test = y_test.reset_index(drop=True)['flag']\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0392a984-602b-4c1a-a93f-17f0bba0c7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20931476, 52), (5231241, 52), (2400000,), (600000,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохраним разделённые данные\n",
    "X_train.to_csv('pipeline/X_train.csv', index=False)\n",
    "X_test.to_csv('pipeline/X_test.csv', index=False)\n",
    "y_train.to_csv('pipeline/y_train.csv', index=False)\n",
    "y_test.to_csv('pipeline/y_test.csv', index=False)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30275359-2d00-4740-bb33-b80e8f7ba866",
   "metadata": {},
   "source": [
    "# Hyperparameters and weights for ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4de04b0b-97a3-4d55-a307-607e2b256633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'verbose': 0,\n",
       "  'use_best_model': True,\n",
       "  'random_seed': 0,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'border_count': 113,\n",
       "  'min_data_in_leaf': 5,\n",
       "  'random_strength': 8.209932299,\n",
       "  'learning_rate': 0.03625476076,\n",
       "  'iterations': 3000,\n",
       "  'l2_leaf_reg': 8.005778243,\n",
       "  'boosting_type': 'Plain',\n",
       "  'od_wait': 100,\n",
       "  'depth': 4,\n",
       "  'subsample': 0.9882297325,\n",
       "  'bagging_temperature': 0.09710127579,\n",
       "  'rsm': 0.7343256008,\n",
       "  'eval_metric': 'AUC',\n",
       "  'loss_function': 'Logloss',\n",
       "  'auto_class_weights': 'Balanced'},\n",
       " {'verbose': 0,\n",
       "  'use_best_model': True,\n",
       "  'random_seed': 0,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'border_count': 113,\n",
       "  'min_data_in_leaf': 5,\n",
       "  'random_strength': 8.209932299,\n",
       "  'learning_rate': 0.03625476076,\n",
       "  'iterations': 3000,\n",
       "  'l2_leaf_reg': 8.005778243,\n",
       "  'boosting_type': 'Plain',\n",
       "  'od_wait': 100,\n",
       "  'depth': 4,\n",
       "  'subsample': 0.9882297325,\n",
       "  'bagging_temperature': 0.09710127579,\n",
       "  'rsm': 0.7343256008,\n",
       "  'eval_metric': 'AUC',\n",
       "  'loss_function': 'Logloss',\n",
       "  'auto_class_weights': 'Balanced'},\n",
       " {'verbose': 0,\n",
       "  'use_best_model': True,\n",
       "  'random_seed': 0,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'border_count': 113,\n",
       "  'min_data_in_leaf': 5,\n",
       "  'random_strength': 8.209932299,\n",
       "  'learning_rate': 0.03625476076,\n",
       "  'iterations': 3000,\n",
       "  'l2_leaf_reg': 8.005778243,\n",
       "  'boosting_type': 'Plain',\n",
       "  'od_wait': 100,\n",
       "  'depth': 4,\n",
       "  'subsample': 0.9882297325,\n",
       "  'bagging_temperature': 0.09710127579,\n",
       "  'rsm': 0.7343256008,\n",
       "  'eval_metric': 'AUC',\n",
       "  'loss_function': 'Logloss',\n",
       "  'auto_class_weights': 'Balanced'},\n",
       " {'verbose': 0,\n",
       "  'use_best_model': True,\n",
       "  'random_seed': 0,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'border_count': 113,\n",
       "  'min_data_in_leaf': 5,\n",
       "  'random_strength': 8.209932299,\n",
       "  'learning_rate': 0.03625476076,\n",
       "  'iterations': 3000,\n",
       "  'l2_leaf_reg': 8.005778243,\n",
       "  'boosting_type': 'Plain',\n",
       "  'od_wait': 100,\n",
       "  'depth': 4,\n",
       "  'subsample': 0.9882297325,\n",
       "  'bagging_temperature': 0.09710127579,\n",
       "  'rsm': 0.7343256008,\n",
       "  'eval_metric': 'AUC',\n",
       "  'loss_function': 'Logloss',\n",
       "  'auto_class_weights': 'Balanced'},\n",
       " {'verbose': 0,\n",
       "  'use_best_model': True,\n",
       "  'random_seed': 0,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'border_count': 113,\n",
       "  'min_data_in_leaf': 5,\n",
       "  'random_strength': 8.209932299,\n",
       "  'learning_rate': 0.03625476076,\n",
       "  'iterations': 3000,\n",
       "  'l2_leaf_reg': 8.005778243,\n",
       "  'boosting_type': 'Plain',\n",
       "  'od_wait': 100,\n",
       "  'depth': 4,\n",
       "  'subsample': 0.9882297325,\n",
       "  'bagging_temperature': 0.09710127579,\n",
       "  'rsm': 0.7343256008,\n",
       "  'eval_metric': 'AUC',\n",
       "  'loss_function': 'Logloss',\n",
       "  'auto_class_weights': 'Balanced'},\n",
       " {'iterations': 2996,\n",
       "  'learning_rate': 0.036254760756236626,\n",
       "  'depth': 4,\n",
       "  'l2_leaf_reg': 8.005778242558318,\n",
       "  'rsm': 0.7343256008238508,\n",
       "  'border_count': 113,\n",
       "  'random_seed': 0,\n",
       "  'verbose': False,\n",
       "  'auto_class_weights': 'Balanced',\n",
       "  'random_strength': 8.209932298658357,\n",
       "  'eval_metric': 'AUC',\n",
       "  'bagging_temperature': 0.09710127579306127,\n",
       "  'boosting_type': 'Plain',\n",
       "  'subsample': 0.9882297325066979,\n",
       "  'early_stopping_rounds': 100,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'min_data_in_leaf': 5}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Соберём список словарей с гиперпараметрами моделей\n",
    "params_list = []\n",
    "for i in range(5):\n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model(f'catboost_models/fold_{i}_сonservative_model.bin')\n",
    "    params_list.append(model.get_params())\n",
    "\n",
    "with open('catboost_models/best_сonservative_params.pkl', 'rb') as file:\n",
    "    final_model_params = pickle.load(file)\n",
    "    \n",
    "params_list.append(final_model_params['best_all_folds_params'])\n",
    "params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "030cda95-9d82-49ff-a878-adcfd4a3c301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7576036850511159,\n",
       " 0.7554545982995526,\n",
       " 0.7532810994057619,\n",
       " 0.7546988571803108,\n",
       " 0.7524269260453276,\n",
       " 0.7546930331964138]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Собираем список весов моделей\n",
    "with open('catboost_models/сonservative_models_weights.pkl', 'rb') as file:\n",
    "    weights_list = pickle.load(file)\n",
    "\n",
    "weights_list = weights_list['val_auc_list']\n",
    "weights_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd7962-3572-4930-99d7-c51655fe80de",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44231b7d-9226-4aad-a823-ffcbe7db8e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20931476, 52), (5231241, 52), (2400000, 1), (600000, 1))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем исходные разделённые данные \n",
    "X_train = pd.read_csv('pipeline/X_train.csv')\n",
    "X_test = pd.read_csv('pipeline/X_test.csv')\n",
    "y_train = pd.read_csv('pipeline/y_train.csv')\n",
    "y_test = pd.read_csv('pipeline/y_test.csv')\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2585a60f-ea6e-46d4-a562-c3662858e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING FUNCTIONS\n",
    "\n",
    "def convert_all_to_numeric_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Преобразует типы всех колоноки в числовые \n",
    "    с заменой ошибок на NaN (errors='coerce').\n",
    "\n",
    "    Args:\n",
    "        df : Исходный DataFrame, содержащий колонки 'id' и 'rn'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame : Копия исходного DataFrame \n",
    "        где все колонки приведены к числовому типу.\n",
    "    \"\"\"\n",
    "    print('FUNCTION convert_all_to_numeric_pipeline')\n",
    "    \n",
    "    # Копируем датасет чтобы не изменять оригинал.\n",
    "    df = df.copy()\n",
    "    \n",
    "    return df.apply(lambda col: pd.to_numeric(col, errors='coerce'))\n",
    "\n",
    "\n",
    "def convert_all_to_int_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Преобразует все колонки DataFrame к целочисленному типу.\n",
    "\n",
    "    Args:\n",
    "        df : Исходный DataFrame с числовыми значениями.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame : DataFrame, где все колонки приведены к типу int.\n",
    "    \"\"\"\n",
    "    print('FUNCTION convert_all_to_int_pipeline')\n",
    "    \n",
    "    return df.astype(int)\n",
    "\n",
    "def drop_duplicates_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Удаляет дубликаты строк из DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df : Исходный DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame : DataFrame без дублирующихся строк.\n",
    "    \"\"\"\n",
    "    \n",
    "    print('FUNCTION drop_duplicates_pipeline')\n",
    "    \n",
    "    return df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3290d14-eac0-4546-a36a-1c5e59851111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGENERING FUNCTIONS\n",
    "\n",
    "def rn_max_feature_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Добавляет в DataFrame новую колонку 'rn_max' — максимальное \n",
    "    значение 'rn' для каждой группы 'id'.\n",
    "\n",
    "    Args:\n",
    "        df : Исходный DataFrame, содержащий колонки 'id' и 'rn'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame : Копия исходного DataFrame с добавленной колонкой 'rn_max'.\n",
    "    \"\"\"\n",
    "    print('FUNCTION rn_max_feature_pipeline')\n",
    "\n",
    "    \"\"\"\n",
    "    Для каждой строки определяем максимальное значение 'rn' среди всех строк с тем же 'id'\n",
    "    Метод transform('max') возвращает Series длины исходного DataFrame, где для каждой строки\n",
    "    указано максимальное значение 'rn' в её группе 'id'.\n",
    "    \"\"\"\n",
    "    df['rn_max'] = df.groupby('id')['rn'].transform('max')\n",
    "\n",
    "    return df\n",
    "\n",
    "def enc_paym_transcoding_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Прекодирует признаки enc_paym_features к единому виду с диапазоном значений {0, 1, 2, 3}.\n",
    "    Для каждого столбца enc_paym_0, enc_paym_1, ..., enc_paym_24, \n",
    "    если в значениях встречается 4, происходит замена:\n",
    "        1 -> 0\n",
    "        2 -> 1\n",
    "        3 -> 2\n",
    "        4 -> 3\n",
    "\n",
    "    Args:\n",
    "        df : Исходный DataFrame с колонками 'enc_paym_0' ... 'enc_paym_24'.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame : Копия DataFrame с перекодированными признаками.\n",
    "    \"\"\"\n",
    "    print('FUNCTION enc_paym_transcoding_pipeline ')\n",
    "    \n",
    "    # Список колонок для перекодировки\n",
    "    columns = [f'enc_paym_{i}' for i in range(25)]\n",
    "    \n",
    "    for col in columns:\n",
    "        # Проверяем, есть ли значение 4 в колонке\n",
    "        if 4 in df[col].unique():\n",
    "            # Заменяем значения согласно маппингу\n",
    "            df.loc[:, col] = df[col].replace({1: 0, 2: 1, 3: 2, 4: 3})\n",
    "            \n",
    "    return df\n",
    "\n",
    "def definite_value_proportion_features_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Создаёт и добавляет в датафрейм новые частотные признаки \n",
    "    на основе заданных значений исходных признаков.\n",
    "    \n",
    "    Для каждого столбца и каждого указанного значения в словаре функция создаёт новые признаки, \n",
    "    отражающие долю записей с этим значением относительно общего количества \n",
    "    кредитов (rn_max) для каждого id.\n",
    "    \n",
    "    Args:\n",
    "        df : Исходный DataFrame, содержащий необходимые признаки и колонку 'rn_max'.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame : Копия исходного DataFrame с добавленными частотными признаками.\n",
    "    \"\"\"\n",
    "    print('FUNCTION definite_value_proportion_features_pipeline ')\n",
    "    \n",
    "    \"\"\"\n",
    "    Создадим словарь где для каждого признака перечислены значения,\n",
    "    по которым считаем долю.\n",
    "    \"\"\"\n",
    "    features_dictionary = {\n",
    "        'enc_loans_account_holder_type': [4],\n",
    "        'pre_pterm': [6, 3],\n",
    "        'is_zero_loans530': [1],\n",
    "        'enc_paym_0': [1],\n",
    "        'pre_loans_credit_cost_rate': [6, 11, 4],\n",
    "        'pre_loans_next_pay_summ': [5, 0],\n",
    "        'is_zero_over2limit': [1],\n",
    "        'pre_loans_outstanding': [1, 5],\n",
    "        'pre_util': [3, 6],\n",
    "        'pre_till_pclose': [10, 7],\n",
    "        'is_zero_loans5': [1],\n",
    "        'pre_since_confirmed': [4, 7],\n",
    "        'pre_loans_credit_limit': [2, 15, 18],\n",
    "        'pre_over2limit': [17],\n",
    "        'pre_till_fclose': [4, 3, 1],\n",
    "        'enc_loans_credit_status': [5],\n",
    "        'pre_since_opened': [12, 8, 19],\n",
    "        'enc_paym_24': [1],\n",
    "        'pre_loans_max_overdue_sum': [1],\n",
    "        'enc_loans_credit_type': [0, 2],\n",
    "        'pre_fterm': [7, 3],\n",
    "        'is_zero_loans3060': [1],\n",
    "        'is_zero_loans6090': [1],\n",
    "        'is_zero_loans90': [1]\n",
    "    }   \n",
    "\n",
    "    # Итерируем по ключам\n",
    "    for col in  features_dictionary.keys():\n",
    "        print('Исходный признак', col)\n",
    "        print('Новые фичи')\n",
    "\n",
    "        # Итерируем по значениям\n",
    "        for value in features_dictionary[col]:\n",
    "            new_column = f'{col}_prop_{value}'\n",
    "            print(new_column)                     \n",
    "\n",
    "            \"\"\"\n",
    "            Создаём булевую маску: True, если значение в col равно value,\n",
    "            иначе False.\n",
    "            \"\"\"\n",
    "            mask = (df[col] == value)\n",
    "            \"\"\"\n",
    "            Для каждой строки вычисляем количество совпадений value \n",
    "            по id (transform('sum')) и делим на общее количество кредитов \n",
    "            по id (rn_max), чтобы получить долю.\n",
    "            \"\"\"\n",
    "            df[new_column] = mask.groupby(df['id']).transform('sum') / df['rn_max']        \n",
    "\n",
    "    return df\n",
    "\n",
    "def from_is_zero_prop_1_create_sum_prop_1_feature_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Вычисляет среднее значение признаков is_zero_*_prop_1 по строкам и добавляет \n",
    "    новый признак 'is_zero_sum_prop_1' в DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df :  Исходный DataFrame с признаками is_zero_*_prop_1.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame : Копия DataFrame с добавленным признаком 'is_zero_sum_prop_1'.\n",
    "    \"\"\"\n",
    "    print('FUNCTION from_is_zero_prop_1_create_sum_prop_1_feature_pipeline ')\n",
    "\n",
    "    columns = [\n",
    "        'is_zero_loans5_prop_1',\n",
    "        'is_zero_loans530_prop_1',\n",
    "        'is_zero_loans3060_prop_1',\n",
    "        'is_zero_loans6090_prop_1',\n",
    "        'is_zero_loans90_prop_1'\n",
    "    ]\n",
    "\n",
    "    df['is_zero_sum_prop_1'] = df[columns].sum(axis=1) / 5\n",
    "\n",
    "    return df\n",
    "\n",
    "def mean_value_frequency_feature_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cоздаёт новые агрегированные признаки,\n",
    "    отражающий среднюю частоту (относительную встречаемость) значений \n",
    "    заданных столбцов columns_list датафрейма для каждого уникального id.\n",
    "    Результат добавляется в  датафрейм \n",
    "    с нормировкой на количество записей (rn_max) для каждого id.\n",
    "    \n",
    "    Args:\n",
    "        df :  Исходный DataFrame с признаками из columns_list.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame :  Копия DataFrame с добавленным новым столбцом {column}_mean_freq,\n",
    "        содержащим нормированное агрегированное значение средней \n",
    "        частоты значений column для каждого id.\n",
    "    \"\"\"\n",
    "    print('FUNCTION mean_value_frequency_feature_pipeline ')\n",
    "        \n",
    "    # Список столбцов, для которых считаем среднюю частоту значений\n",
    "    columns_list = [\n",
    "        'pre_util',\n",
    "        'pre_loans_credit_limit',\n",
    "        'pre_since_opened',\n",
    "        'pre_loans_credit_cost_rate',\n",
    "        'enc_loans_credit_type',\n",
    "        'pre_loans_next_pay_summ',\n",
    "        'pre_since_confirmed',\n",
    "        'pre_pterm',\n",
    "        'enc_paym_0',\n",
    "        'enc_loans_account_holder_type',\n",
    "        'pre_loans530',\n",
    "        'enc_paym_8',\n",
    "        'pre_loans5',\n",
    "        'enc_paym_10',\n",
    "        'enc_loans_account_cur',\n",
    "        'enc_paym_9'\n",
    "    ]\n",
    "    \n",
    "    for col in columns_list:\n",
    "        new_column = f'{col}_mean_freq'\n",
    "        print('new_column', new_column)\n",
    "        \n",
    "        # Вычисляем относительную частоту каждого уникального значения в столбце\n",
    "        bin_freq = df[col].value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        # Создаём Series с частотами значений для каждой строки\n",
    "        freq_series = df[col].map(bin_freq)\n",
    "        \"\"\"\n",
    "        Для каждой строки считаем сумму частот значений (freq_series) по группе 'id'.\n",
    "        Делим эту сумму на общее количество записей по id (rn_max),\n",
    "        чтобы получить нормированную среднюю частоту встречаемости значений\n",
    "        признака для данного id.\n",
    "        Результат сохраняем в новый столбец new_column.\n",
    "        \"\"\"\n",
    "        df[new_column] = freq_series.groupby(df['id']).transform('sum') / df['rn_max']\n",
    "\n",
    "    return df\n",
    "\n",
    "def enc_paym_norm_group_sum_diff_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Генерирует признаки разницы между средними количествами различных статусов платежей \n",
    "    по кредитам за разные временные промежутки.\n",
    "\n",
    "    Основная цель функции — создать итоговые признаки:\n",
    "        - 'enc_paym_avg_0_1_this_year_diff'\n",
    "        - 'enc_paym_avg_1_2_all_diff'\n",
    "        - 'enc_paym_avg_0_years_diff'\n",
    "\n",
    "    Для их расчёта временно создаются промежуточные агрегированные признаки среднего \n",
    "    количества статусов платежей по id и периоду \n",
    "    (например, 'enc_paym_avg_0_this_year'), \n",
    "    которые впоследствии удаляются из итогового датасета.\n",
    "\n",
    "    Args:\n",
    "        df :  Исходный DataFrame с признаками из columns_list.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame :  Копия DataFrame с добавленными итоговыми признаками \n",
    "        разницы между средними количествами статусов платежей по различным периодам.\n",
    "    \"\"\"\n",
    "\n",
    "    print('FUNCTION enc_paym_norm_group_sum_diff_pipeline')\n",
    "\n",
    "    # Создаём временный датафрейм со столбцом id из df\n",
    "    df_buff = pd.DataFrame(data = df['id'], columns = ['id'])\n",
    "    \n",
    "    # Временной промежуток 'all' — все периоды\n",
    "    time_span = 'all'\n",
    "    columns = [f'enc_paym_{i}' for i in range(25)]\n",
    "\n",
    "    # Для статусов платежей по кредитам 1 и 2\n",
    "    for i in range(1, 3):\n",
    "        new_col = f'enc_paym_avg_{i}_{time_span}'\n",
    "        print('new_column', new_col)\n",
    "        \n",
    "        # Считаем количество статуса i по всем столбцам за период \n",
    "        df_buff[new_col] = np.sum(\n",
    "            [df[col] == i for col in columns],\n",
    "            axis=0\n",
    "        )\n",
    "        \"\"\"\n",
    "        Суммируем значения признака new_col по всем строкам с одинаковым id,\n",
    "        затем делим на количество записей по этому id (rn_max),\n",
    "        чтобы получить среднее количество появлений статуса для каждой строки.\n",
    "        Cохраняем результат в новый столбец DataFrame с именем new_col.\n",
    "        \"\"\"\n",
    "        df[new_col] = (\n",
    "            df_buff[new_col].groupby(df_buff['id']).transform('sum') \n",
    "            / df['rn_max']\n",
    "        )\n",
    "        \n",
    "    # Временной промежуток 'this_year' — первые 12 месяцев\n",
    "    time_span = 'this_year'\n",
    "    columns = [f'enc_paym_{i}' for i in range(12)]\n",
    "\n",
    "    # Для статусов платежей по кредитам 0 и 1\n",
    "    for i in range(2):\n",
    "        new_col = f'enc_paym_avg_{i}_{time_span}'\n",
    "        print('new_column', new_col)\n",
    "        \n",
    "        # Считаем количество статуса i по всем столбцам за период \n",
    "        df_buff[new_col] = np.sum(\n",
    "            [df[col] == i for col in columns],\n",
    "            axis=0\n",
    "        )\n",
    "        \"\"\"\n",
    "        Суммируем значения признака new_col по всем строкам с одинаковым id,\n",
    "        затем делим на количество записей по этому id (rn_max),\n",
    "        чтобы получить среднее количество появлений статуса для каждой строки.\n",
    "        Cохраняем результат в новый столбец DataFrame с именем new_col.\n",
    "        \"\"\"\n",
    "        df[new_col] = (\n",
    "            df_buff[new_col].groupby(df_buff['id']).transform('sum')\n",
    "            / df['rn_max']\n",
    "        )\n",
    "        \n",
    "    # Временной промежуток 'last_year' — месяцы с 12 по 24\n",
    "    time_span = 'last_year'\n",
    "    columns = [f'enc_paym_{i}' for i in range(12, 25)]\n",
    "    \n",
    "    \"\"\"\n",
    "    Статус платежей  0.\n",
    "    (Оставим цикл для единообразия кода)\n",
    "    \"\"\"\n",
    "    for i in [0]:\n",
    "        new_col = f'enc_paym_avg_{i}_{time_span}'\n",
    "        print('new_column', new_col)\n",
    "        \n",
    "        # Считаем количество статуса i по всем столбцам за период \n",
    "        df_buff[new_col] = np.sum(\n",
    "            [df[old_col] == i for old_col in columns],\n",
    "            axis=0\n",
    "        )\n",
    "        \"\"\"\n",
    "        Суммируем значения признака new_col по всем строкам с одинаковым id,\n",
    "        затем делим на количество записей по этому id (rn_max),\n",
    "        чтобы получить среднее количество появлений статуса для каждой строки.\n",
    "        Cохраняем результат в новый столбец DataFrame с именем new_col.\n",
    "        \"\"\"\n",
    "        df[new_col] = (\n",
    "            df_buff[new_col].groupby(df_buff['id']).transform('sum')\n",
    "            / df['rn_max']\n",
    "        )\n",
    "\n",
    "    # Создаём фичи разницы \n",
    "    df['enc_paym_avg_0_1_this_year_diff'] = (\n",
    "            df['enc_paym_avg_0_this_year'] - \n",
    "            df['enc_paym_avg_1_this_year']\n",
    "    )\n",
    "\n",
    "    df['enc_paym_avg_1_2_all_diff'] = (\n",
    "            df['enc_paym_avg_1_all'] - \n",
    "            df['enc_paym_avg_2_all']\n",
    "    )\n",
    "\n",
    "    df['enc_paym_avg_0_years_diff'] = (\n",
    "            df['enc_paym_avg_0_this_year'] - \n",
    "            df['enc_paym_avg_0_last_year']\n",
    "    )\n",
    "    \n",
    "    print('new diff columns')\n",
    "    print('enc_paym_avg_0_1_this_year_diff')\n",
    "    print('enc_paym_avg_1_2_all_diff')\n",
    "    print('enc_paym_avg_0_years_diff')\n",
    "\n",
    "    return df\n",
    "\n",
    "def pre_since_opened_sum_mean_repeated_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cоздаёт признак, отражающий пропорцию повторяющихся значений 'pre_since_opened'\n",
    "    для каждого 'id'.\n",
    "\n",
    "    Логика работы:\n",
    "    - Подсчитывает количество появлений каждого значения 'pre_since_opened' для каждого 'id'.\n",
    "    - Выделяет только повторяющиеся значения (где количество > 1) и вычитает 1,\n",
    "      чтобы не считать первое появление.\n",
    "    - Суммирует количество повторов по всем значениям 'pre_since_opened' для каждого 'id'.\n",
    "    - Добавляет отсутствующие 'id' с нулевыми значениями повторов.\n",
    "    - Добавляет новый признак 'pre_since_opened_repeated_prop' в df_to_update,\n",
    "      нормируя сумму повторов на количество записей 'rn_max' для каждого 'id'.\n",
    "\n",
    "    Args:\n",
    "        df :  Исходный DataFrame с признаками  'pre_since_opened', 'id' и 'rn_max'.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame :  Копия DataFrame с \n",
    "        добавленным признаком 'pre_since_opened_repeated_prop'.\n",
    "    \"\"\"\n",
    "    print('FUNCTION pre_since_opened_sum_mean_repeated_pipeline ')\n",
    "    \n",
    "    # Считаем количество каждого значения 'pre_since_opened' для каждого 'id'\n",
    "    counts = df.groupby(['id', 'pre_since_opened']).size()\n",
    "    \n",
    "    \"\"\"\n",
    "    Оставляем только повторяющиеся значения (количество > 1), \n",
    "    вычитаем первое появление.\n",
    "    \"\"\"\n",
    "    repeated_pre_since_opened = counts[counts > 1] - 1\n",
    "\n",
    "    # Суммируем количество повторов по каждому 'id'\n",
    "    sum_repeated = repeated_pre_since_opened.groupby('id').sum()\n",
    "    \n",
    "    # Добавляем отсутствующие 'id' с нулевыми значениями повторов\n",
    "    all_sum_repeated = sum_repeated.reindex(df['id'].unique(), fill_value=0)\n",
    "    \n",
    "    # Переименовываем Series для дальнейшего слияния\n",
    "    all_sum_repeated = all_sum_repeated.rename('pre_since_opened_repeated_prop')\n",
    "\n",
    "    # Объединяем с исходным DataFrame по 'id'\n",
    "    df = df.merge(all_sum_repeated, on='id', how='left')\n",
    "\n",
    "    # Нормируем сумму повторов на количество записей 'rn_max' для каждого 'id'\n",
    "    df['pre_since_opened_repeated_prop'] = (\n",
    "        df['pre_since_opened_repeated_prop'] / df['rn_max']\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_columns_drop_duplicates_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Удаляет исходные и временные признаки из DataFrame,\n",
    "    а также удаляет дубликаты по столбцу 'id', оставляя только первую запись.\n",
    "    После удаления дубликатов столбец 'id' также удаляется.\n",
    "\n",
    "    Args:\n",
    "        df : Исходный DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame : Копия DataFrame без указанных столбцов и дубликатов по 'id'.\n",
    "    \"\"\"\n",
    "\n",
    "    print('FUNCTION drop_columns_drop_duplicates_pipeline ')\n",
    "    # Список столбцов на удаление\n",
    "    columns = [\n",
    "        'rn',\n",
    "        'pre_since_opened',\n",
    "        'pre_since_confirmed',\n",
    "        'pre_pterm',\n",
    "        'pre_fterm',\n",
    "        'pre_till_pclose',\n",
    "        'pre_till_fclose',\n",
    "        'pre_loans_credit_limit',\n",
    "        'pre_loans_next_pay_summ',\n",
    "        'pre_loans_outstanding',\n",
    "        'pre_loans_max_overdue_sum',\n",
    "        'pre_loans_credit_cost_rate',\n",
    "        'pre_loans5',\n",
    "        'pre_loans530',\n",
    "        'is_zero_loans5',\n",
    "        'is_zero_loans530',\n",
    "        'pre_util',\n",
    "        'pre_over2limit',\n",
    "        'is_zero_over2limit',\n",
    "        'enc_paym_0',\n",
    "        'enc_paym_1',\n",
    "        'enc_paym_2',\n",
    "        'enc_paym_8',\n",
    "        'enc_paym_9',\n",
    "        'enc_paym_10',\n",
    "        'enc_paym_24',\n",
    "        'enc_loans_account_holder_type',\n",
    "        'enc_loans_credit_status',\n",
    "        'enc_loans_credit_type',\n",
    "        'enc_loans_account_cur',\n",
    "        'is_zero_loans3060',\n",
    "        'is_zero_loans6090',\n",
    "        'is_zero_loans90',\n",
    "        'enc_paym_3',\n",
    "        'enc_paym_4',\n",
    "        'enc_paym_5',\n",
    "        'enc_paym_6',\n",
    "        'enc_paym_7',\n",
    "        'enc_paym_11',\n",
    "        'enc_paym_12',\n",
    "        'enc_paym_13',\n",
    "        'enc_paym_14',\n",
    "        'enc_paym_15',\n",
    "        'enc_paym_16',\n",
    "        'enc_paym_17',\n",
    "        'enc_paym_18',\n",
    "        'enc_paym_19',\n",
    "        'enc_paym_20',\n",
    "        'enc_paym_21',\n",
    "        'enc_paym_22',\n",
    "        'enc_paym_23',\n",
    "        'enc_paym_avg_1_all',\n",
    "        'enc_paym_avg_2_all',\n",
    "        'enc_paym_avg_0_this_year',\n",
    "        'enc_paym_avg_1_this_year',\n",
    "        'enc_paym_avg_0_last_year',\n",
    "        'is_zero_loans3060_prop_1',\n",
    "        'is_zero_loans6090_prop_1',\n",
    "        'is_zero_loans90_prop_1'\n",
    "    ]\n",
    "    \n",
    "    df = df.drop(columns, axis=1)\n",
    "    \n",
    "    \"\"\"\n",
    "    Удаляем дубликаты по столбцу 'id', оставляя первую запись\n",
    "    и сбрасываем индекс.\n",
    "    \"\"\"\n",
    "    df = df.drop_duplicates(subset=['id'], keep='first').reset_index(drop=True)\n",
    "    \n",
    "    # Удаляем столбец 'id', так как он больше не нужен\n",
    "    df = df.drop('id', axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "580ca15d-454d-4032-86a5-c3870f7465e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFIER\n",
    "\n",
    "class CatBoostEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Ансамблевый классификатор на основе CatBoost, обучающий 5 моделей \n",
    "    на разных разбиениях данных и финальную модель на полном наборе данных.\n",
    "    Чтобы повысить устойчивость и качество предсказаний \n",
    "    за счёт усреднения результатов.\n",
    "\n",
    "    Особенности:\n",
    "        - Используется StratifiedKFold для разбиения данных на 5 фолдов.\n",
    "        - Для каждого фолда обучается отдельная модель на тренировочной части.\n",
    "        - Все 5 моделей сохраняются для последующего усреднения предсказаний.\n",
    "        - Дополнительно обучается финальная модель на полном наборе данных.\n",
    "        - Предсказания объединяются с учётом весов моделей.\n",
    "\n",
    "    Args:\n",
    "        params_list (list of dict): Список параметров для каждой из 6 моделей.\n",
    "        weights_list (list of float): Веса для усреднения предсказаний моделей\n",
    "            представляющие собой auc_score шести моделей. \n",
    "            Это позволяет отдавать большее значение более качественным моделям.\n",
    "            \n",
    "    Attributes:\n",
    "        models_ (list): Список обученных моделей CatBoostClassifier \n",
    "            после вызова fit.\n",
    "\n",
    "    Methods:\n",
    "        fit(X, y): Обучает ансамбль моделей и сохраняет их.\n",
    "        fit_transform(X, y): Обучает модели и возвращает X без изменений \n",
    "            (для совместимости с пайплайнами).\n",
    "        transform(X): Возвращает X без изменений \n",
    "            (для совместимости с пайплайнами).\n",
    "        predict_proba(X): Возвращает взвешенное усреднённое предсказание \n",
    "            вероятностей положительного класса.\n",
    "        predict(X): Возвращает бинарные предсказания с порогом 0.4964.\n",
    "    \"\"\"\n",
    "    def __init__(self, params_list, weights_list):\n",
    "        self.params_list = params_list\n",
    "        self.weights_list = weights_list\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучает ансамбль моделей на разных фолдах и финальную модель \n",
    "        на полном наборе данных.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Признаки.\n",
    "            y (pd.Series или np.array): Целевой признак.\n",
    "\n",
    "        Returns:\n",
    "            self : Обученный объект классификатора с атрибутом models_, \n",
    "              содержащим список обученных моделей.\n",
    "        \"\"\"\n",
    "        self.models_ = []\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "        # Обучаем 5 моделей на разных фолдах\n",
    "        for i, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "            X_train = X.iloc[train_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "            \n",
    "            train_pool = Pool(data=X_train, label=y_train, cat_features=[])\n",
    "            val_pool = Pool(data=X_val, label=y_val, cat_features=[])\n",
    "\n",
    "            \"\"\"\n",
    "            Для обучения используются валидационные подвыборки, \n",
    "            для остановки обучения вместо ГП early_stopping_rounds\n",
    "            в params передаётся od_wait.\n",
    "            \"\"\"\n",
    "            params = self.params_list[i]\n",
    "            model = CatBoostClassifier(\n",
    "                **params\n",
    "            )\n",
    "            model.fit(\n",
    "                train_pool,\n",
    "                eval_set=val_pool\n",
    "            )\n",
    "            self.models_.append(model)\n",
    "            \n",
    "        # Обучаем финальную модель на полном наборе данных\n",
    "        train_pool = Pool(data=X, label=y, cat_features=[])\n",
    "        params = self.params_list[5]\n",
    "        model = CatBoostClassifier(\n",
    "            **params\n",
    "        )\n",
    "        model.fit(\n",
    "            train_pool\n",
    "        )\n",
    "        self.models_.append(model)\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        # Обучаем классификатор\n",
    "        self.fit(X, y)\n",
    "        # Возвращаем X без изменений\n",
    "        return X\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Возвращаем X без изменений\n",
    "        return X\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Предсказывает вероятности классов, \n",
    "        усреднённые по всем моделям с учётом весов.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Матрица признаков.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Массив вероятностей для классов 0 и 1,\n",
    "            размерностью (n_samples, 2).\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for model, weight in zip(self.models_, self.weights_list):\n",
    "            pred = model.predict_proba(X)[:, 1]\n",
    "            preds.append(pred * weight)\n",
    "        mean_pred = np.sum(preds, axis=0) / np.sum(self.weights_list)\n",
    "        return np.vstack([1 - mean_pred, mean_pred]).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказывает классы на основе вероятностей с порогом 0.4964.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Матрица признаков.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Массив предсказанных классов (0 или 1).\n",
    "        \"\"\"\n",
    "        proba = self.predict_proba(X)[:, 1]\n",
    "        return (proba >= 0.4964).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53162a0f-0907-4ca3-8ec2-55ade8b74584",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Из-за большого размера датасета вычисление медиан признаков занимает\n",
    "большой объём памяти, что приводит к падению ядра ноутбука. Поэтому применим\n",
    "кастомный imputer и будем расчитывать медианы на 10% процентах датасета.\n",
    "Оценки медианы будут приближены к реальным медианам, но не совпадать с ними.\n",
    "Такое решение это компромис между точностью и производительностью.\n",
    "Например для признака id погрешность между реальной медианой и оценочной \n",
    "составила около 0.05%.\n",
    "\"\"\"\n",
    "class SampleMedianImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, sample_frac=0.1):\n",
    "        # Доля выборки для вычисления медиан\n",
    "        self.sample_frac = sample_frac\n",
    "        # Атрибут для хранения медиан\n",
    "        self.medians_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Создаём подвыборку датасета, random_state для воспроизводимости\n",
    "        sample = X.sample(frac=self.sample_frac, random_state=0)\n",
    "        # Вычисляем и сохраняем медианы\n",
    "        self.medians_ = sample.median()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Заполняем пропуски медианами\n",
    "        return X.fillna(self.medians_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3417c72d-5480-4485-bf36-277a44b44208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём SampleMedianImputer, долю выборки оставляем равной 0.1\n",
    "imputer = SampleMedianImputer(sample_frac=0.1)\n",
    "\n",
    "# Создаём паплайн препроцессинга\n",
    "preprocessing_pipe = Pipeline([\n",
    "    ('to_numeric', FunctionTransformer(convert_all_to_numeric_pipeline)), \n",
    "    ('imputer', imputer),\n",
    "    ('to_int', FunctionTransformer(convert_all_to_int_pipeline)),\n",
    "    ('drop_duplicates', FunctionTransformer(drop_duplicates_pipeline))\n",
    "])\n",
    "\n",
    "# Создаём основной пайплайн\n",
    "main_pipe = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            'preprocessing',\n",
    "            preprocessing_pipe\n",
    "        ),\n",
    "        (\n",
    "            'create_rn_max_feature',\n",
    "            FunctionTransformer(rn_max_feature_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'enc_paym_transcoding', \n",
    "            FunctionTransformer(enc_paym_transcoding_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'create_definite_value_proportion_features',\n",
    "            FunctionTransformer(definite_value_proportion_features_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'create_sum_prop_1_feature',\n",
    "            FunctionTransformer(from_is_zero_prop_1_create_sum_prop_1_feature_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'create_mean_value_frequency_feature',\n",
    "            FunctionTransformer(mean_value_frequency_feature_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'from_enc_paym_create_normalized_group_sum_features_then_diff_features',\n",
    "            FunctionTransformer(enc_paym_norm_group_sum_diff_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'from_pre_since_opened_create_pre_since_opened_sum_mean_repeated',\n",
    "            FunctionTransformer(pre_since_opened_sum_mean_repeated_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'drop_temporary_and_source_columns_drop_duplicates',\n",
    "            FunctionTransformer(drop_columns_drop_duplicates_pipeline)\n",
    "        ),\n",
    "         (\n",
    "            'classifier', \n",
    "            CatBoostEnsembleClassifier(params_list=params_list, weights_list=weights_list)\n",
    "        )\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "afd2845c-e515-4ab9-8449-c902bcd73908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION convert_all_to_numeric_pipeline\n",
      "FUNCTION convert_all_to_int_pipeline\n",
      "FUNCTION drop_duplicates_pipeline\n",
      "FUNCTION rn_max_feature_pipeline\n",
      "FUNCTION enc_paym_transcoding_pipeline \n",
      "FUNCTION definite_value_proportion_features_pipeline \n",
      "Исходный признак enc_loans_account_holder_type\n",
      "Новые фичи\n",
      "enc_loans_account_holder_type_prop_4\n",
      "Исходный признак pre_pterm\n",
      "Новые фичи\n",
      "pre_pterm_prop_6\n",
      "pre_pterm_prop_3\n",
      "Исходный признак is_zero_loans530\n",
      "Новые фичи\n",
      "is_zero_loans530_prop_1\n",
      "Исходный признак enc_paym_0\n",
      "Новые фичи\n",
      "enc_paym_0_prop_1\n",
      "Исходный признак pre_loans_credit_cost_rate\n",
      "Новые фичи\n",
      "pre_loans_credit_cost_rate_prop_6\n",
      "pre_loans_credit_cost_rate_prop_11\n",
      "pre_loans_credit_cost_rate_prop_4\n",
      "Исходный признак pre_loans_next_pay_summ\n",
      "Новые фичи\n",
      "pre_loans_next_pay_summ_prop_5\n",
      "pre_loans_next_pay_summ_prop_0\n",
      "Исходный признак is_zero_over2limit\n",
      "Новые фичи\n",
      "is_zero_over2limit_prop_1\n",
      "Исходный признак pre_loans_outstanding\n",
      "Новые фичи\n",
      "pre_loans_outstanding_prop_1\n",
      "pre_loans_outstanding_prop_5\n",
      "Исходный признак pre_util\n",
      "Новые фичи\n",
      "pre_util_prop_3\n",
      "pre_util_prop_6\n",
      "Исходный признак pre_till_pclose\n",
      "Новые фичи\n",
      "pre_till_pclose_prop_10\n",
      "pre_till_pclose_prop_7\n",
      "Исходный признак is_zero_loans5\n",
      "Новые фичи\n",
      "is_zero_loans5_prop_1\n",
      "Исходный признак pre_since_confirmed\n",
      "Новые фичи\n",
      "pre_since_confirmed_prop_4\n",
      "pre_since_confirmed_prop_7\n",
      "Исходный признак pre_loans_credit_limit\n",
      "Новые фичи\n",
      "pre_loans_credit_limit_prop_2\n",
      "pre_loans_credit_limit_prop_15\n",
      "pre_loans_credit_limit_prop_18\n",
      "Исходный признак pre_over2limit\n",
      "Новые фичи\n",
      "pre_over2limit_prop_17\n",
      "Исходный признак pre_till_fclose\n",
      "Новые фичи\n",
      "pre_till_fclose_prop_4\n",
      "pre_till_fclose_prop_3\n",
      "pre_till_fclose_prop_1\n",
      "Исходный признак enc_loans_credit_status\n",
      "Новые фичи\n",
      "enc_loans_credit_status_prop_5\n",
      "Исходный признак pre_since_opened\n",
      "Новые фичи\n",
      "pre_since_opened_prop_12\n",
      "pre_since_opened_prop_8\n",
      "pre_since_opened_prop_19\n",
      "Исходный признак enc_paym_24\n",
      "Новые фичи\n",
      "enc_paym_24_prop_1\n",
      "Исходный признак pre_loans_max_overdue_sum\n",
      "Новые фичи\n",
      "pre_loans_max_overdue_sum_prop_1\n",
      "Исходный признак enc_loans_credit_type\n",
      "Новые фичи\n",
      "enc_loans_credit_type_prop_0\n",
      "enc_loans_credit_type_prop_2\n",
      "Исходный признак pre_fterm\n",
      "Новые фичи\n",
      "pre_fterm_prop_7\n",
      "pre_fterm_prop_3\n",
      "Исходный признак is_zero_loans3060\n",
      "Новые фичи\n",
      "is_zero_loans3060_prop_1\n",
      "Исходный признак is_zero_loans6090\n",
      "Новые фичи\n",
      "is_zero_loans6090_prop_1\n",
      "Исходный признак is_zero_loans90\n",
      "Новые фичи\n",
      "is_zero_loans90_prop_1\n",
      "FUNCTION from_is_zero_prop_1_create_sum_prop_1_feature_pipeline \n",
      "FUNCTION mean_value_frequency_feature_pipeline \n",
      "new_column pre_util_mean_freq\n",
      "new_column pre_loans_credit_limit_mean_freq\n",
      "new_column pre_since_opened_mean_freq\n",
      "new_column pre_loans_credit_cost_rate_mean_freq\n",
      "new_column enc_loans_credit_type_mean_freq\n",
      "new_column pre_loans_next_pay_summ_mean_freq\n",
      "new_column pre_since_confirmed_mean_freq\n",
      "new_column pre_pterm_mean_freq\n",
      "new_column enc_paym_0_mean_freq\n",
      "new_column enc_loans_account_holder_type_mean_freq\n",
      "new_column pre_loans530_mean_freq\n",
      "new_column enc_paym_8_mean_freq\n",
      "new_column pre_loans5_mean_freq\n",
      "new_column enc_paym_10_mean_freq\n",
      "new_column enc_loans_account_cur_mean_freq\n",
      "new_column enc_paym_9_mean_freq\n",
      "FUNCTION enc_paym_norm_group_sum_diff_pipeline\n",
      "new_column enc_paym_avg_1_all\n",
      "new_column enc_paym_avg_2_all\n",
      "new_column enc_paym_avg_0_this_year\n",
      "new_column enc_paym_avg_1_this_year\n",
      "new_column enc_paym_avg_0_last_year\n",
      "new diff columns\n",
      "enc_paym_avg_0_1_this_year_diff\n",
      "enc_paym_avg_1_2_all_diff\n",
      "enc_paym_avg_0_years_diff\n",
      "FUNCTION pre_since_opened_sum_mean_repeated_pipeline \n",
      "FUNCTION drop_columns_drop_duplicates_pipeline \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;to_numeric&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function convert_all_to_numeric_pipeline at 0x145b93240&gt;)),\n",
       "                                 (&#x27;imputer&#x27;, SampleMedianImputer()),\n",
       "                                 (&#x27;to_int&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function convert_all_to_int_pipeline at 0x145c90c20&gt;)),\n",
       "                                 (&#x27;drop_duplicates&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function drop_duplicates_pipeline at 0x14...\n",
       "                                                          &#x27;iterations&#x27;: 2996,\n",
       "                                                          &#x27;l2_leaf_reg&#x27;: 8.005778242558318,\n",
       "                                                          &#x27;learning_rate&#x27;: 0.036254760756236626,\n",
       "                                                          &#x27;min_data_in_leaf&#x27;: 5,\n",
       "                                                          &#x27;random_seed&#x27;: 0,\n",
       "                                                          &#x27;random_strength&#x27;: 8.209932298658357,\n",
       "                                                          &#x27;rsm&#x27;: 0.7343256008238508,\n",
       "                                                          &#x27;subsample&#x27;: 0.9882297325066979,\n",
       "                                                          &#x27;verbose&#x27;: False}],\n",
       "                                            weights_list=[0.7576036850511159,\n",
       "                                                          0.7554545982995526,\n",
       "                                                          0.7532810994057619,\n",
       "                                                          0.7546988571803108,\n",
       "                                                          0.7524269260453276,\n",
       "                                                          0.7546930331964138]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;to_numeric&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function convert_all_to_numeric_pipeline at 0x145b93240&gt;)),\n",
       "                                 (&#x27;imputer&#x27;, SampleMedianImputer()),\n",
       "                                 (&#x27;to_int&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function convert_all_to_int_pipeline at 0x145c90c20&gt;)),\n",
       "                                 (&#x27;drop_duplicates&#x27;,\n",
       "                                  FunctionTransformer(func=&lt;function drop_duplicates_pipeline at 0x14...\n",
       "                                                          &#x27;iterations&#x27;: 2996,\n",
       "                                                          &#x27;l2_leaf_reg&#x27;: 8.005778242558318,\n",
       "                                                          &#x27;learning_rate&#x27;: 0.036254760756236626,\n",
       "                                                          &#x27;min_data_in_leaf&#x27;: 5,\n",
       "                                                          &#x27;random_seed&#x27;: 0,\n",
       "                                                          &#x27;random_strength&#x27;: 8.209932298658357,\n",
       "                                                          &#x27;rsm&#x27;: 0.7343256008238508,\n",
       "                                                          &#x27;subsample&#x27;: 0.9882297325066979,\n",
       "                                                          &#x27;verbose&#x27;: False}],\n",
       "                                            weights_list=[0.7576036850511159,\n",
       "                                                          0.7554545982995526,\n",
       "                                                          0.7532810994057619,\n",
       "                                                          0.7546988571803108,\n",
       "                                                          0.7524269260453276,\n",
       "                                                          0.7546930331964138]))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessing: Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for preprocessing: Pipeline</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;to_numeric&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function convert_all_to_numeric_pipeline at 0x145b93240&gt;)),\n",
       "                (&#x27;imputer&#x27;, SampleMedianImputer()),\n",
       "                (&#x27;to_int&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function convert_all_to_int_pipeline at 0x145c90c20&gt;)),\n",
       "                (&#x27;drop_duplicates&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function drop_duplicates_pipeline at 0x145c92200&gt;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>convert_all_to_numeric_pipeline</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function convert_all_to_numeric_pipeline at 0x145b93240&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SampleMedianImputer</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>SampleMedianImputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>convert_all_to_int_pipeline</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function convert_all_to_int_pipeline at 0x145c90c20&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>drop_duplicates_pipeline</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function drop_duplicates_pipeline at 0x145c92200&gt;)</pre></div> </div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>rn_max_feature_pipeline</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function rn_max_feature_pipeline at 0x145b92d40&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>enc_paym_transcoding_pipeline</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function enc_paym_transcoding_pipeline at 0x145b92a20&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>definite_value_proportion_features_pipeline</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function definite_value_proportion_features_pipeline at 0x145b92c00&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>from_is_zero_prop_1_create_sum_prop_1_feature_pipeline</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function from_is_zero_prop_1_create_sum_prop_1_feature_pipeline at 0x145b928e0&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>mean_value_frequency_feature_pipeline</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function mean_value_frequency_feature_pipeline at 0x145b931a0&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>enc_paym_norm_group_sum_diff_pipeline</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function enc_paym_norm_group_sum_diff_pipeline at 0x145b932e0&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>pre_since_opened_sum_mean_repeated_pipeline</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function pre_since_opened_sum_mean_repeated_pipeline at 0x145b92980&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>drop_columns_drop_duplicates_pipeline</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function drop_columns_drop_duplicates_pipeline at 0x145b92700&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CatBoostEnsembleClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>CatBoostEnsembleClassifier(params_list=[{&#x27;auto_class_weights&#x27;: &#x27;Balanced&#x27;,\n",
       "                                         &#x27;bagging_temperature&#x27;: 0.09710127579,\n",
       "                                         &#x27;boosting_type&#x27;: &#x27;Plain&#x27;,\n",
       "                                         &#x27;border_count&#x27;: 113, &#x27;depth&#x27;: 4,\n",
       "                                         &#x27;eval_metric&#x27;: &#x27;AUC&#x27;,\n",
       "                                         &#x27;grow_policy&#x27;: &#x27;SymmetricTree&#x27;,\n",
       "                                         &#x27;iterations&#x27;: 3000,\n",
       "                                         &#x27;l2_leaf_reg&#x27;: 8.005778243,\n",
       "                                         &#x27;learning_rate&#x27;: 0.03625476076,\n",
       "                                         &#x27;loss_function&#x27;: &#x27;Logloss&#x27;,\n",
       "                                         &#x27;min_data_in_leaf&#x27;: 5, &#x27;od_wait&#x27;: 100,\n",
       "                                         &#x27;ra...\n",
       "                                         &#x27;iterations&#x27;: 2996,\n",
       "                                         &#x27;l2_leaf_reg&#x27;: 8.005778242558318,\n",
       "                                         &#x27;learning_rate&#x27;: 0.036254760756236626,\n",
       "                                         &#x27;min_data_in_leaf&#x27;: 5,\n",
       "                                         &#x27;random_seed&#x27;: 0,\n",
       "                                         &#x27;random_strength&#x27;: 8.209932298658357,\n",
       "                                         &#x27;rsm&#x27;: 0.7343256008238508,\n",
       "                                         &#x27;subsample&#x27;: 0.9882297325066979,\n",
       "                                         &#x27;verbose&#x27;: False}],\n",
       "                           weights_list=[0.7576036850511159, 0.7554545982995526,\n",
       "                                         0.7532810994057619, 0.7546988571803108,\n",
       "                                         0.7524269260453276,\n",
       "                                         0.7546930331964138])</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 Pipeline(steps=[('to_numeric',\n",
       "                                  FunctionTransformer(func=<function convert_all_to_numeric_pipeline at 0x145b93240>)),\n",
       "                                 ('imputer', SampleMedianImputer()),\n",
       "                                 ('to_int',\n",
       "                                  FunctionTransformer(func=<function convert_all_to_int_pipeline at 0x145c90c20>)),\n",
       "                                 ('drop_duplicates',\n",
       "                                  FunctionTransformer(func=<function drop_duplicates_pipeline at 0x14...\n",
       "                                                          'iterations': 2996,\n",
       "                                                          'l2_leaf_reg': 8.005778242558318,\n",
       "                                                          'learning_rate': 0.036254760756236626,\n",
       "                                                          'min_data_in_leaf': 5,\n",
       "                                                          'random_seed': 0,\n",
       "                                                          'random_strength': 8.209932298658357,\n",
       "                                                          'rsm': 0.7343256008238508,\n",
       "                                                          'subsample': 0.9882297325066979,\n",
       "                                                          'verbose': False}],\n",
       "                                            weights_list=[0.7576036850511159,\n",
       "                                                          0.7554545982995526,\n",
       "                                                          0.7532810994057619,\n",
       "                                                          0.7546988571803108,\n",
       "                                                          0.7524269260453276,\n",
       "                                                          0.7546930331964138]))])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучим пайплайн\n",
    "main_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2cc412a0-85b0-41b5-b779-473215e70b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним обученный пайплайн в файл\n",
    "with open('pipeline/trained_pipeline.pkl', 'wb') as file:\n",
    "    pickle.dump(main_pipe, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fed1634-f360-41a3-b3d3-1ffdeae11991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION convert_all_to_numeric_pipeline \n",
      "FUNCTION rn_max_feature_pipeline\n",
      "FUNCTION enc_paym_transcoding_pipeline \n",
      "FUNCTION definite_value_proportion_features_pipeline \n",
      "Исходный признак enc_loans_account_holder_type\n",
      "Новые фичи\n",
      "enc_loans_account_holder_type_prop_4\n",
      "Исходный признак pre_pterm\n",
      "Новые фичи\n",
      "pre_pterm_prop_6\n",
      "pre_pterm_prop_3\n",
      "Исходный признак is_zero_loans530\n",
      "Новые фичи\n",
      "is_zero_loans530_prop_1\n",
      "Исходный признак enc_paym_0\n",
      "Новые фичи\n",
      "enc_paym_0_prop_1\n",
      "Исходный признак pre_loans_credit_cost_rate\n",
      "Новые фичи\n",
      "pre_loans_credit_cost_rate_prop_6\n",
      "pre_loans_credit_cost_rate_prop_11\n",
      "pre_loans_credit_cost_rate_prop_4\n",
      "Исходный признак pre_loans_next_pay_summ\n",
      "Новые фичи\n",
      "pre_loans_next_pay_summ_prop_5\n",
      "pre_loans_next_pay_summ_prop_0\n",
      "Исходный признак is_zero_over2limit\n",
      "Новые фичи\n",
      "is_zero_over2limit_prop_1\n",
      "Исходный признак pre_loans_outstanding\n",
      "Новые фичи\n",
      "pre_loans_outstanding_prop_1\n",
      "pre_loans_outstanding_prop_5\n",
      "Исходный признак pre_util\n",
      "Новые фичи\n",
      "pre_util_prop_3\n",
      "pre_util_prop_6\n",
      "Исходный признак pre_till_pclose\n",
      "Новые фичи\n",
      "pre_till_pclose_prop_10\n",
      "pre_till_pclose_prop_7\n",
      "Исходный признак is_zero_loans5\n",
      "Новые фичи\n",
      "is_zero_loans5_prop_1\n",
      "Исходный признак pre_since_confirmed\n",
      "Новые фичи\n",
      "pre_since_confirmed_prop_4\n",
      "pre_since_confirmed_prop_7\n",
      "Исходный признак pre_loans_credit_limit\n",
      "Новые фичи\n",
      "pre_loans_credit_limit_prop_2\n",
      "pre_loans_credit_limit_prop_15\n",
      "pre_loans_credit_limit_prop_18\n",
      "Исходный признак pre_over2limit\n",
      "Новые фичи\n",
      "pre_over2limit_prop_17\n",
      "Исходный признак pre_till_fclose\n",
      "Новые фичи\n",
      "pre_till_fclose_prop_4\n",
      "pre_till_fclose_prop_3\n",
      "pre_till_fclose_prop_1\n",
      "Исходный признак enc_loans_credit_status\n",
      "Новые фичи\n",
      "enc_loans_credit_status_prop_5\n",
      "Исходный признак pre_since_opened\n",
      "Новые фичи\n",
      "pre_since_opened_prop_12\n",
      "pre_since_opened_prop_8\n",
      "pre_since_opened_prop_19\n",
      "Исходный признак enc_paym_24\n",
      "Новые фичи\n",
      "enc_paym_24_prop_1\n",
      "Исходный признак pre_loans_max_overdue_sum\n",
      "Новые фичи\n",
      "pre_loans_max_overdue_sum_prop_1\n",
      "Исходный признак enc_loans_credit_type\n",
      "Новые фичи\n",
      "enc_loans_credit_type_prop_0\n",
      "enc_loans_credit_type_prop_2\n",
      "Исходный признак pre_fterm\n",
      "Новые фичи\n",
      "pre_fterm_prop_7\n",
      "pre_fterm_prop_3\n",
      "Исходный признак is_zero_loans3060\n",
      "Новые фичи\n",
      "is_zero_loans3060_prop_1\n",
      "Исходный признак is_zero_loans6090\n",
      "Новые фичи\n",
      "is_zero_loans6090_prop_1\n",
      "Исходный признак is_zero_loans90\n",
      "Новые фичи\n",
      "is_zero_loans90_prop_1\n",
      "FUNCTION from_is_zero_prop_1_create_sum_prop_1_feature_pipeline \n",
      "FUNCTION mean_value_frequency_feature_pipeline \n",
      "new_column pre_util_mean_freq\n",
      "new_column pre_loans_credit_limit_mean_freq\n",
      "new_column pre_since_opened_mean_freq\n",
      "new_column pre_loans_credit_cost_rate_mean_freq\n",
      "new_column enc_loans_credit_type_mean_freq\n",
      "new_column pre_loans_next_pay_summ_mean_freq\n",
      "new_column pre_since_confirmed_mean_freq\n",
      "new_column pre_pterm_mean_freq\n",
      "new_column enc_paym_0_mean_freq\n",
      "new_column enc_loans_account_holder_type_mean_freq\n",
      "new_column pre_loans530_mean_freq\n",
      "new_column enc_paym_8_mean_freq\n",
      "new_column pre_loans5_mean_freq\n",
      "new_column enc_paym_10_mean_freq\n",
      "new_column enc_loans_account_cur_mean_freq\n",
      "new_column enc_paym_9_mean_freq\n",
      "FUNCTION enc_paym_norm_group_sum_diff_pipeline\n",
      "new_column enc_paym_avg_1_all\n",
      "new_column enc_paym_avg_2_all\n",
      "new_column enc_paym_avg_0_this_year\n",
      "new_column enc_paym_avg_1_this_year\n",
      "new_column enc_paym_avg_0_last_year\n",
      "new diff columns\n",
      "enc_paym_avg_0_1_this_year_diff\n",
      "enc_paym_avg_1_2_all_diff\n",
      "enc_paym_avg_0_years_diff\n",
      "FUNCTION pre_since_opened_sum_mean_repeated_pipeline \n",
      "FUNCTION drop_columns_drop_duplicates_pipeline \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.94601576, 0.05398424],\n",
       "       [0.53785636, 0.46214364],\n",
       "       [0.65246789, 0.34753211],\n",
       "       ...,\n",
       "       [0.56149362, 0.43850638],\n",
       "       [0.83209011, 0.16790989],\n",
       "       [0.31052491, 0.68947509]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Предскажем вероятности классов\n",
    "pred_proba = main_pipe.predict_proba(X_test)\n",
    "pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb0e4f59-bea7-4bf4-87ff-459eb20967c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7572266329942543"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вычислим целевую метрику\n",
    "roc_auc_score(y_test, pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9441579-93dd-43f9-88a5-1b699ddd5ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION convert_all_to_numeric_pipeline \n",
      "FUNCTION rn_max_feature_pipeline\n",
      "FUNCTION enc_paym_transcoding_pipeline \n",
      "FUNCTION definite_value_proportion_features_pipeline \n",
      "Исходный признак enc_loans_account_holder_type\n",
      "Новые фичи\n",
      "enc_loans_account_holder_type_prop_4\n",
      "Исходный признак pre_pterm\n",
      "Новые фичи\n",
      "pre_pterm_prop_6\n",
      "pre_pterm_prop_3\n",
      "Исходный признак is_zero_loans530\n",
      "Новые фичи\n",
      "is_zero_loans530_prop_1\n",
      "Исходный признак enc_paym_0\n",
      "Новые фичи\n",
      "enc_paym_0_prop_1\n",
      "Исходный признак pre_loans_credit_cost_rate\n",
      "Новые фичи\n",
      "pre_loans_credit_cost_rate_prop_6\n",
      "pre_loans_credit_cost_rate_prop_11\n",
      "pre_loans_credit_cost_rate_prop_4\n",
      "Исходный признак pre_loans_next_pay_summ\n",
      "Новые фичи\n",
      "pre_loans_next_pay_summ_prop_5\n",
      "pre_loans_next_pay_summ_prop_0\n",
      "Исходный признак is_zero_over2limit\n",
      "Новые фичи\n",
      "is_zero_over2limit_prop_1\n",
      "Исходный признак pre_loans_outstanding\n",
      "Новые фичи\n",
      "pre_loans_outstanding_prop_1\n",
      "pre_loans_outstanding_prop_5\n",
      "Исходный признак pre_util\n",
      "Новые фичи\n",
      "pre_util_prop_3\n",
      "pre_util_prop_6\n",
      "Исходный признак pre_till_pclose\n",
      "Новые фичи\n",
      "pre_till_pclose_prop_10\n",
      "pre_till_pclose_prop_7\n",
      "Исходный признак is_zero_loans5\n",
      "Новые фичи\n",
      "is_zero_loans5_prop_1\n",
      "Исходный признак pre_since_confirmed\n",
      "Новые фичи\n",
      "pre_since_confirmed_prop_4\n",
      "pre_since_confirmed_prop_7\n",
      "Исходный признак pre_loans_credit_limit\n",
      "Новые фичи\n",
      "pre_loans_credit_limit_prop_2\n",
      "pre_loans_credit_limit_prop_15\n",
      "pre_loans_credit_limit_prop_18\n",
      "Исходный признак pre_over2limit\n",
      "Новые фичи\n",
      "pre_over2limit_prop_17\n",
      "Исходный признак pre_till_fclose\n",
      "Новые фичи\n",
      "pre_till_fclose_prop_4\n",
      "pre_till_fclose_prop_3\n",
      "pre_till_fclose_prop_1\n",
      "Исходный признак enc_loans_credit_status\n",
      "Новые фичи\n",
      "enc_loans_credit_status_prop_5\n",
      "Исходный признак pre_since_opened\n",
      "Новые фичи\n",
      "pre_since_opened_prop_12\n",
      "pre_since_opened_prop_8\n",
      "pre_since_opened_prop_19\n",
      "Исходный признак enc_paym_24\n",
      "Новые фичи\n",
      "enc_paym_24_prop_1\n",
      "Исходный признак pre_loans_max_overdue_sum\n",
      "Новые фичи\n",
      "pre_loans_max_overdue_sum_prop_1\n",
      "Исходный признак enc_loans_credit_type\n",
      "Новые фичи\n",
      "enc_loans_credit_type_prop_0\n",
      "enc_loans_credit_type_prop_2\n",
      "Исходный признак pre_fterm\n",
      "Новые фичи\n",
      "pre_fterm_prop_7\n",
      "pre_fterm_prop_3\n",
      "Исходный признак is_zero_loans3060\n",
      "Новые фичи\n",
      "is_zero_loans3060_prop_1\n",
      "Исходный признак is_zero_loans6090\n",
      "Новые фичи\n",
      "is_zero_loans6090_prop_1\n",
      "Исходный признак is_zero_loans90\n",
      "Новые фичи\n",
      "is_zero_loans90_prop_1\n",
      "FUNCTION from_is_zero_prop_1_create_sum_prop_1_feature_pipeline \n",
      "FUNCTION mean_value_frequency_feature_pipeline \n",
      "new_column pre_util_mean_freq\n",
      "new_column pre_loans_credit_limit_mean_freq\n",
      "new_column pre_since_opened_mean_freq\n",
      "new_column pre_loans_credit_cost_rate_mean_freq\n",
      "new_column enc_loans_credit_type_mean_freq\n",
      "new_column pre_loans_next_pay_summ_mean_freq\n",
      "new_column pre_since_confirmed_mean_freq\n",
      "new_column pre_pterm_mean_freq\n",
      "new_column enc_paym_0_mean_freq\n",
      "new_column enc_loans_account_holder_type_mean_freq\n",
      "new_column pre_loans530_mean_freq\n",
      "new_column enc_paym_8_mean_freq\n",
      "new_column pre_loans5_mean_freq\n",
      "new_column enc_paym_10_mean_freq\n",
      "new_column enc_loans_account_cur_mean_freq\n",
      "new_column enc_paym_9_mean_freq\n",
      "FUNCTION enc_paym_norm_group_sum_diff_pipeline\n",
      "new_column enc_paym_avg_1_all\n",
      "new_column enc_paym_avg_2_all\n",
      "new_column enc_paym_avg_0_this_year\n",
      "new_column enc_paym_avg_1_this_year\n",
      "new_column enc_paym_avg_0_last_year\n",
      "new diff columns\n",
      "enc_paym_avg_0_1_this_year_diff\n",
      "enc_paym_avg_1_2_all_diff\n",
      "enc_paym_avg_0_years_diff\n",
      "FUNCTION pre_since_opened_sum_mean_repeated_pipeline \n",
      "FUNCTION drop_columns_drop_duplicates_pipeline \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Предскажем класс 1\n",
    "pred = main_pipe.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10464883-970a-4a9e-a3b3-4c72b0a863db",
   "metadata": {},
   "source": [
    "git commit -m \"Create classifier, change preprocessing functions\" -m \"- Add ClassifierMixin, pickle, StratifiedKFold, CatBoostClassifier, Pool imports \n",
    "- Replace imports in the order of PEP 8\n",
    "- Create CatBoostEnsembleClassifier\n",
    "- Create the list of hyperparameters of models\n",
    "- Create the list of weights of models\n",
    "- Change lambda functions in preprocessing to named functions\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
