# Credit Scoring with CatBoost Ensemble
*Кредитный скоринг с ансамблем CatBoost*

---

## English Summary
This project implements a credit scoring system to predict client default risk using an ensemble of six CatBoost classifiers. Five models are trained on separate subsets of the training data, each with hyperparameters individually optimized using Optuna. The sixth model is trained on the full training data, with hyperparameters selected from the fold that achieved the highest validation AUC score.

 Final predictions are weighted averages of the predicted class probabilities (predict_proba) based on the validation AUC scores of the models, with the sixth model’s weight computed as the average AUC across its folds. 
 
 To obtain the final binary prediction (0 or 1), a threshold is selected in one of two ways: by maximizing the difference between true positive rate (TPR) and false positive rate (FPR), corresponding to the optimal point on the ROC curve, or by setting a minimum required TPR, allowing the model to be adapted to specific business requirements.

 This educational project completes the Junior ML Engineer course and serves as a portfolio showcase.

---

## Краткое описание проекта

Данный проект реализует систему кредитного скоринга для предсказания риска дефолта клиентов с помощью ансамбля из шести моделей CatBoost. Пять моделей обучены на отдельных непересекающихся частях тренировочных данных, каждая с индивидуально подобранными гиперпараметрами с использованием Optuna. Шестая модель обучена на полном тренировочном наборе, при этом её гиперпараметры — это параметры фолда с наивысшим значением метрики AUC на валидации.

Итоговые предсказания вероятностей классов (predict_proba) формируются как взвешенное среднее , где веса моделей пропорциональны их AUC на валидационных данных, а вес шестой модели вычисляется как среднее значение AUC по её фолдам.

Для получения итогового бинарного предсказания (0 или 1) используется порог, который подбирается двумя способами: по максимальной разнице между полнотой (TPR) и долей ложноположительных результатов (FPR), соответствующей оптимальной точке ROC-кривой, либо исходя из заданного минимального значения полноты (TPR), что позволяет адаптировать модель под бизнес-требования.

Проект является учебным, завершает курс Junior ML Engineer и служит основой портфолио.
---

## Требования / Requirements

- В проэкте использовалась версия Python 3.12.
- Рекомендуется использовать Python 3.12 или выше, так как эта версия содержит важные улучшения производительности и удобства, 
  а также уже получила широкую поддержку основных библиотек.
- Для установки зависимостей используйте файл `requirements.txt`:
```shell
pip install -r requirements.txt
```

- Для работы с исходными файлами датасета в папке `train_data`  
  используется [Git Large File Storage (Git LFS)](https://git-lfs.github.com/).  
  Перед клонированием репозитория убедитесь, что Git LFS установлен и инициализирован:
```shell
git lfs install
```
---

## Установка и запуск / Getting Started

1. Клонируйте репозиторий:  
```shell
git clone <url-репозитория> 
```

2. Создайте и активируйте виртуальное окружение: 
```shell
python -m venv venv
source venv/bin/activate # Linux/Mac
venv\Scripts\activate # Windows
``` 

3. Установите зависимости:  
```shell
pip install -r requirements.txt
```
4. Запустите Jupyter Notebooks из папки `notebooks` и выполняйте ячейки по порядку.

---

## Структура проекта / Project Structure

- `description.xlsx` – файл с описанием признаков исходного датасета.
- `notebooks/` — папка с Jupyter ноутбуками:
  - `data_preparation_and_modeling.ipynb` - анализ данных, создание признаков,  
    оптимизация гиперпараметров моделей ансамбля, визуализации.  
  - `pipeline.ipynb` - пайплайн обработки данных и обучения моделей ансамбля.
- `pipeline/` - папка с результатами моделирования:
  - `trained_pipeline.pkl`- файл с обученным пайплайном,  
  - `test_predict.pkl` - файл с предсказынными классами на тестовых данных,  
  - `test_predict_proba.pkl` - файл с предсказанными вероятностями классов на тестовых данных.
- `README.md` - файл с описанием проекта, инструкциями по установке и использованию.
- `requirements.txt` — список зависимостей.
- `train_data` - папка с исходными файлами датасета в формате Parquet (`.pq`).
- `train_target.csv` - файл с целевой переменной.
- `Методические указания к итоговому проекту «Модель кредитного риск-менеджмента».pdf` -  
  файл с описанием задания к проекту, требованиями и рекомендациями по выполнению.

---

## Особенности реализации / Implementation Details

В проекте реализован полный цикл построения модели для предсказания дефолта клиента:
от сборки исходного датасета из разрозненных Parquet-файлов, генерации признаков, 
последующим отбором наиболее информативных признаков 
и оптимизацией гиперпараметров моделей ансамбля,
до создания пайплайна, который автоматизирует обработку данных и обучение ансамбля моделей.

Размер исходного датасета составлял 26 162 717 строк и 61 столбец.
Количество уникальных клиентов (ID) — 3 000 000.
Датасет с целевой переменной (информация о дефолте клиента) содержит 3 000 000 
записей — по одному значению на каждого уникального клиента.

Таким образом, исходные данные представлены на уровне кредитных договоров,
в то время как целевая переменная задана на уровне клиентов. 
Это потребовало выполнения агрегирования признаков по каждому клиенту и последующего объединения с целевой переменной.

Коэффициент дисбаланса целевой переменной составлял примерно 27. 
Для компенсации дисбаланса в моделях применялся параметр auto_class_weights='Balanced'.
Другие методы балансировки, такие как оверсемплинг и андерсемплинг, не использовались по следующим причинам:
оверсемплинг приводил к значительному увеличению объёма обучающего датасета, что усложняло и замедляло обучение,
а андерсемплинг существенно сокращал количество данных, что приводило к ухудшению качества моделей.

Датасет с целевой переменной был изначально разделён на обучающую и тестовую выборки в соотношении 80/20 с применением стратификации. 
На основе этого разделения исходный датасет также был разбит, и тренировочные и тестовые подвыборки обрабатывались отдельно.

Основной сложностью проекта стало то, что исходные данные были представлены преимущественно в бинаризованном и закодированном виде.

- Бинаризация — область значений признака разбивается на N непересекающихся интервалов,  
  каждому из которых случайным образом присваивается уникальный номер от 0 до N-1.  
  Значения признака заменяются номерами соответствующих интервалов.

- Кодирование — каждому уникальному значению признака случайным образом
  присваивается уникальный номер от 0 до K, и значения признака заменяются этими номерами.

Бинаризация существенно искажает количественную информацию: после неё нельзя утверждать, что большее значение бинаризованного признака соответствует большему (или меньшему) исходному значению. Признаки превращаются в индикаторы принадлежности к определённому интервалу, теряя количественный смысл.

Кодирование сохраняет больше информации, но также не гарантирует упорядоченности значений: номера не отражают количественные отношения между исходными значениями.

В связи с этим для построения признаков тренировочного датасета основной упор был сделан на частотные свойства значений признаков.

Одним из основных методов построения признаков было создание для каждого уникального значения исходного признака числового признака, отражающего частоту встречаемости этого значения у клиента. Поскольку количество записей (кредитов) на каждого клиента различалось, полученные признаки нормировались на общее число записей данного клиента для нивелирования этой разницы.  
Для каждого исходного признака формировался отдельный мини-датасет с такими признаками, на котором обучался классификатор CatBoost с 5-кратной стратифицированной кросс-валидацией. По итогам обучения из каждого мини-датасета отбирались 2–3 наиболее информативных признака, которые включались в итоговый тренировочный датасет.

Вторым основным методом построения признаков является создание агрегированного признака, отражающего среднюю относительную частоту значений заданного столбца для каждого клиента (id). Для этого вычисляется частота встречаемости каждого уникального значения в исходном датасете, затем для каждого клиента эти частоты суммируются  и нормируются на количество записей клиента.

Самым важным признаком для модели оказался агрегированный для каждого клиента показатель, отражающий разницу между средним количеством статусов платежей 0 и 1 за последние 12 месяцев (enc_paym_avg_0_1_this_year_diff).
Этот признак вычисляется как разница между средней частотой «статуса 0»  и «статуса 1» на один кредит в течение года.  
Он позволяет модели улавливать динамику и соотношение между разными типами платежных статусов за последнее время.

Самым важным для модели признаком стал агрегированный для каждого клиента показатель — разница между средним количеством статусов платежей 0 и 1 за последние 12 месяцев (enc_paym_avg_0_1_this_year_diff).  
Этот признак вычисляется как разница средней частоты «статуса 0» и «статуса 1» на один кредит за год и позволяет модели улавливать динамику и соотношение между разными типами платежных статусов, отражая изменения в поведении клиента за последнее время.

<img src="images/exampleScreenshot 2025-07-09 at 10.26.34.png" alt="Feature importance visualization" width="400" />


### Общая схема построения и оценки признаков. 

Исходные признаки обрабатывались группами по типам: бинаризированные, закодированные, статусы ежемесячных платежей, флаги. Несколько признаков создавались  обособленно. После создания каждой новой группы признаков проводилась оценка их влияния на качество модели с помощью функции check_cat_boost.

Эта функция реализует 5-кратную стратифицированную кросс-валидацию модели CatBoost, вычисляет метрику ROC AUC на тренировочном, валидационном и тестовом наборах,  а также аккумулирует важности признаков. Результаты оценки сохранялись в датафрейм для удобного сравнения. 

Важности признаков вычислялись для визуальной оценки распределения их вклада в модель и для определения количества признаков с очень низким или нулевым влиянием на качество. При этом признаки с низкой важностью не удалялись автоматически.

После генерации всех признаков проводился их отбор: сначала удалялись признаки с вкладом в качество модели менее 1%, затем из мультиколлинеарных групп (корреляция выше 0.7 по модулю) оставлялись только те признаки, которые давали наибольший прирост качества.

Такой подход позволил сформировать компактный и информативный набор признаков, обеспечивающий требуемое качество кредитного скоринга.

Изначально было создано 216 признаков.
После отбора по вкладу в качество осталось 136 признаков.
После отбора по мультиколлинеарности осталось 59 признаков.

### Построение и оценка моделей.

В проекте реализованы две схемы построения ансамблей моделей с использованием CatBoost  
и автоматическим подбором гиперпараметров через Optuna (используется TPE-сэмплер и pruning):

1. Агрессивная схема.
- Для каждого из 5 фолдов выполняется автоматический подбор гиперпараметров.
- Финальная модель обучается на объединённых тренировочных и валидационных данных с оптимальными параметрами.
- Для тестовой выборки формируется средневзвешенное предсказание ансамбля.  
  Весами для моделей служат их AUC на валидационных выборках.

Такая схема максимально использует данные для обучения и часто применяется на соревнованиях,  
но может приводить к переобучению и снижению стабильности при применении модели на новых данных.

2. Классическая (консервативная) схема.
- Для каждого фолда подбираются гиперпараметры и обучается модель только на тренировочной части фолда.
- Оценивается AUC на валидационной выборке.
- По результатам оценки фолдов выбираются гиперпараметры самого результативного и на них обучается финальная модель на всех тренировочных данных.
- Для тестовой выборки формируется средневзвешенное предсказание ансамбля, включающего модели фолдов и финальную модель.
  Весами для моделей фолдов служат их AUC на валидационных выборках, а вес финальной модели равен среднему арифметическому AUC всех фолдов.

Эта схема более надёжна и лучше отражает реальный алгоритм применения модели.

Итоги:  
Обе схемы показали практически одинаковое качество на тесте (AUC ~0.7572).
В пайплайне выбран классический подход как более стабильный и интерпретируемый метод.
Использование Optuna с TPE и pruning позволило эффективно подобрать гиперпараметры, ускоряя обучение и снижая риск переобучения.
Результаты оптимизации сохраняются в базе SQLite для возможности возобновления обучения при прерывании.


---

## Результаты

- Модель достигает заданного уровня полноты (TPR) по дефолтным заемщикам, минимизируя пропуск рисковых клиентов.  
- Подбор порога позволяет контролировать баланс между риском и количеством ложных отказов.

---

## Автор

Ваше Имя — ваш.email@example.com

---

## Лицензия

Укажите лицензию, если необходимо (например, MIT License).

---
