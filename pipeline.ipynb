{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc7f2eb-e995-4512-9e68-06681dc26b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import re\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "695f7092-6790-43f7-9177-1e2d4ea6ddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём внутреннюю папку проекта\n",
    "os.makedirs('pipeline', exist_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a991711a-05f4-4b8a-a3bc-11faa01c8919",
   "metadata": {},
   "source": [
    "# Lists of features for the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda82a61-1a8a-4f84-b873-d53bed7ab196",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Basic lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd86d03c-70ae-4b3c-8a89-abb51550015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rn - уникальный признак\n",
    "\n",
    "# Бинаризированные\n",
    "pre_features = [\n",
    "    'pre_since_opened',\n",
    "    'pre_since_confirmed',\n",
    "    'pre_pterm',\n",
    "    'pre_fterm',\n",
    "    'pre_till_pclose',\n",
    "    'pre_till_fclose',\n",
    "    'pre_loans_credit_limit',\n",
    "    'pre_loans_next_pay_summ',\n",
    "    'pre_loans_outstanding',\n",
    "    'pre_loans_max_overdue_sum',\n",
    "    'pre_loans_credit_cost_rate',\n",
    "    'pre_loans5',\n",
    "    'pre_loans530',\n",
    "    'pre_loans3060',\n",
    "    'pre_loans6090',\n",
    "    'pre_loans90',\n",
    "    'pre_util',\n",
    "    'pre_over2limit',\n",
    "    'pre_maxover2limit'\n",
    "]\n",
    "\n",
    "# Закодированные\n",
    "enc_features = [\n",
    "    'enc_loans_account_holder_type',\n",
    "    'enc_loans_credit_status',\n",
    "    'enc_loans_credit_type',\n",
    "    'enc_loans_account_cur'\n",
    "]\n",
    "\n",
    "# Статусы ежемесячных платежей\n",
    "enc_paym_features = [\n",
    "    'enc_paym_0',\n",
    "    'enc_paym_1',\n",
    "    'enc_paym_2',\n",
    "    'enc_paym_3',\n",
    "    'enc_paym_4',\n",
    "    'enc_paym_5',\n",
    "    'enc_paym_6',\n",
    "    'enc_paym_7',\n",
    "    'enc_paym_8',\n",
    "    'enc_paym_9',\n",
    "    'enc_paym_10',\n",
    "    'enc_paym_11',\n",
    "    'enc_paym_12',\n",
    "    'enc_paym_13',\n",
    "    'enc_paym_14',\n",
    "    'enc_paym_15',\n",
    "    'enc_paym_16',\n",
    "    'enc_paym_17',\n",
    "    'enc_paym_18',\n",
    "    'enc_paym_19',\n",
    "    'enc_paym_20',\n",
    "    'enc_paym_21',\n",
    "    'enc_paym_22',\n",
    "    'enc_paym_23',\n",
    "    'enc_paym_24'\n",
    "]\n",
    "\n",
    "#  Флаги\n",
    "flag_features = [\n",
    "    'is_zero_loans5',\n",
    "    'is_zero_loans530',\n",
    "    'is_zero_loans3060',\n",
    "    'is_zero_loans6090',\n",
    "    'is_zero_loans90',\n",
    "    'is_zero_util',\n",
    "    'is_zero_over2limit',\n",
    "    'is_zero_maxover2limit',\n",
    "    'pclose_flag',\n",
    "    'fclose_flag'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1809be45-ffa0-479d-ab99-ed02a40fd67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20931476, 61)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source = pd.read_csv('prepared_data/source_data_train_1.csv')\n",
    "df_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fcd5991d-f0bb-4517-a2cd-36620a1315c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400000, 61)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.read_csv('prepared_data/cut_corr_imp_train.csv')\n",
    "df_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2bf0aa41-c0dd-4ed2-8534-66510b827c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'rn',\n",
       " 'pre_since_opened',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'pre_fterm',\n",
       " 'pre_till_pclose',\n",
       " 'pre_till_fclose',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_loans_next_pay_summ']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source_columns = df_source.columns.tolist()\n",
    "df_source_columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9cd7d089-961c-4f50-8027-fa8d06f64510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'flag',\n",
       " 'is_zero_sum_prop_1',\n",
       " 'enc_paym_avg_0_1_this_year_diff',\n",
       " 'pre_util_prop_3',\n",
       " 'enc_loans_credit_type_prop_0',\n",
       " 'pre_till_pclose_prop_10',\n",
       " 'pre_util_prop_6',\n",
       " 'pre_loans_outstanding_prop_1',\n",
       " 'pre_util_mean_freq']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_columns = df_result.columns.tolist()\n",
    "df_result_columns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28d7a8-c441-4630-9174-d5e2086a0c19",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## List of features to download from the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fbf36f36-3bbf-4834-9a5d-f23dd1d5f796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pre_loans_total_overdue',\n",
       " 'pre_loans3060',\n",
       " 'pre_loans6090',\n",
       " 'pre_loans90',\n",
       " 'is_zero_loans3060',\n",
       " 'is_zero_loans6090',\n",
       " 'is_zero_loans90',\n",
       " 'pre_maxover2limit',\n",
       " 'is_zero_util',\n",
       " 'is_zero_maxover2limit',\n",
       " 'enc_paym_3',\n",
       " 'enc_paym_4',\n",
       " 'enc_paym_5',\n",
       " 'enc_paym_6',\n",
       " 'enc_paym_7',\n",
       " 'enc_paym_11',\n",
       " 'enc_paym_12',\n",
       " 'enc_paym_13',\n",
       " 'enc_paym_14',\n",
       " 'enc_paym_15',\n",
       " 'enc_paym_16',\n",
       " 'enc_paym_17',\n",
       " 'enc_paym_18',\n",
       " 'enc_paym_19',\n",
       " 'enc_paym_20',\n",
       " 'enc_paym_21',\n",
       " 'enc_paym_22',\n",
       " 'enc_paym_23',\n",
       " 'pclose_flag',\n",
       " 'fclose_flag']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Формируем список колонок из df_source_columns,\n",
    "которые НЕ встречаются ни в одном названии из df_result_columns как подстрока.\n",
    "\"\"\"\n",
    "drop_list = []\n",
    "for col_source in df_source_columns:\n",
    "    found = False\n",
    "    for col_result in df_result_columns:\n",
    "        if col_source in col_result:\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        drop_list.append(col_source)\n",
    "\n",
    "print(len(drop_list))\n",
    "drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2bd47bf9-694c-4bfd-acec-fa2ae3ab047f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'rn',\n",
       " 'pre_since_opened',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'pre_fterm',\n",
       " 'pre_till_pclose',\n",
       " 'pre_till_fclose',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_loans_next_pay_summ']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_columns = [x for x in df_source_columns if x not in drop_list]\n",
    "\n",
    "print(len(needed_columns))\n",
    "needed_columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84483ca2-71ed-41d2-b503-624f146a9458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'rn',\n",
       " 'pre_since_opened',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'pre_fterm',\n",
       " 'pre_till_pclose',\n",
       " 'pre_till_fclose',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_loans_next_pay_summ']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Добавим недостающие признаки из групп flag_features и enc_paym _features, \n",
    "для правильной работы функций обрабатывающих эти группы. \n",
    "\"\"\"\n",
    "features_list= [\n",
    "    'is_zero_loans3060',\n",
    "    'is_zero_loans6090',\n",
    "    'is_zero_loans90',\n",
    "    'enc_paym_3',\n",
    "    'enc_paym_4',\n",
    "    'enc_paym_5',\n",
    "    'enc_paym_6',\n",
    "    'enc_paym_7',\n",
    "    'enc_paym_11',\n",
    "    'enc_paym_12',\n",
    "    'enc_paym_13',\n",
    "    'enc_paym_14',\n",
    "    'enc_paym_15',\n",
    "    'enc_paym_16',\n",
    "    'enc_paym_17',\n",
    "    'enc_paym_18',\n",
    "    'enc_paym_19',\n",
    "    'enc_paym_20',\n",
    "    'enc_paym_21',\n",
    "    'enc_paym_22',\n",
    "    'enc_paym_23'\n",
    "]\n",
    "\n",
    "# Список признаков для скачивания из исходного датасета\n",
    "needed_columns = needed_columns + features_list\n",
    "\n",
    "print(len(needed_columns))\n",
    "needed_columns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d67d7-625f-4cde-9d97-0a2905017239",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create_definite_value_proportion_features_pipeline funtion list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b8918094-ea0a-43db-99db-cd070b4b5bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['is_zero_sum_prop_1',\n",
       " 'pre_util_prop_3',\n",
       " 'enc_loans_credit_type_prop_0',\n",
       " 'pre_till_pclose_prop_10',\n",
       " 'pre_util_prop_6',\n",
       " 'pre_loans_outstanding_prop_1',\n",
       " 'pre_loans_credit_limit_prop_2',\n",
       " 'pre_loans_credit_cost_rate_prop_6',\n",
       " 'pre_loans_outstanding_prop_5',\n",
       " 'pre_loans_credit_cost_rate_prop_11',\n",
       " 'pre_loans_credit_cost_rate_prop_4',\n",
       " 'pre_loans_next_pay_summ_prop_5',\n",
       " 'pre_since_opened_prop_12',\n",
       " 'pre_loans_credit_limit_prop_15',\n",
       " 'enc_loans_credit_type_prop_2',\n",
       " 'pre_fterm_prop_7',\n",
       " 'enc_paym_0_prop_1',\n",
       " 'is_zero_over2limit_prop_1',\n",
       " 'pre_since_opened_prop_8',\n",
       " 'pre_loans_max_overdue_sum_prop_1',\n",
       " 'pre_loans_next_pay_summ_prop_0',\n",
       " 'pre_pterm_prop_6',\n",
       " 'pre_since_opened_prop_19',\n",
       " 'is_zero_loans5_prop_1',\n",
       " 'enc_loans_account_holder_type_prop_4',\n",
       " 'pre_loans_credit_limit_prop_18',\n",
       " 'pre_till_fclose_prop_4',\n",
       " 'pre_pterm_prop_3',\n",
       " 'is_zero_loans530_prop_1',\n",
       " 'enc_loans_credit_status_prop_5',\n",
       " 'pre_since_confirmed_prop_4',\n",
       " 'pre_fterm_prop_3',\n",
       " 'pre_till_fclose_prop_3',\n",
       " 'pre_till_fclose_prop_1',\n",
       " 'pre_till_pclose_prop_7',\n",
       " 'pre_since_confirmed_prop_7',\n",
       " 'enc_paym_24_prop_1',\n",
       " 'pre_over2limit_prop_17']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим список пропорциональных фичей в итоговом датасете\n",
    "prop_features_result_list = [col for col in df_result_columns if 'prop_' in col]\n",
    "\n",
    "print(len(prop_features_result_list))\n",
    "prop_features_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "864d11b8-b29a-4cf7-8e75-1c82fa30f7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pre_till_pclose',\n",
       " 'is_zero_loans5',\n",
       " 'pre_since_opened',\n",
       " 'enc_loans_credit_type',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_fterm',\n",
       " 'pre_till_fclose',\n",
       " 'enc_paym_24',\n",
       " 'enc_paym_0',\n",
       " 'enc_loans_credit_status',\n",
       " 'pre_loans_max_overdue_sum',\n",
       " 'enc_loans_account_holder_type',\n",
       " 'pre_loans_outstanding',\n",
       " 'pre_loans_credit_cost_rate',\n",
       " 'is_zero_over2limit',\n",
       " 'pre_util',\n",
       " 'pre_loans_next_pay_summ',\n",
       " 'is_zero_sum',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_over2limit',\n",
       " 'is_zero_loans530',\n",
       " 'pre_pterm']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим список признаков исходного датасета из которых были сделаны пропорциональные фичи\n",
    "prop_features_source_list = list(\n",
    "    set(\n",
    "        [\n",
    "            re.sub(r'_prop.*$', '', col)\n",
    "            for col in prop_features_result_list\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(len(prop_features_source_list))\n",
    "prop_features_source_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c5e70c9-1efe-4c0d-ab60-9e90553339f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pre_till_pclose': [10, 7],\n",
       " 'is_zero_loans5': [1],\n",
       " 'pre_since_opened': [12, 8, 19],\n",
       " 'enc_loans_credit_type': [0, 2],\n",
       " 'pre_since_confirmed': [4, 7],\n",
       " 'pre_fterm': [7, 3],\n",
       " 'pre_till_fclose': [4, 3, 1],\n",
       " 'enc_paym_24': [1],\n",
       " 'enc_paym_0': [1],\n",
       " 'enc_loans_credit_status': [5],\n",
       " 'pre_loans_max_overdue_sum': [1],\n",
       " 'enc_loans_account_holder_type': [4],\n",
       " 'pre_loans_outstanding': [1, 5],\n",
       " 'pre_loans_credit_cost_rate': [6, 11, 4],\n",
       " 'is_zero_over2limit': [1],\n",
       " 'pre_util': [3, 6],\n",
       " 'pre_loans_next_pay_summ': [5, 0],\n",
       " 'is_zero_sum': [1],\n",
       " 'pre_loans_credit_limit': [2, 15, 18],\n",
       " 'pre_over2limit': [17],\n",
       " 'is_zero_loans530': [1],\n",
       " 'pre_pterm': [6, 3]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Соберем часть словаря пропорциональных фичей для пайплайна\n",
    "prop_features_dict = {}\n",
    "\n",
    "for source_col in prop_features_source_list:\n",
    "    # Инициализируем пустой список для каждого исходного признака\n",
    "    prop_features_dict[source_col] = []\n",
    "    # Создадим паттерн: имя col в начале и после него подчёркивание или конец строки\n",
    "    pattern = re.compile(r'^' + source_col + r'(_|$)')\n",
    "    for result_col in prop_features_result_list:\n",
    "        # Проверяем, совпадает ли имя признака с паттерном\n",
    "        if pattern.match(result_col):\n",
    "            # Ищем число в конце строки\n",
    "            match = re.search(r'(\\d+)$', result_col)\n",
    "            # Добавляем найденное число в список для данного source_col\n",
    "            prop_features_dict[source_col].append(int(match.group(1)))\n",
    "prop_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6776ea8b-4970-440c-b8ac-c93930ca9652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pre_till_pclose': [10, 7],\n",
       " 'is_zero_loans5': [1],\n",
       " 'pre_since_opened': [12, 8, 19],\n",
       " 'enc_loans_credit_type': [0, 2],\n",
       " 'pre_since_confirmed': [4, 7],\n",
       " 'pre_fterm': [7, 3],\n",
       " 'pre_till_fclose': [4, 3, 1],\n",
       " 'enc_paym_24': [1],\n",
       " 'enc_paym_0': [1],\n",
       " 'enc_loans_credit_status': [5],\n",
       " 'pre_loans_max_overdue_sum': [1],\n",
       " 'enc_loans_account_holder_type': [4],\n",
       " 'pre_loans_outstanding': [1, 5],\n",
       " 'pre_loans_credit_cost_rate': [6, 11, 4],\n",
       " 'is_zero_over2limit': [1],\n",
       " 'pre_util': [3, 6],\n",
       " 'pre_loans_next_pay_summ': [5, 0],\n",
       " 'pre_loans_credit_limit': [2, 15, 18],\n",
       " 'pre_over2limit': [17],\n",
       " 'is_zero_loans530': [1],\n",
       " 'pre_pterm': [6, 3],\n",
       " 'is_zero_loans3060': [1],\n",
       " 'is_zero_loans6090': [1],\n",
       " 'is_zero_loans90': [1]}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Добавим в словарь недостающие is_zero_loans* для функции суммирования.\n",
    "Удалим is_zero_sum, фича is_zero_sum_prop_1 будет собираться другой функцией.\n",
    "\"\"\"\n",
    "is_zero_loans_list = [\n",
    "        'is_zero_loans5',\n",
    "        'is_zero_loans530',\n",
    "        'is_zero_loans3060',\n",
    "        'is_zero_loans6090',\n",
    "        'is_zero_loans90'\n",
    "    ]\n",
    "for col in is_zero_loans_list:\n",
    "    if col not in prop_features_dict.keys():\n",
    "        prop_features_dict[col] = [1]\n",
    "        \n",
    "del prop_features_dict['is_zero_sum']\n",
    "\n",
    "prop_features_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0a3e3f-a04f-4cb9-a28e-309b435f2cb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## List for create_mean_value_frequency_feature_pipeline features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e3344e24-9ffb-45ca-ab41-0f8e2ee01700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pre_util_mean_freq',\n",
       " 'pre_loans_credit_limit_mean_freq',\n",
       " 'pre_since_opened_mean_freq',\n",
       " 'pre_loans_credit_cost_rate_mean_freq',\n",
       " 'enc_loans_credit_type_mean_freq',\n",
       " 'pre_loans_next_pay_summ_mean_freq',\n",
       " 'pre_since_confirmed_mean_freq',\n",
       " 'pre_pterm_mean_freq',\n",
       " 'enc_paym_0_mean_freq',\n",
       " 'enc_loans_account_holder_type_mean_freq',\n",
       " 'pre_loans530_mean_freq',\n",
       " 'enc_paym_8_mean_freq',\n",
       " 'pre_loans5_mean_freq',\n",
       " 'enc_paym_10_mean_freq',\n",
       " 'enc_loans_account_cur_mean_freq',\n",
       " 'enc_paym_9_mean_freq']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Соберем список всех фичей средней частотности в итоговом датасете\n",
    "mean_freq_result_list = [col for col in df_result_columns if 'mean_freq' in col]\n",
    "\n",
    "print(len(mean_freq_result_list))\n",
    "mean_freq_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ec18ab2-0503-4a84-8dd3-78be3f1457f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pre_util',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_since_opened',\n",
       " 'pre_loans_credit_cost_rate',\n",
       " 'enc_loans_credit_type',\n",
       " 'pre_loans_next_pay_summ',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'enc_paym_0',\n",
       " 'enc_loans_account_holder_type',\n",
       " 'pre_loans530',\n",
       " 'enc_paym_8',\n",
       " 'pre_loans5',\n",
       " 'enc_paym_10',\n",
       " 'enc_loans_account_cur',\n",
       " 'enc_paym_9']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Соберем список признаков исходного датасета \n",
    "из которых были сделаны фичи средней частотности.\n",
    "\"\"\"\n",
    "mean_freq_source_list = [x[:-len('_mean_freq')] for x in mean_freq_result_list]\n",
    "print(len(mean_freq_source_list))\n",
    "mean_freq_source_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b72342-98ab-45a1-842d-96c6a2b3de50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Drop list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "52afd524-3819-4222-8fcb-e2f1bb21ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_features_list = [\n",
    "    'enc_paym_avg_1_all',\n",
    "    'enc_paym_avg_2_all',\n",
    "    'enc_paym_avg_0_this_year',\n",
    "    'enc_paym_avg_1_this_year',\n",
    "    'enc_paym_avg_0_last_year',\n",
    "    'is_zero_loans3060_prop_1',\n",
    "    'is_zero_loans6090_prop_1',\n",
    "    'is_zero_loans90_prop_1'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf48c49b-bd63-40eb-9a6f-32f1e9a96fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'rn',\n",
       " 'pre_since_opened',\n",
       " 'pre_since_confirmed',\n",
       " 'pre_pterm',\n",
       " 'pre_fterm',\n",
       " 'pre_till_pclose',\n",
       " 'pre_till_fclose',\n",
       " 'pre_loans_credit_limit',\n",
       " 'pre_loans_next_pay_summ',\n",
       " 'pre_loans_outstanding',\n",
       " 'pre_loans_max_overdue_sum',\n",
       " 'pre_loans_credit_cost_rate',\n",
       " 'pre_loans5',\n",
       " 'pre_loans530',\n",
       " 'is_zero_loans5',\n",
       " 'is_zero_loans530',\n",
       " 'pre_util',\n",
       " 'pre_over2limit',\n",
       " 'is_zero_over2limit',\n",
       " 'enc_paym_0',\n",
       " 'enc_paym_1',\n",
       " 'enc_paym_2',\n",
       " 'enc_paym_8',\n",
       " 'enc_paym_9',\n",
       " 'enc_paym_10',\n",
       " 'enc_paym_24',\n",
       " 'enc_loans_account_holder_type',\n",
       " 'enc_loans_credit_status',\n",
       " 'enc_loans_credit_type',\n",
       " 'enc_loans_account_cur',\n",
       " 'is_zero_loans3060',\n",
       " 'is_zero_loans6090',\n",
       " 'is_zero_loans90',\n",
       " 'enc_paym_3',\n",
       " 'enc_paym_4',\n",
       " 'enc_paym_5',\n",
       " 'enc_paym_6',\n",
       " 'enc_paym_7',\n",
       " 'enc_paym_11',\n",
       " 'enc_paym_12',\n",
       " 'enc_paym_13',\n",
       " 'enc_paym_14',\n",
       " 'enc_paym_15',\n",
       " 'enc_paym_16',\n",
       " 'enc_paym_17',\n",
       " 'enc_paym_18',\n",
       " 'enc_paym_19',\n",
       " 'enc_paym_20',\n",
       " 'enc_paym_21',\n",
       " 'enc_paym_22',\n",
       " 'enc_paym_23',\n",
       " 'enc_paym_avg_1_all',\n",
       " 'enc_paym_avg_2_all',\n",
       " 'enc_paym_avg_0_this_year',\n",
       " 'enc_paym_avg_1_this_year',\n",
       " 'enc_paym_avg_0_last_year',\n",
       " 'is_zero_loans3060_prop_1',\n",
       " 'is_zero_loans6090_prop_1',\n",
       " 'is_zero_loans90_prop_1']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_list = needed_columns + temporary_features_list\n",
    "print(len(drop_list))\n",
    "drop_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3774b5-4a4d-417c-972e-6f998596816f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Downloading dataset and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cf6d693b-65ab-4f66-b7fd-93020e230eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# СКАЧИВАЕМ ИСХОДНЫЙ ДАТАСЕТ\n",
    "\n",
    "def read_parquet_dataset_from_local(\n",
    "    path_to_dataset: str,\n",
    "    start_from: int = 0,\n",
    "    num_parts_to_read: int = 2,\n",
    "    columns: Optional[List[str]] = None,\n",
    "    verbose: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Читает num_parts_to_read партиций, преобразовывает их к pd.DataFrame и возвращает.\n",
    "\n",
    "    Args:\n",
    "        path_to_dataset : путь до директории с партициями\n",
    "        start_from : номер партиции, с которой нужно начать чтение\n",
    "        num_parts_to_read : количество партиций, которые требуется прочитать\n",
    "        columns : список колонок, которые нужно прочитать из партиции\n",
    "        verbose : выводить ли дополнительную информацию\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    dataset_paths = sorted(\n",
    "        os.path.join(path_to_dataset, filename)\n",
    "        for filename in os.listdir(path_to_dataset)\n",
    "        if filename.startswith('train')\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print('Dataset paths:')\n",
    "        for path in dataset_paths:\n",
    "            print(path)\n",
    "\n",
    "    start_from = max(0, start_from)\n",
    "    chunks = dataset_paths[start_from: start_from + num_parts_to_read]\n",
    "\n",
    "    if verbose:\n",
    "        print('Reading chunks:')\n",
    "        for chunk in chunks:\n",
    "            print(chunk)\n",
    "\n",
    "    for chunk_path in tqdm(chunks, desc=\"Reading dataset with pandas\"):\n",
    "        if verbose:\n",
    "            print('Reading chunk:', chunk_path)\n",
    "        chunk = pd.read_parquet(chunk_path, columns=columns)\n",
    "        res.append(chunk)\n",
    "\n",
    "    return pd.concat(res).reset_index(drop=True)\n",
    "\n",
    "def prepare_transactions_dataset(\n",
    "    path_to_dataset: str,\n",
    "    num_parts_to_preprocess_at_once: int = 1,\n",
    "    num_parts_total: int = 50,\n",
    "    save_to_path: str = None,\n",
    "    verbose: bool = False,\n",
    "    columns: Optional[List[str]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Возвращает исходный pd.DataFrame с признаками из которых нужно собрать\n",
    "    учебный датасет.\n",
    "\n",
    "    Args:\n",
    "        path_to_dataset : путь до датасета с партициями\n",
    "        num_parts_to_preprocess_at_once : количество партиций, \n",
    "            которые будут одновременно держаться и обрабатываться в памяти\n",
    "        num_parts_total : общее количество партиций, которые нужно обработать\n",
    "        save_to_path : путь до папки для сохранения обработанных блоков в .parquet-формате; \n",
    "            если None, сохранение не происходит\n",
    "        verbose : логировать каждую обрабатываемую часть данных\n",
    "        columns : список колонок, которые нужно оставить\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame : датафрейм с объединёнными данными\n",
    "    \"\"\"\n",
    "    preprocessed_frames = []\n",
    "\n",
    "    for step in tqdm(range(0, num_parts_total, num_parts_to_preprocess_at_once),\n",
    "                     desc=\"Transforming transactions data\"):\n",
    "        transactions_frame = read_parquet_dataset_from_local(\n",
    "            path_to_dataset,\n",
    "            start_from=step,\n",
    "            num_parts_to_read=num_parts_to_preprocess_at_once,\n",
    "            verbose=verbose,\n",
    "            columns=columns\n",
    "        )\n",
    "\n",
    "       # Записываем подготовленные данные в файл\n",
    "        if save_to_path:\n",
    "            block_as_str = str(step)\n",
    "            if len(block_as_str) == 1:\n",
    "                block_as_str = '00' + block_as_str\n",
    "            else:\n",
    "                block_as_str = '0' + block_as_str\n",
    "            transactions_frame.to_parquet(os.path.join(save_to_path, f'processed_chunk_{block_as_str}.parquet'))\n",
    "\n",
    "        preprocessed_frames.append(transactions_frame)\n",
    "    \n",
    "    return pd.concat(preprocessed_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "938b8752-54e0-415c-9c1a-5345f1fe9210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e75eef828634b33b19fc6788d860e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transforming transactions data:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53835feaec37409da6c098cc4be665fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd762ebb46344431913b494021074fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e2e4cfda8e4aaba91d602a6be16968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ad74d9bdb54983a043bb08d2de7530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51fb18b57b24c51a594356b2d93030a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ed75073a6c4ecca78c846f91c5db11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6829b75940384b5b8be369c21752d502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14da6862958d43edacc381abc97650a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2e9cdc70d94f46b3b1dc4fd337b0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38ce4f0814a4ea09c7aeccb44bc56e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f8f8a9e92d4b9a826e46e6da972afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8caf252088274ae682526e21e9ac98e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading dataset with pandas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((20931476, 52), (5231241, 52), (2400000,), (600000,))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Собираем исходный датасет из parquet файлов,  \n",
    "скачиваем только необходимые колонки\n",
    "\"\"\"\n",
    "# Путь до данных в проекте\n",
    "path = 'train_data/'\n",
    "\n",
    "data = prepare_transactions_dataset(\n",
    "    path,\n",
    "    num_parts_to_preprocess_at_once=1,\n",
    "    num_parts_total=12,\n",
    "    save_to_path='train_data/',\n",
    "    columns=needed_columns) \n",
    "\n",
    "# Загружаем датасет с целевой переменной\n",
    "target = pd.read_csv('train_target.csv')\n",
    "\n",
    "# Делим датасет с целевой переменной на train/test части\n",
    "y_train, y_test  = train_test_split(target, train_size=0.8, random_state=0, stratify=target.flag)\n",
    "\n",
    "# Забираем наборы id из train/test\n",
    "train_id = y_train['id'].values\n",
    "test_id = y_test['id'].values\n",
    "\n",
    "# На основе наборов id делим исходный датасет на train/test части\n",
    "X_train = data.set_index('id').loc[train_id].reset_index()\n",
    "X_test = data.set_index('id').loc[test_id].reset_index()\n",
    "\n",
    "# Сбросим индексы для приведения к единому виду с X_train/X_test \n",
    "y_train = y_train.reset_index(drop=True)['flag']\n",
    "y_test = y_test.reset_index(drop=True)['flag']\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0392a984-602b-4c1a-a93f-17f0bba0c7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20931476, 52), (5231241, 52), (2400000,), (600000,))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохраним разделённые данные\n",
    "X_train.to_csv('pipeline/X_train.csv', index=False)\n",
    "X_test.to_csv('pipeline/X_test.csv', index=False)\n",
    "y_train.to_csv('pipeline/y_train.csv', index=False)\n",
    "y_test.to_csv('pipeline/y_test.csv', index=False)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30275359-2d00-4740-bb33-b80e8f7ba866",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de04b0b-97a3-4d55-a307-607e2b256633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030cda95-9d82-49ff-a878-adcfd4a3c301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0cd7962-3572-4930-99d7-c51655fe80de",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44231b7d-9226-4aad-a823-ffcbe7db8e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20931476, 52), (5231241, 52), (2400000, 1), (600000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем исходные разделённые данные \n",
    "X_train = pd.read_csv('pipeline/X_train.csv')\n",
    "X_test = pd.read_csv('pipeline/X_test.csv')\n",
    "y_train = pd.read_csv('pipeline/y_train.csv')\n",
    "y_test = pd.read_csv('pipeline/y_test.csv')\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb7646-a345-45b7-8bba-252d9a5af26d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6015c69-9e80-43fd-899c-5f7359fb8223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d69930a-45f8-4f89-b991-bfa15ed84c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20931476, 52)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Для полной проверки будем использовать копию тренировочных данных.\n",
    "\"\"\"\n",
    "X_train_full = X_train.copy()\n",
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2585a60f-ea6e-46d4-a562-c3662858e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "def convert_all_to_numeric_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Преобразует типы всех колоноки в числовые с заменой ошибок на NaN.\n",
    "\n",
    "    Args:\n",
    "        df: Исходный DataFrame, содержащий колонки 'id' и 'rn'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Копия исходного DataFrame с добавленной колонкой 'rn_max'.\n",
    "    \"\"\"\n",
    "    print('FUNCTION convert_all_to_numeric_pipeline ')\n",
    "    # Копируем датасет чтобы не изменять оригинал.\n",
    "    df = df.copy()\n",
    "    \n",
    "    return df.apply(lambda col: pd.to_numeric(col, errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3290d14-eac0-4546-a36a-1c5e59851111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGENERING FUNCTIONS\n",
    "\n",
    "def rn_max_feature_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Добавляет в DataFrame новую колонку 'rn_max' — максимальное \n",
    "    значение 'rn' для каждой группы 'id'.\n",
    "\n",
    "    Args:\n",
    "        df: Исходный DataFrame, содержащий колонки 'id' и 'rn'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Копия исходного DataFrame с добавленной колонкой 'rn_max'.\n",
    "    \"\"\"\n",
    "    print('FUNCTION rn_max_feature_pipeline')\n",
    "\n",
    "    \"\"\"\n",
    "    Для каждой строки определяем максимальное значение 'rn' среди всех строк с тем же 'id'\n",
    "    Метод transform('max') возвращает Series длины исходного DataFrame, где для каждой строки\n",
    "    указано максимальное значение 'rn' в её группе 'id'.\n",
    "    \"\"\"\n",
    "    df['rn_max'] = df.groupby('id')['rn'].transform('max')\n",
    "\n",
    "    return df\n",
    "\n",
    "def enc_paym_transcoding_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Прекодирует признаки enc_paym_features к единому виду с диапазоном значений {0, 1, 2, 3}.\n",
    "    Для каждого столбца enc_paym_0, enc_paym_1, ..., enc_paym_24, \n",
    "    если в значениях встречается 4, происходит замена:\n",
    "        1 -> 0\n",
    "        2 -> 1\n",
    "        3 -> 2\n",
    "        4 -> 3\n",
    "\n",
    "    Args:\n",
    "        df: Исходный DataFrame с колонками 'enc_paym_0' ... 'enc_paym_24'.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: Копия DataFrame с перекодированными признаками.\n",
    "    \"\"\"\n",
    "    print('FUNCTION enc_paym_transcoding_pipeline ')\n",
    "    \n",
    "    # Список колонок для перекодировки\n",
    "    columns = [f'enc_paym_{i}' for i in range(25)]\n",
    "    \n",
    "    for col in columns:\n",
    "        # Проверяем, есть ли значение 4 в колонке\n",
    "        if 4 in df[col].unique():\n",
    "            # Заменяем значения согласно маппингу\n",
    "            df.loc[:, col] = df[col].replace({1: 0, 2: 1, 3: 2, 4: 3})\n",
    "            \n",
    "    return df\n",
    "\n",
    "def definite_value_proportion_features_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Создаёт и добавляет в датафрейм новые частотные признаки \n",
    "    на основе заданных значений исходных признаков.\n",
    "    \n",
    "    Для каждого столбца и каждого указанного значения в словаре функция создаёт новые признаки, \n",
    "    отражающие долю записей с этим значением относительно общего количества \n",
    "    кредитов (rn_max) для каждого id.\n",
    "    \n",
    "    Args:\n",
    "        df: Исходный DataFrame, содержащий необходимые признаки и колонку 'rn_max'.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Копия исходного DataFrame с добавленными частотными признаками.\n",
    "    \"\"\"\n",
    "    print('FUNCTION definite_value_proportion_features_pipeline ')\n",
    "    \n",
    "    \"\"\"\n",
    "    Создадим словарь где для каждого признака перечислены значения,\n",
    "    по которым считаем долю.\n",
    "    \"\"\"\n",
    "    features_dictionary = {\n",
    "        'enc_loans_account_holder_type': [4],\n",
    "        'pre_pterm': [6, 3],\n",
    "        'is_zero_loans530': [1],\n",
    "        'enc_paym_0': [1],\n",
    "        'pre_loans_credit_cost_rate': [6, 11, 4],\n",
    "        'pre_loans_next_pay_summ': [5, 0],\n",
    "        'is_zero_over2limit': [1],\n",
    "        'pre_loans_outstanding': [1, 5],\n",
    "        'pre_util': [3, 6],\n",
    "        'pre_till_pclose': [10, 7],\n",
    "        'is_zero_loans5': [1],\n",
    "        'pre_since_confirmed': [4, 7],\n",
    "        'pre_loans_credit_limit': [2, 15, 18],\n",
    "        'pre_over2limit': [17],\n",
    "        'pre_till_fclose': [4, 3, 1],\n",
    "        'enc_loans_credit_status': [5],\n",
    "        'pre_since_opened': [12, 8, 19],\n",
    "        'enc_paym_24': [1],\n",
    "        'pre_loans_max_overdue_sum': [1],\n",
    "        'enc_loans_credit_type': [0, 2],\n",
    "        'pre_fterm': [7, 3],\n",
    "        'is_zero_loans3060': [1],\n",
    "        'is_zero_loans6090': [1],\n",
    "        'is_zero_loans90': [1]\n",
    "    }   \n",
    "\n",
    "    # Итерируем по ключам\n",
    "    for col in  features_dictionary.keys():\n",
    "        print('Исходный признак', col)\n",
    "        print('Новые фичи')\n",
    "\n",
    "        # Итерируем по значениям\n",
    "        for value in features_dictionary[col]:\n",
    "            new_column = f'{col}_prop_{value}'\n",
    "            print(new_column)                     \n",
    "\n",
    "            \"\"\"\n",
    "            Создаём булевую маску: True, если значение в col равно value,\n",
    "            иначе False.\n",
    "            \"\"\"\n",
    "            mask = (df[col] == value)\n",
    "            \"\"\"\n",
    "            Для каждой строки вычисляем количество совпадений value \n",
    "            по id (transform('sum')) и делим на общее количество кредитов \n",
    "            по id (rn_max), чтобы получить долю.\n",
    "            \"\"\"\n",
    "            df[new_column] = mask.groupby(df['id']).transform('sum') / df['rn_max']        \n",
    "\n",
    "    return df\n",
    "\n",
    "def from_is_zero_prop_1_create_sum_prop_1_feature_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Вычисляет среднее значение признаков is_zero_*_prop_1 по строкам и добавляет \n",
    "    новый признак 'is_zero_sum_prop_1' в DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df:  Исходный DataFrame с признаками is_zero_*_prop_1.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Копия DataFrame с добавленным признаком 'is_zero_sum_prop_1'.\n",
    "    \"\"\"\n",
    "    print('FUNCTION from_is_zero_prop_1_create_sum_prop_1_feature_pipeline ')\n",
    "\n",
    "    columns = [\n",
    "        'is_zero_loans5_prop_1',\n",
    "        'is_zero_loans530_prop_1',\n",
    "        'is_zero_loans3060_prop_1',\n",
    "        'is_zero_loans6090_prop_1',\n",
    "        'is_zero_loans90_prop_1'\n",
    "    ]\n",
    "\n",
    "    df['is_zero_sum_prop_1'] = df[columns].sum(axis=1) / 5\n",
    "\n",
    "    return df\n",
    "\n",
    "def mean_value_frequency_feature_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cоздаёт новые агрегированные признаки,\n",
    "    отражающий среднюю частоту (относительную встречаемость) значений \n",
    "    заданных столбцов columns_list датафрейма для каждого уникального id.\n",
    "    Результат добавляется в  датафрейм \n",
    "    с нормировкой на количество записей (rn_max) для каждого id.\n",
    "    \n",
    "    Args:\n",
    "        df :  Исходный DataFrame с признаками из columns_list.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame :  Копия DataFrame с добавленным новым столбцом {column}_mean_freq,\n",
    "        содержащим нормированное агрегированное значение средней \n",
    "        частоты значений column для каждого id.\n",
    "    \"\"\"\n",
    "    print('FUNCTION mean_value_frequency_feature_pipeline ')\n",
    "        \n",
    "    # Список столбцов, для которых считаем среднюю частоту значений\n",
    "    columns_list = [\n",
    "        'pre_util',\n",
    "        'pre_loans_credit_limit',\n",
    "        'pre_since_opened',\n",
    "        'pre_loans_credit_cost_rate',\n",
    "        'enc_loans_credit_type',\n",
    "        'pre_loans_next_pay_summ',\n",
    "        'pre_since_confirmed',\n",
    "        'pre_pterm',\n",
    "        'enc_paym_0',\n",
    "        'enc_loans_account_holder_type',\n",
    "        'pre_loans530',\n",
    "        'enc_paym_8',\n",
    "        'pre_loans5',\n",
    "        'enc_paym_10',\n",
    "        'enc_loans_account_cur',\n",
    "        'enc_paym_9'\n",
    "    ]\n",
    "    \n",
    "    for col in columns_list:\n",
    "        new_column = f'{col}_mean_freq'\n",
    "        print('new_column', new_column)\n",
    "        \n",
    "        # Вычисляем относительную частоту каждого уникального значения в столбце\n",
    "        bin_freq = df[col].value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        # Создаём Series с частотами значений для каждой строки\n",
    "        freq_series = df[col].map(bin_freq)\n",
    "        \n",
    "        # Группируем по 'id' и суммируем частоты значений\n",
    "        agg_freq = freq_series.groupby(df['id']).sum().reset_index(name=new_column)\n",
    "        \n",
    "        # Добавляем новый признак в DataFrame, объединяя по 'id'\n",
    "        df = df.merge(agg_freq, on='id', how='left')\n",
    "    \n",
    "        # Нормируем агрегированные суммы частот на количество записей 'rn_max' для каждого id\n",
    "        df[new_column] = df[new_column] / df['rn_max']\n",
    "\n",
    "    return df\n",
    "\n",
    "def enc_paym_norm_group_sum_diff_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Генерирует признаки разницы между средними количествами различных статусов платежей \n",
    "    по кредитам за разные временные промежутки.\n",
    "\n",
    "    Основная цель функции — создать итоговые признаки:\n",
    "        - 'enc_paym_avg_0_1_this_year_diff'\n",
    "        - 'enc_paym_avg_1_2_all_diff'\n",
    "        - 'enc_paym_avg_0_years_diff'\n",
    "\n",
    "    Для их расчёта временно создаются промежуточные агрегированные признаки среднего \n",
    "    количества статусов платежей по id и периоду \n",
    "    (например, 'enc_paym_avg_0_this_year'), \n",
    "    которые впоследствии удаляются из итогового датасета.\n",
    "\n",
    "    Args:\n",
    "        df :  Исходный DataFrame с признаками из columns_list.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame :  Копия DataFrame с добавленными итоговыми признаками \n",
    "        разницы между средними количествами статусов платежей по различным периодам.\n",
    "    \"\"\"\n",
    "\n",
    "    print('FUNCTION enc_paym_norm_group_sum_diff_pipeline ')\n",
    "\n",
    "    # Создаём временный датафрейм со столбцом id из df\n",
    "    df_buff = pd.DataFrame(data = df['id'], columns = ['id'])\n",
    "    \n",
    "    # Временной промежуток 'all' — все периоды\n",
    "    time_span = 'all'\n",
    "    columns = [f'enc_paym_{i}' for i in range(25)]\n",
    "\n",
    "    # Для статусов платежей по кредитам 1 и 2\n",
    "    for i in range(1, 3):\n",
    "        new_col = f'enc_paym_avg_{i}_{time_span}'\n",
    "        print('new_column', new_col)\n",
    "        \n",
    "        # Считаем количество статуса i по всем столбцам за период \n",
    "        df_buff[new_col] = np.sum(\n",
    "            [df[col] == i for col in columns],\n",
    "            axis=0\n",
    "        )\n",
    "        \n",
    "        # Группируем по id и суммируем значения\n",
    "        agg_sum = (\n",
    "            df_buff\n",
    "            .groupby('id')\n",
    "            [new_col]  \n",
    "            .sum()\n",
    "            .reset_index(name=new_col)\n",
    "        )\n",
    "        \n",
    "        # Добавляем группировку в исходный DataFrame\n",
    "        df = df.merge(agg_sum, on='id', how='left')\n",
    "        \n",
    "        # Нормируем сумму на количество записей 'rn_max' \n",
    "        df[new_col] = df[new_col] / df['rn_max']\n",
    "        \n",
    "    # Временной промежуток 'this_year' — первые 12 месяцев\n",
    "    time_span = 'this_year'\n",
    "    columns = [f'enc_paym_{i}' for i in range(12)]\n",
    "\n",
    "    # Для статусов платежей по кредитам 0 и 1\n",
    "    for i in range(2):\n",
    "        new_col = f'enc_paym_avg_{i}_{time_span}'\n",
    "        print('new_column', new_col)\n",
    "        \n",
    "        # Считаем количество статуса i по всем столбцам за период \n",
    "        df_buff[new_col] = np.sum(\n",
    "            [df[col] == i for col in columns],\n",
    "            axis=0\n",
    "        )\n",
    "        \n",
    "        # Группируем по id и суммируем значения\n",
    "        agg_sum = (\n",
    "            df_buff\n",
    "            .groupby('id')\n",
    "            [new_col]  \n",
    "            .sum()\n",
    "            .reset_index(name=new_col)\n",
    "        )\n",
    "        \n",
    "        # Добавляем группировку в исходный DataFrame\n",
    "        df = df.merge(agg_sum, on='id', how='left')\n",
    "        \n",
    "        # Нормируем сумму на количество записей 'rn_max' \n",
    "        df[new_col] = df[new_col] / df['rn_max']\n",
    "        \n",
    "    # Временной промежуток 'last_year' — месяцы с 12 по 24\n",
    "    time_span = 'last_year'\n",
    "    columns = [f'enc_paym_{i}' for i in range(12, 25)]\n",
    "    \n",
    "    \"\"\"\n",
    "    Статус платежей  0.\n",
    "    (Оставим цикл для единообразия кода)\n",
    "    \"\"\"\n",
    "    for i in [0]:\n",
    "        new_col = f'enc_paym_avg_{i}_{time_span}'\n",
    "        print('new_column', new_col)\n",
    "        \n",
    "        # Считаем количество статуса i по всем столбцам за период \n",
    "        df_buff[new_col] = np.sum(\n",
    "            [df[old_col] == i for old_col in columns],\n",
    "            axis=0\n",
    "        )\n",
    "        \n",
    "        # Группируем по id и суммируем значения\n",
    "        agg_sum = (\n",
    "            df_buff\n",
    "            .groupby('id')\n",
    "            [new_col]  \n",
    "            .sum()\n",
    "            .reset_index(name=new_col)\n",
    "        )\n",
    "        \n",
    "        # Добавляем группировку в исходный DataFrame\n",
    "        df = df.merge(agg_sum, on='id', how='left')\n",
    "        \n",
    "        # Нормируем сумму на количество записей 'rn_max' \n",
    "        df[new_col] = df[new_col] / df['rn_max']\n",
    "\n",
    "    # Создаём фичи разницы \n",
    "    df['enc_paym_avg_0_1_this_year_diff'] = (\n",
    "            df['enc_paym_avg_0_this_year'] - \n",
    "            df['enc_paym_avg_1_this_year']\n",
    "    )\n",
    "\n",
    "    df['enc_paym_avg_1_2_all_diff'] = (\n",
    "            df['enc_paym_avg_1_all'] - \n",
    "            df['enc_paym_avg_2_all']\n",
    "    )\n",
    "\n",
    "    df['enc_paym_avg_0_years_diff'] = (\n",
    "            df['enc_paym_avg_0_this_year'] - \n",
    "            df['enc_paym_avg_0_last_year']\n",
    "    )\n",
    "    \n",
    "    print('new diff columns')\n",
    "    print('enc_paym_avg_0_1_this_year_diff')\n",
    "    print('enc_paym_avg_1_2_all_diff')\n",
    "    print('enc_paym_avg_0_years_diff')\n",
    "\n",
    "    return df\n",
    "\n",
    "def pre_since_opened_sum_mean_repeated_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cоздаёт признак, отражающий пропорцию повторяющихся значений 'pre_since_opened'\n",
    "    для каждого 'id'.\n",
    "\n",
    "    Логика работы:\n",
    "    - Подсчитывает количество появлений каждого значения 'pre_since_opened' для каждого 'id'.\n",
    "    - Выделяет только повторяющиеся значения (где количество > 1) и вычитает 1,\n",
    "      чтобы не считать первое появление.\n",
    "    - Суммирует количество повторов по всем значениям 'pre_since_opened' для каждого 'id'.\n",
    "    - Добавляет отсутствующие 'id' с нулевыми значениями повторов.\n",
    "    - Добавляет новый признак 'pre_since_opened_repeated_prop' в df_to_update,\n",
    "      нормируя сумму повторов на количество записей 'rn_max' для каждого 'id'.\n",
    "\n",
    "    Args:\n",
    "        df :  Исходный DataFrame с признаками  'pre_since_opened', 'id' и 'rn_max'.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame :  Копия DataFrame с \n",
    "        добавленным признаком 'pre_since_opened_repeated_prop'.\n",
    "    \"\"\"\n",
    "    print('FUNCTION pre_since_opened_sum_mean_repeated_pipeline ')\n",
    "    \n",
    "    # Считаем количество каждого значения 'pre_since_opened' для каждого 'id'\n",
    "    counts = df.groupby(['id', 'pre_since_opened']).size()\n",
    "    \n",
    "    \"\"\"\n",
    "    Оставляем только повторяющиеся значения (количество > 1), \n",
    "    вычитаем первое появление.\n",
    "    \"\"\"\n",
    "    repeated_pre_since_opened = counts[counts > 1] - 1\n",
    "\n",
    "    # Суммируем количество повторов по каждому 'id'\n",
    "    sum_repeated = repeated_pre_since_opened.groupby('id').sum()\n",
    "    \n",
    "    # Добавляем отсутствующие 'id' с нулевыми значениями повторов\n",
    "    all_sum_repeated = sum_repeated.reindex(df['id'].unique(), fill_value=0)\n",
    "    \n",
    "    # Переименовываем Series для дальнейшего слияния\n",
    "    all_sum_repeated = all_sum_repeated.rename('pre_since_opened_repeated_prop')\n",
    "\n",
    "    # Объединяем с исходным DataFrame по 'id'\n",
    "    df = df.merge(all_sum_repeated, on='id', how='left')\n",
    "\n",
    "    # Нормируем сумму повторов на количество записей 'rn_max' для каждого 'id'\n",
    "    df['pre_since_opened_repeated_prop'] = (\n",
    "        df['pre_since_opened_repeated_prop'] / df['rn_max']\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def drop_columns_drop_duplicates_pipeline(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Удаляет исходные и временные признаки из DataFrame,\n",
    "    а также удаляет дубликаты по столбцу 'id', оставляя только первую запись.\n",
    "    После удаления дубликатов столбец 'id' также удаляется.\n",
    "\n",
    "    Args:\n",
    "        df : Исходный DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame : Копия DataFrame без указанных столбцов и дубликатов по 'id'.\n",
    "    \"\"\"\n",
    "\n",
    "    print('FUNCTION drop_columns_drop_duplicates_pipeline ')\n",
    "    # Список столбцов на удаление\n",
    "    columns = [\n",
    "        'rn',\n",
    "        'pre_since_opened',\n",
    "        'pre_since_confirmed',\n",
    "        'pre_pterm',\n",
    "        'pre_fterm',\n",
    "        'pre_till_pclose',\n",
    "        'pre_till_fclose',\n",
    "        'pre_loans_credit_limit',\n",
    "        'pre_loans_next_pay_summ',\n",
    "        'pre_loans_outstanding',\n",
    "        'pre_loans_max_overdue_sum',\n",
    "        'pre_loans_credit_cost_rate',\n",
    "        'pre_loans5',\n",
    "        'pre_loans530',\n",
    "        'is_zero_loans5',\n",
    "        'is_zero_loans530',\n",
    "        'pre_util',\n",
    "        'pre_over2limit',\n",
    "        'is_zero_over2limit',\n",
    "        'enc_paym_0',\n",
    "        'enc_paym_1',\n",
    "        'enc_paym_2',\n",
    "        'enc_paym_8',\n",
    "        'enc_paym_9',\n",
    "        'enc_paym_10',\n",
    "        'enc_paym_24',\n",
    "        'enc_loans_account_holder_type',\n",
    "        'enc_loans_credit_status',\n",
    "        'enc_loans_credit_type',\n",
    "        'enc_loans_account_cur',\n",
    "        'is_zero_loans3060',\n",
    "        'is_zero_loans6090',\n",
    "        'is_zero_loans90',\n",
    "        'enc_paym_3',\n",
    "        'enc_paym_4',\n",
    "        'enc_paym_5',\n",
    "        'enc_paym_6',\n",
    "        'enc_paym_7',\n",
    "        'enc_paym_11',\n",
    "        'enc_paym_12',\n",
    "        'enc_paym_13',\n",
    "        'enc_paym_14',\n",
    "        'enc_paym_15',\n",
    "        'enc_paym_16',\n",
    "        'enc_paym_17',\n",
    "        'enc_paym_18',\n",
    "        'enc_paym_19',\n",
    "        'enc_paym_20',\n",
    "        'enc_paym_21',\n",
    "        'enc_paym_22',\n",
    "        'enc_paym_23',\n",
    "        'enc_paym_avg_1_all',\n",
    "        'enc_paym_avg_2_all',\n",
    "        'enc_paym_avg_0_this_year',\n",
    "        'enc_paym_avg_1_this_year',\n",
    "        'enc_paym_avg_0_last_year',\n",
    "        'is_zero_loans3060_prop_1',\n",
    "        'is_zero_loans6090_prop_1',\n",
    "        'is_zero_loans90_prop_1'\n",
    "    ]\n",
    "    \n",
    "    df = df.drop(columns, axis=1)\n",
    "    \n",
    "    \"\"\"\n",
    "    Удаляем дубликаты по столбцу 'id', оставляя первую запись\n",
    "    и сбрасываем индекс.\n",
    "    \"\"\"\n",
    "    df = df.drop_duplicates(subset=['id'], keep='first').reset_index(drop=True)\n",
    "    \n",
    "    # Удаляем столбец 'id', так как он больше не нужен\n",
    "    df = df.drop('id', axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53162a0f-0907-4ca3-8ec2-55ade8b74584",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Из-за большого размера датасета вычисление медиан признаков занимает\n",
    "большой объём памяти, что приводит к падению ядра ноутбука. Поэтому применим\n",
    "кастомный imputer и будем расчитывать медианы на 10% процентах датасета.\n",
    "Оценки медианы будут приближены к реальным медианам, но не совпадать с ними.\n",
    "Такое решение это компромис между точностью и производительностью.\n",
    "Например для признака id погрешность между реальной медианой и оценочной \n",
    "составила около 0.05%.\n",
    "\"\"\"\n",
    "class SampleMedianImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, sample_frac=0.1):\n",
    "        # Доля выборки для вычисления медиан\n",
    "        self.sample_frac = sample_frac\n",
    "        # Атрибут для хранения медиан\n",
    "        self.medians_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Создаём подвыборку датасета, random_state для воспроизводимости\n",
    "        sample = X.sample(frac=self.sample_frac, random_state=0)\n",
    "        # Вычисляем и сохраняем медианы\n",
    "        self.medians_ = sample.median()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Заполняем пропуски медианами\n",
    "        return X.fillna(self.medians_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3417c72d-5480-4485-bf36-277a44b44208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём SampleMedianImputer, долю выборки оставляем равной 0.1\n",
    "imputer = SampleMedianImputer(sample_frac=0.1)\n",
    "\n",
    "# Создаём паплайн препроцессинга\n",
    "preprocessing_pipe = Pipeline([\n",
    "    ('to_numeric', FunctionTransformer(convert_all_to_numeric_pipeline)), \n",
    "    ('imputer', imputer),\n",
    "    ('to_int', FunctionTransformer(lambda df: df.astype(int), validate=False)),\n",
    "    ('drop_duplicates', FunctionTransformer(lambda df: df.drop_duplicates(), validate=False))\n",
    "])\n",
    "\n",
    "# Создаём основной пайплайн\n",
    "main_pipe = Pipeline(\n",
    "    [\n",
    "        # (\n",
    "        #     'preprocessing',\n",
    "        #     preprocessing_pipe\n",
    "        # ),\n",
    "        (\n",
    "            'create_rn_max_feature',\n",
    "            FunctionTransformer(rn_max_feature_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'enc_paym_transcoding', \n",
    "            FunctionTransformer(enc_paym_transcoding_pipeline)\n",
    "        ),\n",
    "        (\n",
    "            'create_definite_value_proportion_features',\n",
    "            FunctionTransformer(definite_value_proportion_features_pipeline)\n",
    "        ),\n",
    "        # (\n",
    "        #     'create_sum_prop_1_feature',\n",
    "        #     FunctionTransformer(from_is_zero_prop_1_create_sum_prop_1_feature_pipeline)\n",
    "        # ),\n",
    "        # (\n",
    "        #     'create_mean_value_frequency_feature',\n",
    "        #     FunctionTransformer(mean_value_frequency_feature_pipeline)\n",
    "        # ),\n",
    "        # (\n",
    "        #     'from_enc_paym_create_normalized_group_sum_features_then_diff_features',\n",
    "        #     FunctionTransformer(enc_paym_norm_group_sum_diff_pipeline)\n",
    "        # ),\n",
    "        # (\n",
    "        #     'from_pre_since_opened_create_pre_since_opened_sum_mean_repeated',\n",
    "        #     FunctionTransformer(pre_since_opened_sum_mean_repeated_pipeline)\n",
    "        # ),\n",
    "        # (\n",
    "        #     'drop_temporary_and_source_columns_drop_duplicates',\n",
    "        #     FunctionTransformer(drop_columns_drop_duplicates_pipeline)\n",
    "        # ),\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8659654c-4732-4087-a77b-42e9d384c3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTION rn_max_feature_pipeline\n",
      "FUNCTION enc_paym_transcoding_pipeline \n",
      "FUNCTION definite_value_proportion_features_pipeline \n",
      "Исходный признак enc_loans_account_holder_type\n",
      "Новые фичи\n",
      "enc_loans_account_holder_type_prop_4\n",
      "Исходный признак pre_pterm\n",
      "Новые фичи\n",
      "pre_pterm_prop_6\n",
      "pre_pterm_prop_3\n",
      "Исходный признак is_zero_loans530\n",
      "Новые фичи\n",
      "is_zero_loans530_prop_1\n",
      "Исходный признак enc_paym_0\n",
      "Новые фичи\n",
      "enc_paym_0_prop_1\n",
      "Исходный признак pre_loans_credit_cost_rate\n",
      "Новые фичи\n",
      "pre_loans_credit_cost_rate_prop_6\n",
      "pre_loans_credit_cost_rate_prop_11\n",
      "pre_loans_credit_cost_rate_prop_4\n",
      "Исходный признак pre_loans_next_pay_summ\n",
      "Новые фичи\n",
      "pre_loans_next_pay_summ_prop_5\n",
      "pre_loans_next_pay_summ_prop_0\n",
      "Исходный признак is_zero_over2limit\n",
      "Новые фичи\n",
      "is_zero_over2limit_prop_1\n",
      "Исходный признак pre_loans_outstanding\n",
      "Новые фичи\n",
      "pre_loans_outstanding_prop_1\n",
      "pre_loans_outstanding_prop_5\n",
      "Исходный признак pre_util\n",
      "Новые фичи\n",
      "pre_util_prop_3\n",
      "pre_util_prop_6\n",
      "Исходный признак pre_till_pclose\n",
      "Новые фичи\n",
      "pre_till_pclose_prop_10\n",
      "pre_till_pclose_prop_7\n",
      "Исходный признак is_zero_loans5\n",
      "Новые фичи\n",
      "is_zero_loans5_prop_1\n",
      "Исходный признак pre_since_confirmed\n",
      "Новые фичи\n",
      "pre_since_confirmed_prop_4\n",
      "pre_since_confirmed_prop_7\n",
      "Исходный признак pre_loans_credit_limit\n",
      "Новые фичи\n",
      "pre_loans_credit_limit_prop_2\n",
      "pre_loans_credit_limit_prop_15\n",
      "pre_loans_credit_limit_prop_18\n",
      "Исходный признак pre_over2limit\n",
      "Новые фичи\n",
      "pre_over2limit_prop_17\n",
      "Исходный признак pre_till_fclose\n",
      "Новые фичи\n",
      "pre_till_fclose_prop_4\n",
      "pre_till_fclose_prop_3\n",
      "pre_till_fclose_prop_1\n",
      "Исходный признак enc_loans_credit_status\n",
      "Новые фичи\n",
      "enc_loans_credit_status_prop_5\n",
      "Исходный признак pre_since_opened\n",
      "Новые фичи\n",
      "pre_since_opened_prop_12\n",
      "pre_since_opened_prop_8\n",
      "pre_since_opened_prop_19\n",
      "Исходный признак enc_paym_24\n",
      "Новые фичи\n",
      "enc_paym_24_prop_1\n",
      "Исходный признак pre_loans_max_overdue_sum\n",
      "Новые фичи\n",
      "pre_loans_max_overdue_sum_prop_1\n",
      "Исходный признак enc_loans_credit_type\n",
      "Новые фичи\n",
      "enc_loans_credit_type_prop_0\n",
      "enc_loans_credit_type_prop_2\n",
      "Исходный признак pre_fterm\n",
      "Новые фичи\n",
      "pre_fterm_prop_7\n",
      "pre_fterm_prop_3\n",
      "Исходный признак is_zero_loans3060\n",
      "Новые фичи\n",
      "is_zero_loans3060_prop_1\n",
      "Исходный признак is_zero_loans6090\n",
      "Новые фичи\n",
      "is_zero_loans6090_prop_1\n",
      "Исходный признак is_zero_loans90\n",
      "Новые фичи\n",
      "is_zero_loans90_prop_1\n",
      "FUNCTION definite_value_proportion_features_pipeline_2 \n",
      "Исходный признак enc_loans_account_holder_type\n",
      "Новые фичи\n",
      "enc_loans_account_holder_type_prop_4_2\n",
      "Исходный признак pre_pterm\n",
      "Новые фичи\n",
      "pre_pterm_prop_6_2\n",
      "pre_pterm_prop_3_2\n",
      "Исходный признак is_zero_loans530\n",
      "Новые фичи\n",
      "is_zero_loans530_prop_1_2\n",
      "Исходный признак enc_paym_0\n",
      "Новые фичи\n",
      "enc_paym_0_prop_1_2\n",
      "Исходный признак pre_loans_credit_cost_rate\n",
      "Новые фичи\n",
      "pre_loans_credit_cost_rate_prop_6_2\n",
      "pre_loans_credit_cost_rate_prop_11_2\n",
      "pre_loans_credit_cost_rate_prop_4_2\n",
      "Исходный признак pre_loans_next_pay_summ\n",
      "Новые фичи\n",
      "pre_loans_next_pay_summ_prop_5_2\n",
      "pre_loans_next_pay_summ_prop_0_2\n",
      "Исходный признак is_zero_over2limit\n",
      "Новые фичи\n",
      "is_zero_over2limit_prop_1_2\n",
      "Исходный признак pre_loans_outstanding\n",
      "Новые фичи\n",
      "pre_loans_outstanding_prop_1_2\n",
      "pre_loans_outstanding_prop_5_2\n",
      "Исходный признак pre_util\n",
      "Новые фичи\n",
      "pre_util_prop_3_2\n",
      "pre_util_prop_6_2\n",
      "Исходный признак pre_till_pclose\n",
      "Новые фичи\n",
      "pre_till_pclose_prop_10_2\n",
      "pre_till_pclose_prop_7_2\n",
      "Исходный признак is_zero_loans5\n",
      "Новые фичи\n",
      "is_zero_loans5_prop_1_2\n",
      "Исходный признак pre_since_confirmed\n",
      "Новые фичи\n",
      "pre_since_confirmed_prop_4_2\n",
      "pre_since_confirmed_prop_7_2\n",
      "Исходный признак pre_loans_credit_limit\n",
      "Новые фичи\n",
      "pre_loans_credit_limit_prop_2_2\n",
      "pre_loans_credit_limit_prop_15_2\n",
      "pre_loans_credit_limit_prop_18_2\n",
      "Исходный признак pre_over2limit\n",
      "Новые фичи\n",
      "pre_over2limit_prop_17_2\n",
      "Исходный признак pre_till_fclose\n",
      "Новые фичи\n",
      "pre_till_fclose_prop_4_2\n",
      "pre_till_fclose_prop_3_2\n",
      "pre_till_fclose_prop_1_2\n",
      "Исходный признак enc_loans_credit_status\n",
      "Новые фичи\n",
      "enc_loans_credit_status_prop_5_2\n",
      "Исходный признак pre_since_opened\n",
      "Новые фичи\n",
      "pre_since_opened_prop_12_2\n",
      "pre_since_opened_prop_8_2\n",
      "pre_since_opened_prop_19_2\n",
      "Исходный признак enc_paym_24\n",
      "Новые фичи\n",
      "enc_paym_24_prop_1_2\n",
      "Исходный признак pre_loans_max_overdue_sum\n",
      "Новые фичи\n",
      "pre_loans_max_overdue_sum_prop_1_2\n",
      "Исходный признак enc_loans_credit_type\n",
      "Новые фичи\n",
      "enc_loans_credit_type_prop_0_2\n",
      "enc_loans_credit_type_prop_2_2\n",
      "Исходный признак pre_fterm\n",
      "Новые фичи\n",
      "pre_fterm_prop_7_2\n",
      "pre_fterm_prop_3_2\n",
      "Исходный признак is_zero_loans3060\n",
      "Новые фичи\n",
      "is_zero_loans3060_prop_1_2\n",
      "Исходный признак is_zero_loans6090\n",
      "Новые фичи\n",
      "is_zero_loans6090_prop_1_2\n",
      "Исходный признак is_zero_loans90\n",
      "Новые фичи\n",
      "is_zero_loans90_prop_1_2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rn</th>\n",
       "      <th>pre_since_opened</th>\n",
       "      <th>pre_since_confirmed</th>\n",
       "      <th>pre_pterm</th>\n",
       "      <th>pre_fterm</th>\n",
       "      <th>pre_till_pclose</th>\n",
       "      <th>pre_till_fclose</th>\n",
       "      <th>pre_loans_credit_limit</th>\n",
       "      <th>pre_loans_next_pay_summ</th>\n",
       "      <th>...</th>\n",
       "      <th>pre_since_opened_prop_19_2</th>\n",
       "      <th>enc_paym_24_prop_1_2</th>\n",
       "      <th>pre_loans_max_overdue_sum_prop_1_2</th>\n",
       "      <th>enc_loans_credit_type_prop_0_2</th>\n",
       "      <th>enc_loans_credit_type_prop_2_2</th>\n",
       "      <th>pre_fterm_prop_7_2</th>\n",
       "      <th>pre_fterm_prop_3_2</th>\n",
       "      <th>is_zero_loans3060_prop_1_2</th>\n",
       "      <th>is_zero_loans6090_prop_1_2</th>\n",
       "      <th>is_zero_loans90_prop_1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1506130</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1506130</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1506130</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1506130</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1506130</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20931471</th>\n",
       "      <td>2022334</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20931472</th>\n",
       "      <td>2022334</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20931473</th>\n",
       "      <td>2022334</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20931474</th>\n",
       "      <td>2022334</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20931475</th>\n",
       "      <td>2022334</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20931476 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  rn  pre_since_opened  pre_since_confirmed  pre_pterm  \\\n",
       "0         1506130   1                10                    6          1   \n",
       "1         1506130   2                10                    6          4   \n",
       "2         1506130   3                 5                    9         17   \n",
       "3         1506130   4                11                    1         15   \n",
       "4         1506130   5                 1                    9         15   \n",
       "...           ...  ..               ...                  ...        ...   \n",
       "20931471  2022334  14                 7                    5          9   \n",
       "20931472  2022334  15                19                    6         13   \n",
       "20931473  2022334  16                19                   16          9   \n",
       "20931474  2022334  17                12                   16         13   \n",
       "20931475  2022334  18                12                    2          2   \n",
       "\n",
       "          pre_fterm  pre_till_pclose  pre_till_fclose  pre_loans_credit_limit  \\\n",
       "0                16                3                5                       0   \n",
       "1                13                1                7                      15   \n",
       "2                 8                1               11                      15   \n",
       "3                 9                2                6                       2   \n",
       "4                 8                1               11                       2   \n",
       "...             ...              ...              ...                     ...   \n",
       "20931471          3               12               15                       6   \n",
       "20931472          2               12               11                       6   \n",
       "20931473          8               12               11                      13   \n",
       "20931474          0               12               11                      19   \n",
       "20931475          8                8               11                       1   \n",
       "\n",
       "          pre_loans_next_pay_summ  ...  pre_since_opened_prop_19_2  \\\n",
       "0                               5  ...                    0.000000   \n",
       "1                               5  ...                    0.000000   \n",
       "2                               2  ...                    0.000000   \n",
       "3                               2  ...                    0.000000   \n",
       "4                               5  ...                    0.000000   \n",
       "...                           ...  ...                         ...   \n",
       "20931471                        2  ...                    0.111111   \n",
       "20931472                        2  ...                    0.111111   \n",
       "20931473                        2  ...                    0.111111   \n",
       "20931474                        1  ...                    0.111111   \n",
       "20931475                        6  ...                    0.111111   \n",
       "\n",
       "          enc_paym_24_prop_1_2  pre_loans_max_overdue_sum_prop_1_2  \\\n",
       "0                          0.0                                 0.2   \n",
       "1                          0.0                                 0.2   \n",
       "2                          0.0                                 0.2   \n",
       "3                          0.0                                 0.2   \n",
       "4                          0.0                                 0.2   \n",
       "...                        ...                                 ...   \n",
       "20931471                   0.0                                 0.0   \n",
       "20931472                   0.0                                 0.0   \n",
       "20931473                   0.0                                 0.0   \n",
       "20931474                   0.0                                 0.0   \n",
       "20931475                   0.0                                 0.0   \n",
       "\n",
       "          enc_loans_credit_type_prop_0_2  enc_loans_credit_type_prop_2_2  \\\n",
       "0                                    0.0                             0.0   \n",
       "1                                    0.0                             0.0   \n",
       "2                                    0.0                             0.0   \n",
       "3                                    0.0                             0.0   \n",
       "4                                    0.0                             0.0   \n",
       "...                                  ...                             ...   \n",
       "20931471                             0.0                             0.0   \n",
       "20931472                             0.0                             0.0   \n",
       "20931473                             0.0                             0.0   \n",
       "20931474                             0.0                             0.0   \n",
       "20931475                             0.0                             0.0   \n",
       "\n",
       "          pre_fterm_prop_7_2  pre_fterm_prop_3_2  is_zero_loans3060_prop_1_2  \\\n",
       "0                        0.0            0.000000                         1.0   \n",
       "1                        0.0            0.000000                         1.0   \n",
       "2                        0.0            0.000000                         1.0   \n",
       "3                        0.0            0.000000                         1.0   \n",
       "4                        0.0            0.000000                         1.0   \n",
       "...                      ...                 ...                         ...   \n",
       "20931471                 0.0            0.055556                         1.0   \n",
       "20931472                 0.0            0.055556                         1.0   \n",
       "20931473                 0.0            0.055556                         1.0   \n",
       "20931474                 0.0            0.055556                         1.0   \n",
       "20931475                 0.0            0.055556                         1.0   \n",
       "\n",
       "          is_zero_loans6090_prop_1_2  is_zero_loans90_prop_1_2  \n",
       "0                                1.0                       1.0  \n",
       "1                                1.0                       1.0  \n",
       "2                                1.0                       1.0  \n",
       "3                                1.0                       1.0  \n",
       "4                                1.0                       1.0  \n",
       "...                              ...                       ...  \n",
       "20931471                         1.0                       1.0  \n",
       "20931472                         1.0                       1.0  \n",
       "20931473                         1.0                       1.0  \n",
       "20931474                         1.0                       1.0  \n",
       "20931475                         1.0                       1.0  \n",
       "\n",
       "[20931476 rows x 133 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучим пайплайн\n",
    "X_train_full = main_pipe.fit_transform(X_train_full)\n",
    "X_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eff4f8b7-6589-4111-a39e-c808f1f852c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(X_train_full.is_zero_loans90_prop_1 == X_train_full.is_zero_loans90_prop_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10464883-970a-4a9e-a3b3-4c72b0a863db",
   "metadata": {},
   "source": [
    "git commit -m \"Change definite_value_proportion_features_pipeline function \" -m \"-Change merge to transform in definite_value_proportion_features_pipeline function\n",
    "-Remove fillna for the new columns\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
